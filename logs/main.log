2024-10-21 11:57:31,012 - __main__ - INFO - Starting main.py
2024-10-21 11:57:31,012 - __main__ - INFO - Chat log file path: C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\chat_history\2024\10\21.log
2024-10-21 11:57:31,012 - __main__ - INFO - API keys loaded successfully
2024-10-21 11:57:31,032 - comtypes - DEBUG - CoInitializeEx(None, 2)
2024-10-21 11:57:31,044 - comtypes.client._code_cache - INFO - Imported existing <module 'comtypes.gen' from 'C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\comtypes\\gen\\__init__.py'>
2024-10-21 11:57:31,044 - comtypes.client._code_cache - INFO - Using writeable comtypes cache directory: 'C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\comtypes\gen'
2024-10-21 11:57:31,092 - comtypes.client - DEBUG - SAPI.SPVoice -> {96749377-3391-11D2-9EE3-00C04F797396}
2024-10-21 11:57:31,092 - comtypes.client - DEBUG - CoCreateInstance({96749377-3391-11D2-9EE3-00C04F797396}, clsctx=None, interface=None)
2024-10-21 11:57:31,092 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IUnknown) ptr=0x1b7b771ba20 at 1b7caec6ed0>)
2024-10-21 11:57:31,092 - comtypes.client - DEBUG - Does implement IProvideClassInfo
2024-10-21 11:57:31,107 - comtypes.client - DEBUG - Default interface is {269316D8-57BD-11D2-9EEE-00C04F797396}
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1b7b771ba60 at 1b7caec72d0>
2024-10-21 11:57:31,107 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 11:57:31,107 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechVoice'>
2024-10-21 11:57:31,107 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechVoice) ptr=0x1b7b771ba60 at 1b7caec7250>
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo) ptr=0x1b7b771ba80 at 1b7caec6e50>
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x1b7c92b4ba8 at 1b7caec6f50>
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x1b7c92b4c00 at 1b7caec6fd0>
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x1b7c8ffa2f0 at 1b7caec72d0>
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1b7b771ba20 at 1b7caec6ed0>
2024-10-21 11:57:31,107 - comtypes.client._events - DEBUG - <POINTER(ISpeechVoice) ptr=0x1b7b771ba60 at 1b7caec7250> using sinkinterface from clsid <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo2) ptr=0x1b7b771ba80 at 1b7caec6ed0>
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>: _ISpeechVoiceEvents.VoiceChange not implemented
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>: _ISpeechVoiceEvents.Bookmark not implemented
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>: _ISpeechVoiceEvents.Sentence not implemented
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>: _ISpeechVoiceEvents.Phoneme not implemented
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>: _ISpeechVoiceEvents.Viseme not implemented
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>: _ISpeechVoiceEvents.AudioLevel not implemented
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>: _ISpeechVoiceEvents.EnginePrivate not implemented
2024-10-21 11:57:31,107 - comtypes.client._events - DEBUG - Start advise <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>.QueryInterface({A372ACD1-3BEF-4BBD-8FFB-CB3E2B416AF8}) -> S_OK
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - 1 active COM objects: Added   <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>.AddRef() -> 1
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IConnectionPointContainer) ptr=0x1b7b771ba88 at 1b7caf2c6d0>
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectToken) ptr=0x1b7b77f2b80 at 1b7caf2c6d0>)
2024-10-21 11:57:31,155 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x1b7b77f2b80 at 1b7caf2c6d0>
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x1b7cbc0a850 at 1b7caf2c6d0>)
2024-10-21 11:57:31,155 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1b7cbdb1420 at 1b7caf2c7d0>
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - wrap_outparam(<POINTER(IDispatch) ptr=0x1b7cbd64710 at 1b7caf2c9d0>)
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IDispatch) ptr=0x1b7cbd64710 at 1b7caf2c9d0>)
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo, trying IProvideClassInfo2
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo/IProvideClassInfo2
2024-10-21 11:57:31,155 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1b7c92b4cb0 at 1b7caf2cbd0>
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}
2024-10-21 11:57:31,155 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1b7cbd64710 at 1b7caf2ccd0>
2024-10-21 11:57:31,155 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechObjectToken) ptr=0x1b7cbd64710 at 1b7caf2cbd0>
2024-10-21 11:57:31,171 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x1b7cbd64710 at 1b7caf2cb50>
2024-10-21 11:57:31,171 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x1b7c92b4cb0 at 1b7caf2cc50>
2024-10-21 11:57:31,171 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x1b7c8ffa2f0 at 1b7caf2ccd0>
2024-10-21 11:57:31,171 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x1b7cbd64710 at 1b7caf2c9d0>
2024-10-21 11:57:31,171 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IEnumVARIANT) ptr=0x1b7cbdb1420 at 1b7caf2c850>
2024-10-21 11:57:31,171 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectTokens) ptr=0x1b7cbc0a850 at 1b7caf2c6d0>
2024-10-21 11:57:31,171 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x1b7cbd64710 at 1b7caf2cbd0>
2024-10-21 11:57:31,171 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 11:57:31,171 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 11:57:31,392 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 11:57:31,392 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 11:57:31,784 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2024-10-21 11:57:32,654 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/Systran/faster-whisper-base/revision/main HTTP/1.1" 200 1848
2024-10-21 11:57:33,239 - __main__ - INFO - Siri instance initialized
2024-10-21 11:57:43,828 - faster_whisper - INFO - Processing audio with duration 00:07.012
2024-10-21 11:57:44,529 - faster_whisper - INFO - Detected language 'es' with probability 0.40
2024-10-21 11:57:44,529 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:57:48,491 - faster_whisper - INFO - Processing audio with duration 00:02.020
2024-10-21 11:57:49,140 - faster_whisper - INFO - Detected language 'en' with probability 0.43
2024-10-21 11:57:49,140 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:58:04,371 - faster_whisper - INFO - Processing audio with duration 00:10.449
2024-10-21 11:58:05,035 - faster_whisper - INFO - Detected language 'en' with probability 0.43
2024-10-21 11:58:05,035 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:58:05,129 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.0 (-1.006838 < -1.000000)
2024-10-21 11:58:08,107 - faster_whisper - INFO - Processing audio with duration 00:01.486
2024-10-21 11:58:08,827 - faster_whisper - INFO - Detected language 'en' with probability 0.47
2024-10-21 11:58:08,827 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:58:18,851 - faster_whisper - INFO - Processing audio with duration 00:01.532
2024-10-21 11:58:19,645 - faster_whisper - INFO - Detected language 'en' with probability 0.39
2024-10-21 11:58:19,646 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:58:36,300 - faster_whisper - INFO - Processing audio with duration 00:15.186
2024-10-21 11:58:37,172 - faster_whisper - INFO - Detected language 'en' with probability 0.90
2024-10-21 11:58:37,172 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:58:57,414 - faster_whisper - INFO - Processing audio with duration 00:18.135
2024-10-21 11:58:58,078 - faster_whisper - INFO - Detected language 'en' with probability 0.36
2024-10-21 11:58:58,078 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:58:58,235 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'hello. Hello, Siri.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 11:58:58,329 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 11:58:58,329 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 11:58:58,464 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CE0EB590>
2024-10-21 11:58:58,464 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B7CAF2C8D0> server_hostname='api.groq.com' timeout=5.0
2024-10-21 11:58:58,578 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CE0EAF30>
2024-10-21 11:58:58,578 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 11:58:58,578 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 11:58:58,578 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 11:58:58,578 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 11:58:58,578 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 11:58:59,098 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 08:58:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19877'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'369ms'), (b'x-request-id', b'req_01jaq4t4dwf6ntxprjqej0sgr6'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=a8Nf1MCnumdQuxItbUgZ6sNHAxEyJHaT6FAT3gfgQK0-1729501139-1.0.1.1-iWwtbcXXIIM4MLlQQGingf0pF6RYJsu5ATHP6dSFmnVGuE5F5fl2CQOoVy7SEBy5RoNFwUTVUzi15WZC_oIWYQ; path=/; expires=Mon, 21-Oct-24 09:28:59 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d600c882c990566-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 11:58:59,113 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 11:58:59,114 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 08:58:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19877', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '369ms', 'x-request-id': 'req_01jaq4t4dwf6ntxprjqej0sgr6', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=a8Nf1MCnumdQuxItbUgZ6sNHAxEyJHaT6FAT3gfgQK0-1729501139-1.0.1.1-iWwtbcXXIIM4MLlQQGingf0pF6RYJsu5ATHP6dSFmnVGuE5F5fl2CQOoVy7SEBy5RoNFwUTVUzi15WZC_oIWYQ; path=/; expires=Mon, 21-Oct-24 09:28:59 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8d600c882c990566-JNB', 'content-encoding': 'gzip'})
2024-10-21 11:58:59,114 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'hello. Hello, Siri.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 11:58:59,114 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 11:58:59,830 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 08:59:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19823'), (b'x-ratelimit-reset-requests', b'11.351999999s'), (b'x-ratelimit-reset-tokens', b'531ms'), (b'x-request-id', b'req_01jaq4t522e7rtt42rh33m47jy'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d600c8c396d0566-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 11:58:59,830 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 11:58:59,830 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 11:58:59,830 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 11:58:59,830 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 11:58:59,830 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 11:58:59,830 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 08:59:00 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19823', 'x-ratelimit-reset-requests': '11.351999999s', 'x-ratelimit-reset-tokens': '531ms', 'x-request-id': 'req_01jaq4t522e7rtt42rh33m47jy', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d600c8c396d0566-JNB', 'content-encoding': 'gzip'})
2024-10-21 11:59:00,107 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I'm not Siri, I'm a multi-modal AI voice assistant. This is the beginning of our conversation, and I'm not seeing any context or additional information attached. Please feel free to share any questions, topics, or photos you'd like to discuss.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 11:59:00,107 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 11:59:00,107 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 11:59:00,288 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CFD29FA0>
2024-10-21 11:59:00,288 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B7CAF2D150> server_hostname='api.openai.com' timeout=5.0
2024-10-21 11:59:00,430 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CFD29E80>
2024-10-21 11:59:00,430 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 11:59:00,430 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 11:59:00,430 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 11:59:00,430 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 11:59:00,430 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 11:59:02,955 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 08:59:03 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1176'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_ac496087664a55a99dcf24ea3c59a227'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=s.R2B8sW99AdBjmGSAccB0sskkqZTGs69aM0zByWwAM-1729501143-1.0.1.1-Zaf26vFgtIkZkxwTncp..uicoJkFwCaGMjXHpHRv1v8HPcOSafWnBRKD5U178dLwpp7UaVnC8u2rxHufEL6akQ; path=/; expires=Mon, 21-Oct-24 09:29:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=xMM10zBBCXHMYhtPqK.Oif7xxRvFiOQbTjS7IC210RM-1729501143472-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d600c942bef73e2-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 11:59:02,955 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 11:59:02,955 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers([('date', 'Mon, 21 Oct 2024 08:59:03 GMT'), ('content-type', 'audio/pcm'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'viva-ai-g59lkf'), ('openai-processing-ms', '1176'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-reset-requests', '120ms'), ('x-request-id', 'req_ac496087664a55a99dcf24ea3c59a227'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=s.R2B8sW99AdBjmGSAccB0sskkqZTGs69aM0zByWwAM-1729501143-1.0.1.1-Zaf26vFgtIkZkxwTncp..uicoJkFwCaGMjXHpHRv1v8HPcOSafWnBRKD5U178dLwpp7UaVnC8u2rxHufEL6akQ; path=/; expires=Mon, 21-Oct-24 09:29:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=xMM10zBBCXHMYhtPqK.Oif7xxRvFiOQbTjS7IC210RM-1729501143472-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8d600c942bef73e2-JNB'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-10-21 11:59:02,955 - openai._base_client - DEBUG - request_id: req_ac496087664a55a99dcf24ea3c59a227
2024-10-21 11:59:02,955 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 11:59:17,548 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 11:59:17,548 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 11:59:17,548 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 11:59:49,986 - faster_whisper - INFO - Processing audio with duration 00:31.974
2024-10-21 11:59:50,694 - faster_whisper - INFO - Detected language 'en' with probability 0.78
2024-10-21 11:59:50,694 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:59:50,945 - faster_whisper - DEBUG - Processing segment at 00:20.000
2024-10-21 12:00:11,099 - faster_whisper - INFO - Processing audio with duration 00:17.810
2024-10-21 12:00:12,071 - faster_whisper - INFO - Detected language 'en' with probability 0.89
2024-10-21 12:00:12,072 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:00:14,106 - faster_whisper - INFO - Processing audio with duration 00:01.440
2024-10-21 12:00:15,025 - faster_whisper - INFO - Detected language 'en' with probability 0.42
2024-10-21 12:00:15,025 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:00:21,798 - faster_whisper - INFO - Processing audio with duration 00:01.370
2024-10-21 12:00:22,624 - faster_whisper - INFO - Detected language 'en' with probability 0.39
2024-10-21 12:00:22,624 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:00:23,946 - faster_whisper - INFO - Processing audio with duration 00:00.859
2024-10-21 12:00:24,796 - faster_whisper - INFO - Detected language 'en' with probability 0.46
2024-10-21 12:00:24,796 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:00:26,966 - faster_whisper - INFO - Processing audio with duration 00:01.765
2024-10-21 12:00:27,707 - faster_whisper - INFO - Detected language 'en' with probability 0.46
2024-10-21 12:00:27,707 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:00:31,191 - faster_whisper - INFO - Processing audio with duration 00:01.347
2024-10-21 12:00:31,931 - faster_whisper - INFO - Detected language 'en' with probability 0.37
2024-10-21 12:00:31,931 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:00:41,663 - faster_whisper - INFO - Processing audio with duration 00:02.624
2024-10-21 12:00:42,346 - faster_whisper - INFO - Detected language 'en' with probability 0.34
2024-10-21 12:00:42,346 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:01:00,514 - faster_whisper - INFO - Processing audio with duration 00:02.972
2024-10-21 12:01:01,512 - faster_whisper - INFO - Detected language 'en' with probability 0.39
2024-10-21 12:01:01,513 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:01:37,825 - faster_whisper - INFO - Processing audio with duration 00:25.496
2024-10-21 12:01:38,836 - faster_whisper - INFO - Detected language 'en' with probability 0.47
2024-10-21 12:01:38,838 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:01:39,177 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'who is the president of the US? Hello Siri, who is the first US president?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:01:39,178 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:01:39,179 - httpcore.connection - DEBUG - close.started
2024-10-21 12:01:39,179 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:01:39,180 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:01:39,283 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CE0E97C0>
2024-10-21 12:01:39,284 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B7CAF2C8D0> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:01:39,418 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CE0EAFF0>
2024-10-21 12:01:39,418 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:01:39,419 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:01:39,420 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:01:39,420 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:01:39,421 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:01:39,916 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:01:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19863'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'411ms'), (b'x-request-id', b'req_01jaq4z1fpfznvn9766rn6kqm2'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6010755a6c4eb7-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:01:39,917 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:01:39,917 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:01:39,918 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:01:39,918 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:01:39,918 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:01:39,919 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:01:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19863', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '411ms', 'x-request-id': 'req_01jaq4z1fpfznvn9766rn6kqm2', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6010755a6c4eb7-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:01:39,923 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'hello. Hello, Siri.'}, {'role': 'assistant', 'content': "I'm not Siri, I'm a multi-modal AI voice assistant. This is the beginning of our conversation, and I'm not seeing any context or additional information attached. Please feel free to share any questions, topics, or photos you'd like to discuss."}, {'role': 'user', 'content': 'who is the president of the US? Hello Siri, who is the first US president?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:01:39,924 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:01:39,925 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:01:39,925 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:01:39,925 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:01:39,926 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:01:39,926 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:01:40,515 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:01:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19735'), (b'x-ratelimit-reset-requests', b'11.483s'), (b'x-ratelimit-reset-tokens', b'795ms'), (b'x-request-id', b'req_01jaq4z1zxepnrhnehpggb8q2b'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6010789de94eb7-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:01:40,516 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:01:40,516 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:01:40,517 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:01:40,517 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:01:40,517 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:01:40,518 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:01:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19735', 'x-ratelimit-reset-requests': '11.483s', 'x-ratelimit-reset-tokens': '795ms', 'x-request-id': 'req_01jaq4z1zxepnrhnehpggb8q2b', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6010789de94eb7-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:01:40,777 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I'm not Siri, I'm a different AI voice assistant. Our conversation continues - currently, the President of the United States is Joe Biden. The first US president and the first commander-in-chief of the US military is George Washington, who served from 1789 to 1797.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:01:40,779 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:01:40,779 - httpcore.connection - DEBUG - close.started
2024-10-21 12:01:40,780 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:01:40,780 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:01:40,883 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CFD2BFB0>
2024-10-21 12:01:40,883 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B7CAF2D150> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:01:41,240 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CFD2B890>
2024-10-21 12:01:41,242 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:01:41,243 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:01:41,245 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:01:41,247 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:01:41,248 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:01:43,616 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:01:44 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1230'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_0019c5559e9eaacea61071af786e6c69'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60108109bb73b5-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:01:43,616 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:01:43,617 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:01:44 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1230', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_0019c5559e9eaacea61071af786e6c69', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d60108109bb73b5-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:01:43,618 - openai._base_client - DEBUG - request_id: req_0019c5559e9eaacea61071af786e6c69
2024-10-21 12:01:43,618 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:02:01,608 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:02:01,608 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:02:01,609 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:02:42,254 - faster_whisper - INFO - Processing audio with duration 00:35.085
2024-10-21 12:07:03,550 - faster_whisper - INFO - Detected language 'en' with probability 0.57
2024-10-21 12:07:03,550 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:07:03,785 - faster_whisper - DEBUG - Processing segment at 00:19.600
2024-10-21 12:07:23,032 - faster_whisper - INFO - Processing audio with duration 00:13.630
2024-10-21 12:07:23,697 - faster_whisper - INFO - Detected language 'en' with probability 0.70
2024-10-21 12:07:23,697 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:07:23,949 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': "and if you're not Siri, who are you?"}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:07:23,949 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:07:23,949 - httpcore.connection - DEBUG - close.started
2024-10-21 12:07:23,949 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:07:23,949 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:07:24,064 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CFD2A8A0>
2024-10-21 12:07:24,064 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B7CAF2C8D0> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:07:24,202 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CFD2A1B0>
2024-10-21 12:07:24,202 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:07:24,203 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:07:24,203 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:07:24,204 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:07:24,204 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:07:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19872'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'384ms'), (b'x-request-id', b'req_01jaq59jche6caq4nnt1c8b7eq'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6018e038970519-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:07:24,887 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:07:24,887 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:07:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19872', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '384ms', 'x-request-id': 'req_01jaq59jche6caq4nnt1c8b7eq', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6018e038970519-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:07:24,887 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'hello. Hello, Siri.'}, {'role': 'assistant', 'content': "I'm not Siri, I'm a multi-modal AI voice assistant. This is the beginning of our conversation, and I'm not seeing any context or additional information attached. Please feel free to share any questions, topics, or photos you'd like to discuss."}, {'role': 'user', 'content': 'who is the president of the US? Hello Siri, who is the first US president?'}, {'role': 'assistant', 'content': "I'm not Siri, I'm a different AI voice assistant. Our conversation continues - currently, the President of the United States is Joe Biden. The first US president and the first commander-in-chief of the US military is George Washington, who served from 1789 to 1797."}, {'role': 'user', 'content': "and if you're not Siri, who are you?"}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:07:24,887 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:07:25,516 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:07:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19650'), (b'x-ratelimit-reset-requests', b'11.47s'), (b'x-ratelimit-reset-tokens', b'1.05s'), (b'x-request-id', b'req_01jaq59jx3e72vy08r4d8s1n34'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6018e4dc7c0519-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:07:25,516 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:07:25,516 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:07:25,516 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:07:25,516 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:07:25,516 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:07:25,516 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:07:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19650', 'x-ratelimit-reset-requests': '11.47s', 'x-ratelimit-reset-tokens': '1.05s', 'x-request-id': 'req_01jaq59jx3e72vy08r4d8s1n34', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6018e4dc7c0519-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:07:25,802 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I'm an AI assistant that can process and respond to various inputs, including text prompts, audio questions, and visual data attached to our conversation. Since I can integrate with user-media and engage with context, I'm often referred to as a multi-modal AI voice assistant.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:07:25,802 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:07:25,802 - httpcore.connection - DEBUG - close.started
2024-10-21 12:07:25,802 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:07:25,802 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:07:25,936 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CE0E9910>
2024-10-21 12:07:25,936 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B7CAF2D150> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:07:26,072 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CFD2B470>
2024-10-21 12:07:26,072 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:07:26,072 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:07:26,072 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:07:26,072 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:07:26,072 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:07:27,927 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:07:28 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1151'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_db323bbb8c3296a019cc60550aa8e379'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6018ebe89473fc-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:07:27,927 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:07:27,927 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:07:28 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1151', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_db323bbb8c3296a019cc60550aa8e379', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6018ebe89473fc-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:07:27,927 - openai._base_client - DEBUG - request_id: req_db323bbb8c3296a019cc60550aa8e379
2024-10-21 12:07:27,927 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:07:45,169 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:07:56,770 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:07:56,770 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:08:18,018 - faster_whisper - INFO - Processing audio with duration 00:18.228
2024-10-21 12:08:18,683 - faster_whisper - INFO - Detected language 'en' with probability 0.41
2024-10-21 12:08:30,035 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:08:33,259 - faster_whisper - INFO - Processing audio with duration 00:01.324
2024-10-21 12:08:33,873 - faster_whisper - INFO - Detected language 'en' with probability 0.40
2024-10-21 12:08:33,873 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:08:41,737 - comtypes._post_coinit.unknwn - DEBUG - Calling CoUninitialize()
2024-10-21 12:08:41,737 - comtypes._post_coinit.unknwn - DEBUG - CoUninitialize() done.
2024-10-21 12:10:00,380 - __main__ - INFO - Starting main.py
2024-10-21 12:10:00,380 - __main__ - INFO - Chat log file path: C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\chat_history\2024\10\21.log
2024-10-21 12:10:00,380 - __main__ - INFO - API keys loaded successfully
2024-10-21 12:10:00,380 - comtypes - DEBUG - CoInitializeEx(None, 2)
2024-10-21 12:10:00,412 - comtypes.client._code_cache - INFO - Imported existing <module 'comtypes.gen' from 'C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\comtypes\\gen\\__init__.py'>
2024-10-21 12:10:00,412 - comtypes.client._code_cache - INFO - Using writeable comtypes cache directory: 'C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\comtypes\gen'
2024-10-21 12:10:00,459 - comtypes.client - DEBUG - SAPI.SPVoice -> {96749377-3391-11D2-9EE3-00C04F797396}
2024-10-21 12:10:00,459 - comtypes.client - DEBUG - CoCreateInstance({96749377-3391-11D2-9EE3-00C04F797396}, clsctx=None, interface=None)
2024-10-21 12:10:00,465 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IUnknown) ptr=0x1f63ad1ba20 at 1f64e4b6f50>)
2024-10-21 12:10:00,465 - comtypes.client - DEBUG - Does implement IProvideClassInfo
2024-10-21 12:10:00,465 - comtypes.client - DEBUG - Default interface is {269316D8-57BD-11D2-9EEE-00C04F797396}
2024-10-21 12:10:00,465 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1f63ad1ba60 at 1f64e4b7350>
2024-10-21 12:10:00,465 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:10:00,465 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechVoice'>
2024-10-21 12:10:00,465 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechVoice) ptr=0x1f63ad1ba60 at 1f64e4b72d0>
2024-10-21 12:10:00,465 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo) ptr=0x1f63ad1ba80 at 1f64e4b6ed0>
2024-10-21 12:10:00,465 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x1f64c8e2048 at 1f64e4b6fd0>
2024-10-21 12:10:00,465 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x1f64c8e20a0 at 1f64e4b7050>
2024-10-21 12:10:00,465 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x1f64c50eb00 at 1f64e4b7350>
2024-10-21 12:10:00,465 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1f63ad1ba20 at 1f64e4b6f50>
2024-10-21 12:10:00,465 - comtypes.client._events - DEBUG - <POINTER(ISpeechVoice) ptr=0x1f63ad1ba60 at 1f64e4b72d0> using sinkinterface from clsid <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:10:00,465 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo2) ptr=0x1f63ad1ba80 at 1f64e4b6f50>
2024-10-21 12:10:00,465 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>: _ISpeechVoiceEvents.VoiceChange not implemented
2024-10-21 12:10:00,465 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>: _ISpeechVoiceEvents.Bookmark not implemented
2024-10-21 12:10:00,465 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>: _ISpeechVoiceEvents.Sentence not implemented
2024-10-21 12:10:00,475 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>: _ISpeechVoiceEvents.Phoneme not implemented
2024-10-21 12:10:00,475 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>: _ISpeechVoiceEvents.Viseme not implemented
2024-10-21 12:10:00,475 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>: _ISpeechVoiceEvents.AudioLevel not implemented
2024-10-21 12:10:00,475 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>: _ISpeechVoiceEvents.EnginePrivate not implemented
2024-10-21 12:10:00,475 - comtypes.client._events - DEBUG - Start advise <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:10:00,475 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>.QueryInterface({A372ACD1-3BEF-4BBD-8FFB-CB3E2B416AF8}) -> S_OK
2024-10-21 12:10:00,475 - comtypes._comobject - DEBUG - 1 active COM objects: Added   <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>
2024-10-21 12:10:00,475 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>.AddRef() -> 1
2024-10-21 12:10:00,475 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IConnectionPointContainer) ptr=0x1f63ad1ba88 at 1f64e51c750>
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectToken) ptr=0x1f6371e5f50 at 1f64e51c750>)
2024-10-21 12:10:00,521 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x1f6371e5f50 at 1f64e51c750>
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x1f6501606d0 at 1f64e51c750>)
2024-10-21 12:10:00,521 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1f6501af470 at 1f64e51c850>
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - wrap_outparam(<POINTER(IDispatch) ptr=0x1f6501f25f0 at 1f64e51ca50>)
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IDispatch) ptr=0x1f6501f25f0 at 1f64e51ca50>)
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo, trying IProvideClassInfo2
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo/IProvideClassInfo2
2024-10-21 12:10:00,521 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1f64c8e2150 at 1f64e51cc50>
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}
2024-10-21 12:10:00,521 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1f6501f25f0 at 1f64e51cd50>
2024-10-21 12:10:00,521 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechObjectToken) ptr=0x1f6501f25f0 at 1f64e51cc50>
2024-10-21 12:10:00,521 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x1f6501f25f0 at 1f64e51cbd0>
2024-10-21 12:10:00,521 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x1f64c8e2150 at 1f64e51ccd0>
2024-10-21 12:10:00,521 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x1f64c50eb00 at 1f64e51cd50>
2024-10-21 12:10:00,537 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x1f6501f25f0 at 1f64e51ca50>
2024-10-21 12:10:00,537 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IEnumVARIANT) ptr=0x1f6501af470 at 1f64e51c8d0>
2024-10-21 12:10:00,537 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectTokens) ptr=0x1f6501606d0 at 1f64e51c750>
2024-10-21 12:10:00,537 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x1f6501f25f0 at 1f64e51cc50>
2024-10-21 12:10:00,537 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:10:00,537 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:10:00,773 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:10:00,773 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:10:01,136 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2024-10-21 12:10:01,671 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/Systran/faster-whisper-base/revision/main HTTP/1.1" 200 1848
2024-10-21 12:10:02,340 - __main__ - INFO - Siri instance initialized
2024-10-21 12:10:13,622 - faster_whisper - INFO - Processing audio with duration 00:01.834
2024-10-21 12:10:26,352 - faster_whisper - INFO - Detected language 'en' with probability 0.39
2024-10-21 12:10:26,352 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:10:26,463 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:10:26,557 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:10:26,557 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:10:26,668 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E6030>
2024-10-21 12:10:26,668 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F64E51C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:10:26,797 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E5F70>
2024-10-21 12:10:26,797 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:10:26,797 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:10:26,797 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:10:26,797 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:10:26,797 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:10:27,300 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:10:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19881'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'357ms'), (b'x-request-id', b'req_01jaq5f4g5e2ctegj4rtds80ax'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WzeGaSMIKP14LZHIyQTVBeutaCEgpSt9zdOeWTWyyTM-1729501827-1.0.1.1-SKjvJEl0pIUf5dfiC_LFcZp.2qUDR5XF_grGivaxjF84F8mLXz2cCCNejhdfTjbf83oHeYe3pwAg2yFPc_GPUw; path=/; expires=Mon, 21-Oct-24 09:40:27 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601d557fa093ce-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:10:27,300 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:10:27,300 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:10:27,300 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:10:27,300 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:10:27,300 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:10:27,300 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:10:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19881', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '357ms', 'x-request-id': 'req_01jaq5f4g5e2ctegj4rtds80ax', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=WzeGaSMIKP14LZHIyQTVBeutaCEgpSt9zdOeWTWyyTM-1729501827-1.0.1.1-SKjvJEl0pIUf5dfiC_LFcZp.2qUDR5XF_grGivaxjF84F8mLXz2cCCNejhdfTjbf83oHeYe3pwAg2yFPc_GPUw; path=/; expires=Mon, 21-Oct-24 09:40:27 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8d601d557fa093ce-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:10:27,309 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:10:27,309 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:10:27,309 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:10:27,309 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:10:27,309 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:10:27,309 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:10:27,309 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:10:27,851 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:10:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19827'), (b'x-ratelimit-reset-requests', b'11.477s'), (b'x-ratelimit-reset-tokens', b'519ms'), (b'x-request-id', b'req_01jaq5f50hejqsyb6c828dte1w'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601d58bb6993ce-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:10:27,851 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:10:27,851 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:10:27,851 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:10:27,851 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:10:27,851 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:10:27,851 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:10:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19827', 'x-ratelimit-reset-requests': '11.477s', 'x-ratelimit-reset-tokens': '519ms', 'x-request-id': 'req_01jaq5f50hejqsyb6c828dte1w', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d601d58bb6993ce-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:10:28,147 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "What can I assist you with, or would you like to discuss or provide more context such as providing an image which may help generate a more accurate and personalized response, don't worry though the conversation can proceed without.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:10:28,147 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:10:28,147 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:10:28,322 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F653216270>
2024-10-21 12:10:28,322 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F64E51D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:10:28,463 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F653216180>
2024-10-21 12:10:28,464 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:10:28,466 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:10:28,466 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:10:28,467 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:10:28,467 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:10:30,747 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:10:31 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1295'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_d7bfe365e6df3e71286281ea402f2144'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Yp3tYXfW0IhEx_DL6Xm4w9qXceI7RbTJLBxFIvI0gec-1729501831-1.0.1.1-f.JZlNvY_YE2ESfcryMlzoRHwzfeAGzEbGF.m3llhTUiFs5iYDe8LHX.18E8k72onRbaDd8Jt_R1kj8LdRa0fA; path=/; expires=Mon, 21-Oct-24 09:40:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=OyDQVnTU1JNZIOKIZsPdwvmcE1MBfe0fuA_s5fs5O3Q-1729501831260-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601d5fe9fe73ad-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:10:30,747 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:10:30,747 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers([('date', 'Mon, 21 Oct 2024 09:10:31 GMT'), ('content-type', 'audio/pcm'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'viva-ai-g59lkf'), ('openai-processing-ms', '1295'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-reset-requests', '120ms'), ('x-request-id', 'req_d7bfe365e6df3e71286281ea402f2144'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Yp3tYXfW0IhEx_DL6Xm4w9qXceI7RbTJLBxFIvI0gec-1729501831-1.0.1.1-f.JZlNvY_YE2ESfcryMlzoRHwzfeAGzEbGF.m3llhTUiFs5iYDe8LHX.18E8k72onRbaDd8Jt_R1kj8LdRa0fA; path=/; expires=Mon, 21-Oct-24 09:40:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=OyDQVnTU1JNZIOKIZsPdwvmcE1MBfe0fuA_s5fs5O3Q-1729501831260-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8d601d5fe9fe73ad-JNB'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-10-21 12:10:30,747 - openai._base_client - DEBUG - request_id: req_d7bfe365e6df3e71286281ea402f2144
2024-10-21 12:10:30,747 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:10:45,069 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:10:45,069 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:10:45,069 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:11:00,899 - faster_whisper - INFO - Processing audio with duration 00:13.375
2024-10-21 12:11:03,786 - faster_whisper - INFO - Detected language 'en' with probability 0.76
2024-10-21 12:11:03,786 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:11:03,959 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'I want to know if what model you are based on.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:11:03,974 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:11:03,974 - httpcore.connection - DEBUG - close.started
2024-10-21 12:11:03,974 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:11:03,974 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:11:04,089 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E7710>
2024-10-21 12:11:04,090 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F64E51C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:11:04,219 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E6660>
2024-10-21 12:11:04,220 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:11:04,221 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:11:04,221 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:11:04,221 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:11:04,221 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:11:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19870'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'390ms'), (b'x-request-id', b'req_01jaq5g91ve0jvekbqjtp0x3y9'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601e3f5be94f6f-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:11:04,783 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:11:04,783 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:11:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19870', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '390ms', 'x-request-id': 'req_01jaq5g91ve0jvekbqjtp0x3y9', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d601e3f5be94f6f-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:11:04,783 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': "What can I assist you with, or would you like to discuss or provide more context such as providing an image which may help generate a more accurate and personalized response, don't worry though the conversation can proceed without."}, {'role': 'user', 'content': 'I want to know if what model you are based on.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:11:04,783 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:11:05,463 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:11:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19749'), (b'x-ratelimit-reset-requests', b'11.442999999s'), (b'x-ratelimit-reset-tokens', b'753ms'), (b'x-request-id', b'req_01jaq5g9kaf7x86r1gyegt7jv5'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601e42ef3e4f6f-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:11:05,463 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:11:05,463 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:11:05,463 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:11:05,463 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:11:05,463 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:11:05,463 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:11:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19749', 'x-ratelimit-reset-requests': '11.442999999s', 'x-ratelimit-reset-tokens': '753ms', 'x-request-id': 'req_01jaq5g9kaf7x86r1gyegt7jv5', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d601e42ef3e4f6f-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:11:05,637 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I'm a multi-modal AI voice assistant based on the combination of various transformer models including T5 and BERT, fine-tuned on a large dataset of text from the internet and integrated with computer vision capabilities to process images and text from screenshots or webcam captures for context.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:11:05,642 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:11:05,642 - httpcore.connection - DEBUG - close.started
2024-10-21 12:11:05,642 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:11:05,642 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:11:05,762 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F653217DD0>
2024-10-21 12:11:05,762 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F64E51D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:11:05,882 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6532175C0>
2024-10-21 12:11:05,882 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:11:05,882 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:11:05,882 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:11:05,882 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:11:05,882 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:11:07,248 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:11:07 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'757'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_819624b4c4cf06de102cdd6958f05c15'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601e49b8c1740c-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:11:07,248 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:11:07,253 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:11:07 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '757', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_819624b4c4cf06de102cdd6958f05c15', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d601e49b8c1740c-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:11:07,253 - openai._base_client - DEBUG - request_id: req_819624b4c4cf06de102cdd6958f05c15
2024-10-21 12:11:07,253 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:11:25,866 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:11:25,866 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:11:25,867 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:11:27,484 - faster_whisper - INFO - Processing audio with duration 00:01.277
2024-10-21 12:11:28,349 - faster_whisper - INFO - Detected language 'en' with probability 0.41
2024-10-21 12:11:28,352 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:11:28,519 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:11:28,519 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:11:28,519 - httpcore.connection - DEBUG - close.started
2024-10-21 12:11:28,519 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:11:28,519 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:11:28,630 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E5E80>
2024-10-21 12:11:28,631 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F64E51C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:11:28,762 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E70E0>
2024-10-21 12:11:28,762 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:11:28,762 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:11:28,762 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:11:28,762 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:11:28,762 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:11:29,232 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:11:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19881'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'357ms'), (b'x-request-id', b'req_01jaq5h111e9hrgmfs72ng27jv'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601ed8cf399e94-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:11:29,232 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:11:29,232 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:11:29,232 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:11:29,232 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:11:29,232 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:11:29,232 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:11:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19881', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '357ms', 'x-request-id': 'req_01jaq5h111e9hrgmfs72ng27jv', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d601ed8cf399e94-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:11:29,248 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': "What can I assist you with, or would you like to discuss or provide more context such as providing an image which may help generate a more accurate and personalized response, don't worry though the conversation can proceed without."}, {'role': 'user', 'content': 'I want to know if what model you are based on.'}, {'role': 'assistant', 'content': "I'm a multi-modal AI voice assistant based on the combination of various transformer models including T5 and BERT, fine-tuned on a large dataset of text from the internet and integrated with computer vision capabilities to process images and text from screenshots or webcam captures for context."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:11:29,248 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:11:29,248 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:11:29,248 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:11:29,248 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:11:29,248 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:11:29,248 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:11:29,849 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:11:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19666'), (b'x-ratelimit-reset-requests', b'11.532s'), (b'x-ratelimit-reset-tokens', b'1.002s'), (b'x-request-id', b'req_01jaq5h1fpfyfarg3wszr42v0z'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601edbcbb29e94-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:11:29,849 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:11:29,849 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:11:29,849 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:11:29,849 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:11:29,849 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:11:29,849 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:11:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19666', 'x-ratelimit-reset-requests': '11.532s', 'x-ratelimit-reset-tokens': '1.002s', 'x-request-id': 'req_01jaq5h1fpfyfarg3wszr42v0z', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d601edbcbb29e94-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:11:30,017 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'As a multi-modal AI voice assistant, my primary architecture combines elements of natural language processing and computer vision to provide more accurate and informative responses to a wider range of questions and prompts, utilizing a combination of BERT and T5 to form my foundation.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:11:30,017 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:11:30,017 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:11:30,017 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:11:30,017 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:11:30,017 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:11:30,017 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:11:31,536 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:11:31 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'943'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_0013e766061bc70a13bfd5400709a45f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601ee0bf18740c-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:11:31,536 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:11:31,536 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:11:31 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '943', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_0013e766061bc70a13bfd5400709a45f', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d601ee0bf18740c-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:11:31,536 - openai._base_client - DEBUG - request_id: req_0013e766061bc70a13bfd5400709a45f
2024-10-21 12:11:31,536 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:11:48,953 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:11:56,602 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:11:56,602 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:12:05,109 - faster_whisper - INFO - Processing audio with duration 00:02.694
2024-10-21 12:12:05,741 - faster_whisper - INFO - Detected language 'en' with probability 0.54
2024-10-21 12:12:05,741 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:12:05,882 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.0 (-1.107911 < -1.000000)
2024-10-21 12:12:06,150 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.2 (-1.431759 < -1.000000)
2024-10-21 12:12:06,482 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.4 (-1.435050 < -1.000000)
2024-10-21 12:12:07,907 - faster_whisper - DEBUG - Compression ratio threshold is not met with temperature 0.6 (13.382979 > 2.400000)
2024-10-21 12:12:08,255 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.8 (-1.944614 < -1.000000)
2024-10-21 12:12:08,491 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 1.0 (-2.275364 < -1.000000)
2024-10-21 12:12:08,491 - faster_whisper - DEBUG - Reset prompt. prompt_reset_on_temperature threshold is met 1.000000 > 0.500000
2024-10-21 12:12:08,491 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': "We'll see you in the next one."}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:12:08,491 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:12:08,491 - httpcore.connection - DEBUG - close.started
2024-10-21 12:12:08,491 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:12:08,491 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:12:08,602 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E73B0>
2024-10-21 12:12:08,602 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F64E51C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:12:08,738 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E6000>
2024-10-21 12:12:08,738 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:12:08,738 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:12:08,738 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:12:08,738 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:12:08,738 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:12:09,239 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:12:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19874'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'378ms'), (b'x-request-id', b'req_01jaq5j82cemz8cskws01tskz3'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601fd2a8fa4eb5-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:12:09,239 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:12:09,239 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:12:09,247 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:12:09,247 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:12:09,248 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:12:09,248 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:12:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19874', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '378ms', 'x-request-id': 'req_01jaq5j82cemz8cskws01tskz3', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d601fd2a8fa4eb5-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:12:09,248 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': "What can I assist you with, or would you like to discuss or provide more context such as providing an image which may help generate a more accurate and personalized response, don't worry though the conversation can proceed without."}, {'role': 'user', 'content': 'I want to know if what model you are based on.'}, {'role': 'assistant', 'content': "I'm a multi-modal AI voice assistant based on the combination of various transformer models including T5 and BERT, fine-tuned on a large dataset of text from the internet and integrated with computer vision capabilities to process images and text from screenshots or webcam captures for context."}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'As a multi-modal AI voice assistant, my primary architecture combines elements of natural language processing and computer vision to provide more accurate and informative responses to a wider range of questions and prompts, utilizing a combination of BERT and T5 to form my foundation.'}, {'role': 'user', 'content': "We'll see you in the next one."}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:12:09,248 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:12:09,248 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:12:09,248 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:12:09,248 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:12:09,248 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:12:09,248 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:12:09,915 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:12:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19578'), (b'x-ratelimit-reset-requests', b'11.461999999s'), (b'x-ratelimit-reset-tokens', b'1.266s'), (b'x-request-id', b'req_01jaq5j8k7fsrajp2s9bzb4ayh'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601fd60ecc4eb5-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:12:09,915 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:12:09,915 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:12:09,915 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:12:09,915 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:12:09,915 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:12:09,915 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:12:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19578', 'x-ratelimit-reset-requests': '11.461999999s', 'x-ratelimit-reset-tokens': '1.266s', 'x-request-id': 'req_01jaq5j8k7fsrajp2s9bzb4ayh', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d601fd60ecc4eb5-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:12:10,099 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "Sounds good, I'll be ready for our next conversation.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:12:10,099 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:12:10,099 - httpcore.connection - DEBUG - close.started
2024-10-21 12:12:10,099 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:12:10,099 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:12:10,228 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F653216600>
2024-10-21 12:12:10,238 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F64E51D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:12:10,371 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F653215A60>
2024-10-21 12:12:10,371 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:12:10,371 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:12:10,371 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:12:10,371 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:12:10,371 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:12:11,806 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:12:12 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'778'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_ad940687ac62c6f04c008d193a2186bc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601fdcef6e4ebc-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:12:11,806 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:12:11,806 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:12:12 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '778', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_ad940687ac62c6f04c008d193a2186bc', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d601fdcef6e4ebc-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:12:11,806 - openai._base_client - DEBUG - request_id: req_ad940687ac62c6f04c008d193a2186bc
2024-10-21 12:12:11,806 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:12:14,662 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:12:14,662 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:12:14,662 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:12:25,458 - comtypes._post_coinit.unknwn - DEBUG - Calling CoUninitialize()
2024-10-21 12:12:25,458 - comtypes._post_coinit.unknwn - DEBUG - CoUninitialize() done.
2024-10-21 12:12:30,503 - __main__ - INFO - Starting main.py
2024-10-21 12:12:30,519 - __main__ - INFO - Chat log file path: C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\chat_history\2024\10\21.log
2024-10-21 12:12:30,519 - __main__ - INFO - API keys loaded successfully
2024-10-21 12:12:30,524 - comtypes - DEBUG - CoInitializeEx(None, 2)
2024-10-21 12:12:30,551 - comtypes.client._code_cache - INFO - Imported existing <module 'comtypes.gen' from 'C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\comtypes\\gen\\__init__.py'>
2024-10-21 12:12:30,551 - comtypes.client._code_cache - INFO - Using writeable comtypes cache directory: 'C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\comtypes\gen'
2024-10-21 12:12:30,598 - comtypes.client - DEBUG - SAPI.SPVoice -> {96749377-3391-11D2-9EE3-00C04F797396}
2024-10-21 12:12:30,598 - comtypes.client - DEBUG - CoCreateInstance({96749377-3391-11D2-9EE3-00C04F797396}, clsctx=None, interface=None)
2024-10-21 12:12:30,598 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IUnknown) ptr=0x256da11ba20 at 256ed8f6f50>)
2024-10-21 12:12:30,598 - comtypes.client - DEBUG - Does implement IProvideClassInfo
2024-10-21 12:12:30,598 - comtypes.client - DEBUG - Default interface is {269316D8-57BD-11D2-9EEE-00C04F797396}
2024-10-21 12:12:30,598 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x256da11ba60 at 256ed8f7350>
2024-10-21 12:12:30,598 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:12:30,598 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechVoice'>
2024-10-21 12:12:30,598 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechVoice) ptr=0x256da11ba60 at 256ed8f72d0>
2024-10-21 12:12:30,598 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo) ptr=0x256da11ba80 at 256ed8f6ed0>
2024-10-21 12:12:30,598 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x256ebca55e8 at 256ed8f6fd0>
2024-10-21 12:12:30,598 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x256ebca5640 at 256ed8f7050>
2024-10-21 12:12:30,613 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x256ebecddd0 at 256ed8f7350>
2024-10-21 12:12:30,613 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x256da11ba20 at 256ed8f6f50>
2024-10-21 12:12:30,613 - comtypes.client._events - DEBUG - <POINTER(ISpeechVoice) ptr=0x256da11ba60 at 256ed8f72d0> using sinkinterface from clsid <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:12:30,613 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo2) ptr=0x256da11ba80 at 256ed8f6f50>
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>: _ISpeechVoiceEvents.VoiceChange not implemented
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>: _ISpeechVoiceEvents.Bookmark not implemented
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>: _ISpeechVoiceEvents.Sentence not implemented
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>: _ISpeechVoiceEvents.Phoneme not implemented
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>: _ISpeechVoiceEvents.Viseme not implemented
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>: _ISpeechVoiceEvents.AudioLevel not implemented
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>: _ISpeechVoiceEvents.EnginePrivate not implemented
2024-10-21 12:12:30,613 - comtypes.client._events - DEBUG - Start advise <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>.QueryInterface({A372ACD1-3BEF-4BBD-8FFB-CB3E2B416AF8}) -> S_OK
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - 1 active COM objects: Added   <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>.AddRef() -> 1
2024-10-21 12:12:30,624 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IConnectionPointContainer) ptr=0x256da11ba88 at 256ed95c750>
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectToken) ptr=0x256da1f2d30 at 256ed95c750>)
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x256da1f2d30 at 256ed95c750>
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x256ec70aad0 at 256ed95c750>)
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x256edeb1150 at 256ed95c850>
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - wrap_outparam(<POINTER(IDispatch) ptr=0x256ede64950 at 256ed95ca50>)
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IDispatch) ptr=0x256ede64950 at 256ed95ca50>)
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo, trying IProvideClassInfo2
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo/IProvideClassInfo2
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x256ebca56f0 at 256ed95cc50>
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x256ede64950 at 256ed95cd50>
2024-10-21 12:12:30,676 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechObjectToken) ptr=0x256ede64950 at 256ed95cc50>
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x256ede64950 at 256ed95cbd0>
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x256ebca56f0 at 256ed95ccd0>
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x256ebecddd0 at 256ed95cd50>
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x256ede64950 at 256ed95ca50>
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IEnumVARIANT) ptr=0x256edeb1150 at 256ed95c8d0>
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectTokens) ptr=0x256ec70aad0 at 256ed95c750>
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x256ede64950 at 256ed95cc50>
2024-10-21 12:12:30,676 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:12:30,676 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:12:30,912 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:12:30,912 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:12:31,273 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2024-10-21 12:12:31,871 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/Systran/faster-whisper-base/revision/main HTTP/1.1" 200 1848
2024-10-21 12:12:32,374 - __main__ - INFO - Siri instance initialized
2024-10-21 12:12:40,209 - faster_whisper - INFO - Processing audio with duration 00:01.834
2024-10-21 12:12:43,675 - faster_whisper - INFO - Detected language 'en' with probability 0.38
2024-10-21 12:12:43,675 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:12:43,801 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:12:43,879 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:12:43,879 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:12:44,013 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E9CD0>
2024-10-21 12:12:44,013 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:12:44,142 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F0907CE0>
2024-10-21 12:12:44,142 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:12:44,142 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:12:44,142 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:12:44,147 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:12:44,147 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:12:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19881'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'357ms'), (b'x-request-id', b'req_01jaq5katse16993a3k47dj4zr'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cdBVonBffTnLSMRT2Ar5iU.JJOxvoHF6jeVFYxd6SCY-1729501965-1.0.1.1-UInXDxqRDB4tko_r0Nj6tpTCQRoN9ZO5xRB304ykaVH4zdWbDrhXhs1uwNfvCRGF6ORUtWDMpp9YE5GEy29BNA; path=/; expires=Mon, 21-Oct-24 09:42:45 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6020afee7d7404-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:12:44,930 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:12:44,930 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:12:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19881', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '357ms', 'x-request-id': 'req_01jaq5katse16993a3k47dj4zr', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=cdBVonBffTnLSMRT2Ar5iU.JJOxvoHF6jeVFYxd6SCY-1729501965-1.0.1.1-UInXDxqRDB4tko_r0Nj6tpTCQRoN9ZO5xRB304ykaVH4zdWbDrhXhs1uwNfvCRGF6ORUtWDMpp9YE5GEy29BNA; path=/; expires=Mon, 21-Oct-24 09:42:45 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8d6020afee7d7404-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:12:44,930 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:12:44,930 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:12:45,527 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:12:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19827'), (b'x-ratelimit-reset-requests', b'11.411s'), (b'x-ratelimit-reset-tokens', b'519ms'), (b'x-request-id', b'req_01jaq5kbd6e9p9tef06hn3q6be'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6020b4dcdb7404-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:12:45,528 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:12:45,528 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:12:45,528 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:12:45,529 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:12:45,529 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:12:45,530 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:12:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19827', 'x-ratelimit-reset-requests': '11.411s', 'x-ratelimit-reset-tokens': '519ms', 'x-request-id': 'req_01jaq5kbd6e9p9tef06hn3q6be', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6020b4dcdb7404-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:12:45,795 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:12:45,795 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:12:45,795 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:12:45,913 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269DF40>
2024-10-21 12:12:45,913 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:12:46,086 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269DE50>
2024-10-21 12:12:46,086 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:12:46,089 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:12:46,089 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:12:46,089 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:12:46,089 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:12:47,928 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:12:48 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1223'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_d18c338b62cb2c820b9bc83bfea9ccf6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=kflyyrAD8OojjpvFyg8b9.RsJ3CS_qVg_JtVPG2s_vk-1729501968-1.0.1.1-3eRM6JrBLXFr4UTyDRNJpEIliHSIScprP92KOiXbjRaXshoCFnTiVT3AJeC.N.BPq7Wa2PLPcNeap9.vAsKfjQ; path=/; expires=Mon, 21-Oct-24 09:42:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=dRea2fCGFH6B.FQ72e3TrK.6pXSMK6hC6OgSUbQotyw-1729501968467-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6020bc1e5c73e5-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:12:47,944 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:12:47,944 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers([('date', 'Mon, 21 Oct 2024 09:12:48 GMT'), ('content-type', 'audio/pcm'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'viva-ai-g59lkf'), ('openai-processing-ms', '1223'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-reset-requests', '120ms'), ('x-request-id', 'req_d18c338b62cb2c820b9bc83bfea9ccf6'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=kflyyrAD8OojjpvFyg8b9.RsJ3CS_qVg_JtVPG2s_vk-1729501968-1.0.1.1-3eRM6JrBLXFr4UTyDRNJpEIliHSIScprP92KOiXbjRaXshoCFnTiVT3AJeC.N.BPq7Wa2PLPcNeap9.vAsKfjQ; path=/; expires=Mon, 21-Oct-24 09:42:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=dRea2fCGFH6B.FQ72e3TrK.6pXSMK6hC6OgSUbQotyw-1729501968467-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8d6020bc1e5c73e5-JNB'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-10-21 12:12:47,944 - openai._base_client - DEBUG - request_id: req_d18c338b62cb2c820b9bc83bfea9ccf6
2024-10-21 12:12:47,944 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:13:17,395 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:13:17,395 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:13:17,395 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:13:33,405 - faster_whisper - INFO - Processing audio with duration 00:11.935
2024-10-21 12:13:34,047 - faster_whisper - INFO - Detected language 'en' with probability 0.85
2024-10-21 12:13:34,047 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:13:34,195 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Which is the longest you find the world?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:13:34,195 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:13:34,195 - httpcore.connection - DEBUG - close.started
2024-10-21 12:13:34,195 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:13:34,195 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:13:34,325 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E92E0>
2024-10-21 12:13:34,325 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:13:34,462 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EA1B0>
2024-10-21 12:13:34,462 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:13:34,462 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:13:34,462 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:13:34,462 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:13:34,462 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:13:34,979 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:13:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19871'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'387ms'), (b'x-request-id', b'req_01jaq5mvshebfavymvt102794g'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6021ea6cfd740d-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:13:34,979 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:13:34,979 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:13:34,979 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:13:34,979 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:13:34,979 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:13:34,979 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:13:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19871', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '387ms', 'x-request-id': 'req_01jaq5mvshebfavymvt102794g', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6021ea6cfd740d-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:13:34,979 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:13:34,995 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:13:34,996 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:13:34,996 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:13:34,996 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:13:34,996 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:13:34,996 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:13:35,618 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:13:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19690'), (b'x-ratelimit-reset-requests', b'11.484s'), (b'x-ratelimit-reset-tokens', b'930ms'), (b'x-request-id', b'req_01jaq5mw9tfhj9qjz9m7yks7r7'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6021eda8a6740d-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:13:35,618 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:13:35,618 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:13:35,618 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:13:35,618 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:13:35,618 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:13:35,618 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:13:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19690', 'x-ratelimit-reset-requests': '11.484s', 'x-ratelimit-reset-tokens': '930ms', 'x-request-id': 'req_01jaq5mw9tfhj9qjz9m7yks7r7', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6021eda8a6740d-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:13:35,796 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:13:35,796 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:13:35,796 - httpcore.connection - DEBUG - close.started
2024-10-21 12:13:35,796 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:13:35,796 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:13:35,942 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269FA10>
2024-10-21 12:13:35,942 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:13:36,051 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269F410>
2024-10-21 12:13:36,051 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:13:36,053 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:13:36,053 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:13:36,053 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:13:36,053 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:13:39,393 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:13:39 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'2100'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_92cbc3c6b7cbbdc2b469bb4e374bb4ed'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6021f44b0573ad-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:13:39,393 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:13:39,393 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:13:39 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '2100', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_92cbc3c6b7cbbdc2b469bb4e374bb4ed', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6021f44b0573ad-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:13:39,393 - openai._base_client - DEBUG - request_id: req_92cbc3c6b7cbbdc2b469bb4e374bb4ed
2024-10-21 12:13:39,393 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:14:02,898 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:14:02,898 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:14:02,898 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:14:19,970 - faster_whisper - INFO - Processing audio with duration 00:13.375
2024-10-21 12:14:20,636 - faster_whisper - INFO - Detected language 'en' with probability 0.79
2024-10-21 12:14:20,636 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:14:20,761 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:14:20,761 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:14:20,761 - httpcore.connection - DEBUG - close.started
2024-10-21 12:14:20,761 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:14:20,761 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:14:20,895 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E95B0>
2024-10-21 12:14:20,896 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:14:21,012 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E9340>
2024-10-21 12:14:21,013 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:14:21,014 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:14:21,014 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:14:21,014 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:14:21,015 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:14:21,562 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:14:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19870'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'390ms'), (b'x-request-id', b'req_01jaq5p9a5fg7a70qjxvwbx0qj'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60230ddfb47402-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:14:21,562 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:14:21,562 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:14:21,562 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:14:21,562 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:14:21,562 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:14:21,562 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:14:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19870', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '390ms', 'x-request-id': 'req_01jaq5p9a5fg7a70qjxvwbx0qj', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60230ddfb47402-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:14:21,573 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:14:21,573 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:14:21,577 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:14:21,578 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:14:21,578 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:14:21,578 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:14:21,578 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:14:22,226 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:14:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19584'), (b'x-ratelimit-reset-requests', b'11.524s'), (b'x-ratelimit-reset-tokens', b'1.248s'), (b'x-request-id', b'req_01jaq5p9s3f86ra2mhp20fs9nn'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602310cc837402-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:14:22,226 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:14:22,226 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:14:22,227 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:14:22,228 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:14:22,228 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:14:22,228 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:14:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19584', 'x-ratelimit-reset-requests': '11.524s', 'x-ratelimit-reset-tokens': '1.248s', 'x-request-id': 'req_01jaq5p9s3f86ra2mhp20fs9nn', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602310cc837402-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:14:22,396 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:14:22,396 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:14:22,396 - httpcore.connection - DEBUG - close.started
2024-10-21 12:14:22,396 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:14:22,396 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:14:22,525 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269C950>
2024-10-21 12:14:22,525 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:14:22,668 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269CC20>
2024-10-21 12:14:22,668 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:14:22,668 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:14:22,668 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:14:22,668 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:14:22,668 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:14:24,104 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:14:24 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'911'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_2b4735701e629b786ca00c28b9c46599'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602317acff73dd-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:14:24,104 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:14:24,104 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:14:24 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '911', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_2b4735701e629b786ca00c28b9c46599', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602317acff73dd-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:14:24,118 - openai._base_client - DEBUG - request_id: req_2b4735701e629b786ca00c28b9c46599
2024-10-21 12:14:24,118 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:14:51,389 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:14:51,389 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:14:51,389 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:15:07,664 - faster_whisper - INFO - Processing audio with duration 00:13.421
2024-10-21 12:15:08,323 - faster_whisper - INFO - Detected language 'en' with probability 0.28
2024-10-21 12:15:08,323 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:15:08,511 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:15:08,511 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:15:08,511 - httpcore.connection - DEBUG - close.started
2024-10-21 12:15:08,511 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:15:08,511 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:15:08,887 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E90A0>
2024-10-21 12:15:08,887 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:15:09,193 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EA480>
2024-10-21 12:15:09,193 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:15:09,194 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:15:09,194 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:15:09,194 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:15:09,194 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:15:09,693 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:15:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19869'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'393ms'), (b'x-request-id', b'req_01jaq5qr99e50av37bnynmbavf'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60243a6b13740e-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:15:09,694 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:15:09,694 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:15:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19869', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '393ms', 'x-request-id': 'req_01jaq5qr99e50av37bnynmbavf', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60243a6b13740e-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:15:09,694 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:15:09,694 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:15:11,218 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:15:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19453'), (b'x-ratelimit-reset-requests', b'10.68s'), (b'x-ratelimit-reset-tokens', b'1.641s'), (b'x-request-id', b'req_01jaq5qsjke10bs4q539et3p87'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60243daf69740e-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:15:11,218 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:15:11,218 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:15:11,218 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:15:11,218 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:15:11,218 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:15:11,234 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:15:11 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19453', 'x-ratelimit-reset-requests': '10.68s', 'x-ratelimit-reset-tokens': '1.641s', 'x-request-id': 'req_01jaq5qsjke10bs4q539et3p87', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60243daf69740e-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:15:11,394 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:15:11,394 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:15:11,394 - httpcore.connection - DEBUG - close.started
2024-10-21 12:15:11,394 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:15:11,394 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:15:11,525 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269EF00>
2024-10-21 12:15:11,525 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:15:11,649 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269ECF0>
2024-10-21 12:15:11,649 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:15:11,649 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:15:11,649 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:15:11,649 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:15:11,655 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:15:13,795 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:15:14 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1579'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_4f7881b93e68e4e1a9d1b13348e3284c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602449dd364ec4-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:15:13,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:15:13,795 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:15:14 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1579', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_4f7881b93e68e4e1a9d1b13348e3284c', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602449dd364ec4-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:15:13,795 - openai._base_client - DEBUG - request_id: req_4f7881b93e68e4e1a9d1b13348e3284c
2024-10-21 12:15:13,795 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:15:47,881 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:15:47,881 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:15:47,881 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:16:07,090 - faster_whisper - INFO - Processing audio with duration 00:17.299
2024-10-21 12:16:07,947 - faster_whisper - INFO - Detected language 'en' with probability 0.65
2024-10-21 12:16:07,947 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:16:08,151 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:16:08,151 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:16:08,151 - httpcore.connection - DEBUG - close.started
2024-10-21 12:16:08,151 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:16:08,151 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:16:08,264 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EAB70>
2024-10-21 12:16:08,265 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:16:08,457 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EB7A0>
2024-10-21 12:16:08,457 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:16:08,457 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:16:08,457 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:16:08,457 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:16:08,457 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:16:08,958 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:16:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19864'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'408ms'), (b'x-request-id', b'req_01jaq5sj5re1hrsg8rn6te15p1'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6025acee7773f1-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:16:08,959 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:16:08,959 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:16:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19864', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '408ms', 'x-request-id': 'req_01jaq5sj5re1hrsg8rn6te15p1', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6025acee7773f1-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:16:08,959 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:16:08,959 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:16:09,650 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:16:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19289'), (b'x-ratelimit-reset-requests', b'11.469s'), (b'x-ratelimit-reset-tokens', b'2.133s'), (b'x-request-id', b'req_01jaq5sjnrfatvf3a94jg68yjf'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6025b01bdd73f1-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:16:09,650 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:16:09,650 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:16:09,650 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:16:09,650 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:16:09,650 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:16:09,650 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:16:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19289', 'x-ratelimit-reset-requests': '11.469s', 'x-ratelimit-reset-tokens': '2.133s', 'x-request-id': 'req_01jaq5sjnrfatvf3a94jg68yjf', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6025b01bdd73f1-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:16:09,826 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:16:09,826 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:16:09,826 - httpcore.connection - DEBUG - close.started
2024-10-21 12:16:09,826 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:16:09,826 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:16:09,956 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269F350>
2024-10-21 12:16:09,956 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:16:10,090 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269F9E0>
2024-10-21 12:16:10,090 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:16:10,090 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:16:10,090 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:16:10,090 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:16:10,090 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:16:12,845 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:16:13 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1706'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_1468df37b393345f9ce16ecb0b2dfd50'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6025b71d35738c-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:16:12,845 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:16:12,845 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:16:13 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1706', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_1468df37b393345f9ce16ecb0b2dfd50', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6025b71d35738c-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:16:12,851 - openai._base_client - DEBUG - request_id: req_1468df37b393345f9ce16ecb0b2dfd50
2024-10-21 12:16:12,851 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:16:34,282 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:16:34,282 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:16:34,282 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:16:50,317 - faster_whisper - INFO - Processing audio with duration 00:15.604
2024-10-21 12:16:51,106 - faster_whisper - INFO - Detected language 'en' with probability 0.45
2024-10-21 12:16:51,106 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:16:51,280 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:16:51,280 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:16:51,280 - httpcore.connection - DEBUG - close.started
2024-10-21 12:16:51,280 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:16:51,280 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:16:51,383 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EBC80>
2024-10-21 12:16:51,383 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:16:51,541 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EA150>
2024-10-21 12:16:51,541 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:16:51,541 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:16:51,541 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:16:51,556 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:16:51,556 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:16:52,021 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:16:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19868'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'396ms'), (b'x-request-id', b'req_01jaq5tw7sf14rxhpmcpar0d6h'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6026ba3fa24eb6-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:16:52,024 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:16:52,025 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:16:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19868', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '396ms', 'x-request-id': 'req_01jaq5tw7sf14rxhpmcpar0d6h', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6026ba3fa24eb6-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:16:52,025 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}, {'role': 'assistant', 'content': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?"}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:16:52,025 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:16:52,804 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:16:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19180'), (b'x-ratelimit-reset-requests', b'11.494999999s'), (b'x-ratelimit-reset-tokens', b'2.46s'), (b'x-request-id', b'req_01jaq5twptesm8y7sy4qh0vbep'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6026bd2ba64eb6-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:16:52,804 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:16:52,804 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:16:52,804 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:16:52,804 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:16:52,804 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:16:52,804 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:16:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19180', 'x-ratelimit-reset-requests': '11.494999999s', 'x-ratelimit-reset-tokens': '2.46s', 'x-request-id': 'req_01jaq5twptesm8y7sy4qh0vbep', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6026bd2ba64eb6-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:16:52,975 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'Directions from Nairobi City to Mombasa City typically involve driving via the Mombasa Highway or A109 highway, which is a major road network connecting the two cities. The journey is approximately 480 kilometers and usually takes around 8-10 hours by car, depending on traffic and road conditions. You can take regular breaks along the way through towns like Machakos, Kitale and Voi and it is also advisable to consider hiring a guided tour or driving with a local.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:16:52,975 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:16:52,975 - httpcore.connection - DEBUG - close.started
2024-10-21 12:16:52,975 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:16:52,975 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:16:53,106 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269CB00>
2024-10-21 12:16:53,106 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:16:53,217 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269D520>
2024-10-21 12:16:53,217 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:16:53,217 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:16:53,217 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:16:53,217 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:16:53,217 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:16:56,776 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:16:56 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1385'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_1e8819260d5f3fa3c769a59669061899'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6026c4cbae051d-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:16:56,792 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:16:56,792 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:16:56 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1385', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_1e8819260d5f3fa3c769a59669061899', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6026c4cbae051d-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:16:56,792 - openai._base_client - DEBUG - request_id: req_1e8819260d5f3fa3c769a59669061899
2024-10-21 12:16:56,792 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:17:27,263 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:17:27,263 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:17:27,263 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:18:01,367 - faster_whisper - INFO - Processing audio with duration 00:12.098
2024-10-21 12:18:02,050 - faster_whisper - INFO - Detected language 'en' with probability 0.79
2024-10-21 12:18:02,050 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:18:02,207 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': "Do you have access to Google Maps API's?"}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:18:02,207 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:18:02,207 - httpcore.connection - DEBUG - close.started
2024-10-21 12:18:02,207 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:18:02,207 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:18:02,787 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E9D60>
2024-10-21 12:18:02,787 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:18:02,907 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EACC0>
2024-10-21 12:18:02,907 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:18:02,907 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:18:02,907 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:18:02,907 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:18:02,907 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:18:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19871'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'387ms'), (b'x-request-id', b'req_01jaq5x1y4f8rt7bjs4xqnrnkp'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6028783c81053e-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:18:03,390 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:18:03,390 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:18:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19871', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '387ms', 'x-request-id': 'req_01jaq5x1y4f8rt7bjs4xqnrnkp', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6028783c81053e-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:18:03,390 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}, {'role': 'assistant', 'content': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?"}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}, {'role': 'assistant', 'content': 'Directions from Nairobi City to Mombasa City typically involve driving via the Mombasa Highway or A109 highway, which is a major road network connecting the two cities. The journey is approximately 480 kilometers and usually takes around 8-10 hours by car, depending on traffic and road conditions. You can take regular breaks along the way through towns like Machakos, Kitale and Voi and it is also advisable to consider hiring a guided tour or driving with a local.'}, {'role': 'user', 'content': "Do you have access to Google Maps API's?"}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:18:03,390 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:18:04,098 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:18:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19044'), (b'x-ratelimit-reset-requests', b'11.504999999s'), (b'x-ratelimit-reset-tokens', b'2.868s'), (b'x-request-id', b'req_01jaq5x2ddebyan3wf3dxwar0q'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60287b3ff1053e-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:18:04,098 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:18:04,098 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:18:04,098 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:18:04,098 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:18:04,098 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:18:04,098 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:18:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19044', 'x-ratelimit-reset-requests': '11.504999999s', 'x-ratelimit-reset-tokens': '2.868s', 'x-request-id': 'req_01jaq5x2ddebyan3wf3dxwar0q', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60287b3ff1053e-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:18:04,274 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "No, I don't have direct access to the Google Maps API or any external APIs for that matter. My previous response was based on pre-existing knowledge and general information. I can provide directions and distances but will not have real-time traffic updates or exact route information.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:18:04,274 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:18:04,274 - httpcore.connection - DEBUG - close.started
2024-10-21 12:18:04,274 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:18:04,274 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:18:04,405 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26A8920>
2024-10-21 12:18:04,405 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:18:04,553 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26A80E0>
2024-10-21 12:18:04,553 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:18:04,553 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:18:04,553 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:18:04,553 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:18:04,553 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:18:06,612 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:18:07 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1237'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_625473e1189bfbcb269283b279faa304'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6028827a4c73f1-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:18:06,612 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:18:06,612 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:18:07 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1237', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_625473e1189bfbcb269283b279faa304', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6028827a4c73f1-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:18:06,628 - openai._base_client - DEBUG - request_id: req_625473e1189bfbcb269283b279faa304
2024-10-21 12:18:06,628 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:18:24,411 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:18:24,411 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:18:24,411 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:18:42,514 - faster_whisper - INFO - Processing audio with duration 00:14.280
2024-10-21 12:18:43,230 - faster_whisper - INFO - Detected language 'en' with probability 0.59
2024-10-21 12:18:43,230 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:18:43,464 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': "Does Jimmy know, can I change your voice? Can I change it to someone else's voice?"}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:18:43,464 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:18:43,464 - httpcore.connection - DEBUG - close.started
2024-10-21 12:18:43,464 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:18:43,464 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:18:43,582 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E90A0>
2024-10-21 12:18:43,582 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:18:43,699 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EB980>
2024-10-21 12:18:43,699 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:18:43,700 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:18:43,700 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:18:43,700 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:18:43,701 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:18:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19861'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'417ms'), (b'x-request-id', b'req_01jaq5y9s5e7vtgm0034ytn9d7'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6029771c074eb9-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:18:44,189 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:18:44,189 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:18:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19861', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '417ms', 'x-request-id': 'req_01jaq5y9s5e7vtgm0034ytn9d7', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6029771c074eb9-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:18:44,189 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}, {'role': 'assistant', 'content': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?"}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}, {'role': 'assistant', 'content': 'Directions from Nairobi City to Mombasa City typically involve driving via the Mombasa Highway or A109 highway, which is a major road network connecting the two cities. The journey is approximately 480 kilometers and usually takes around 8-10 hours by car, depending on traffic and road conditions. You can take regular breaks along the way through towns like Machakos, Kitale and Voi and it is also advisable to consider hiring a guided tour or driving with a local.'}, {'role': 'user', 'content': "Do you have access to Google Maps API's?"}, {'role': 'assistant', 'content': "No, I don't have direct access to the Google Maps API or any external APIs for that matter. My previous response was based on pre-existing knowledge and general information. I can provide directions and distances but will not have real-time traffic updates or exact route information."}, {'role': 'user', 'content': "Does Jimmy know, can I change your voice? Can I change it to someone else's voice?"}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:18:44,189 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:18:44,985 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:18:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'18943'), (b'x-ratelimit-reset-requests', b'11.491s'), (b'x-ratelimit-reset-tokens', b'3.171s'), (b'x-request-id', b'req_01jaq5ya8re8n95srzaf8cf2js'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60297a48b84eb9-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:18:44,985 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:18:44,985 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:18:44,985 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:18:44,985 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:18:44,985 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:18:44,985 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:18:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '18943', 'x-ratelimit-reset-requests': '11.491s', 'x-ratelimit-reset-tokens': '3.171s', 'x-request-id': 'req_01jaq5ya8re8n95srzaf8cf2js', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60297a48b84eb9-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:18:45,173 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'I don\'t have personal relationships or interactions with individuals, so I\'m not aware of a "Jimmy" who knows anything about me. Regarding changing my voice, I can mimic the tones, pace, and language styles of different human voices, but I don\'t have direct control over external synthesis or persona modeling that would allow me to perfectly emulate someone else\'s voice, such as a well-known celebrity or an individual. However, I can modify my voice to fit various personas or reflect different emotional tones with varying levels of success, based on pre-existing data and modeling.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:18:45,173 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:18:45,173 - httpcore.connection - DEBUG - close.started
2024-10-21 12:18:45,173 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:18:45,173 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:18:45,299 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269EC30>
2024-10-21 12:18:45,299 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:18:45,478 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26ABC50>
2024-10-21 12:18:45,478 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:18:45,478 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:18:45,478 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:18:45,483 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:18:45,483 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:18:47,146 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:18:47 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1244'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_db1d60d5aff214a901071cdc28a0739f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602982395173e4-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:18:47,146 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:18:47,146 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:18:47 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1244', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_db1d60d5aff214a901071cdc28a0739f', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602982395173e4-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:18:47,146 - openai._base_client - DEBUG - request_id: req_db1d60d5aff214a901071cdc28a0739f
2024-10-21 12:18:47,146 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:19:22,528 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:19:22,528 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:19:22,528 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:19:39,686 - faster_whisper - INFO - Processing audio with duration 00:15.023
2024-10-21 12:19:40,398 - faster_whisper - INFO - Detected language 'en' with probability 0.82
2024-10-21 12:19:40,398 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:19:40,571 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Okay, so now from now on be sound more empathetic.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:19:40,571 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:19:40,571 - httpcore.connection - DEBUG - close.started
2024-10-21 12:19:40,571 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:19:40,571 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:19:40,686 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269D610>
2024-10-21 12:19:40,686 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:19:40,809 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269DA90>
2024-10-21 12:19:40,809 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:19:40,810 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:19:40,810 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:19:40,810 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:19:40,811 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:19:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19869'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'393ms'), (b'x-request-id', b'req_01jaq601htf928xczaj0c63mc6'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602adc28d373fa-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:19:41,321 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:19:41,321 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:19:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19869', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '393ms', 'x-request-id': 'req_01jaq601htf928xczaj0c63mc6', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602adc28d373fa-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:19:41,321 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}, {'role': 'assistant', 'content': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?"}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}, {'role': 'assistant', 'content': 'Directions from Nairobi City to Mombasa City typically involve driving via the Mombasa Highway or A109 highway, which is a major road network connecting the two cities. The journey is approximately 480 kilometers and usually takes around 8-10 hours by car, depending on traffic and road conditions. You can take regular breaks along the way through towns like Machakos, Kitale and Voi and it is also advisable to consider hiring a guided tour or driving with a local.'}, {'role': 'user', 'content': "Do you have access to Google Maps API's?"}, {'role': 'assistant', 'content': "No, I don't have direct access to the Google Maps API or any external APIs for that matter. My previous response was based on pre-existing knowledge and general information. I can provide directions and distances but will not have real-time traffic updates or exact route information."}, {'role': 'user', 'content': "Does Jimmy know, can I change your voice? Can I change it to someone else's voice?"}, {'role': 'assistant', 'content': 'I don\'t have personal relationships or interactions with individuals, so I\'m not aware of a "Jimmy" who knows anything about me. Regarding changing my voice, I can mimic the tones, pace, and language styles of different human voices, but I don\'t have direct control over external synthesis or persona modeling that would allow me to perfectly emulate someone else\'s voice, such as a well-known celebrity or an individual. However, I can modify my voice to fit various personas or reflect different emotional tones with varying levels of success, based on pre-existing data and modeling.'}, {'role': 'user', 'content': 'Okay, so now from now on be sound more empathetic.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:19:41,321 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:19:41,336 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:19:41,338 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:19:42,952 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:19:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'18775'), (b'x-ratelimit-reset-requests', b'10.616s'), (b'x-ratelimit-reset-tokens', b'3.675s'), (b'x-request-id', b'req_01jaq602w2f9ctg1hmyww3sktz'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602adf6d4473fa-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:19:42,952 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:19:42,952 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:19:42,952 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:19:42,952 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:19:42,952 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:19:42,952 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:19:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '18775', 'x-ratelimit-reset-requests': '10.616s', 'x-ratelimit-reset-tokens': '3.675s', 'x-request-id': 'req_01jaq602w2f9ctg1hmyww3sktz', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602adf6d4473fa-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:19:43,121 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I'll do my best to adapt my tone and language to be more empathetic and compassionate, acknowledging the emotional and personal contexts that users bring to our conversations. I'll strive to be more understanding, supportive, and validating, while still providing accurate and helpful information. Let's communicate in a way that feels more personal and sensitive to your concerns and needs.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:19:43,121 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:19:43,121 - httpcore.connection - DEBUG - close.started
2024-10-21 12:19:43,121 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:19:43,121 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:19:43,230 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26AA5D0>
2024-10-21 12:19:43,230 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:19:43,351 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26AA3F0>
2024-10-21 12:19:43,351 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:19:43,351 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:19:43,351 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:19:43,351 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:19:43,351 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:19:46,905 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:19:47 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'2285'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_c619d872b0937a5748774ba8dc4f110b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602aec0c4d0521-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:19:46,905 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:19:46,905 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:19:47 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '2285', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_c619d872b0937a5748774ba8dc4f110b', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602aec0c4d0521-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:19:46,905 - openai._base_client - DEBUG - request_id: req_c619d872b0937a5748774ba8dc4f110b
2024-10-21 12:19:46,905 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:20:11,071 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:20:11,071 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:20:11,071 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:20:27,185 - faster_whisper - INFO - Processing audio with duration 00:14.257
2024-10-21 12:20:27,875 - faster_whisper - INFO - Detected language 'en' with probability 0.42
2024-10-21 12:20:27,875 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:20:28,033 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'What other languages can you recognize apart from English?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:20:28,033 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:20:28,033 - httpcore.connection - DEBUG - close.started
2024-10-21 12:20:28,033 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:20:28,033 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:20:28,170 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269FE00>
2024-10-21 12:20:28,171 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:20:28,296 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269F650>
2024-10-21 12:20:28,297 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:20:28,298 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:20:28,298 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:20:28,298 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:20:28,298 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:20:28,771 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:20:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19867'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'399ms'), (b'x-request-id', b'req_01jaq61fx8fjmbq4wffgyazshe'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602c04dbc84ed9-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:20:28,771 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:20:28,771 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:20:28,771 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:20:28,771 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:20:28,771 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:20:28,771 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:20:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19867', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '399ms', 'x-request-id': 'req_01jaq61fx8fjmbq4wffgyazshe', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602c04dbc84ed9-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:20:28,787 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}, {'role': 'assistant', 'content': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?"}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}, {'role': 'assistant', 'content': 'Directions from Nairobi City to Mombasa City typically involve driving via the Mombasa Highway or A109 highway, which is a major road network connecting the two cities. The journey is approximately 480 kilometers and usually takes around 8-10 hours by car, depending on traffic and road conditions. You can take regular breaks along the way through towns like Machakos, Kitale and Voi and it is also advisable to consider hiring a guided tour or driving with a local.'}, {'role': 'user', 'content': "Do you have access to Google Maps API's?"}, {'role': 'assistant', 'content': "No, I don't have direct access to the Google Maps API or any external APIs for that matter. My previous response was based on pre-existing knowledge and general information. I can provide directions and distances but will not have real-time traffic updates or exact route information."}, {'role': 'user', 'content': "Does Jimmy know, can I change your voice? Can I change it to someone else's voice?"}, {'role': 'assistant', 'content': 'I don\'t have personal relationships or interactions with individuals, so I\'m not aware of a "Jimmy" who knows anything about me. Regarding changing my voice, I can mimic the tones, pace, and language styles of different human voices, but I don\'t have direct control over external synthesis or persona modeling that would allow me to perfectly emulate someone else\'s voice, such as a well-known celebrity or an individual. However, I can modify my voice to fit various personas or reflect different emotional tones with varying levels of success, based on pre-existing data and modeling.'}, {'role': 'user', 'content': 'Okay, so now from now on be sound more empathetic.'}, {'role': 'assistant', 'content': "I'll do my best to adapt my tone and language to be more empathetic and compassionate, acknowledging the emotional and personal contexts that users bring to our conversations. I'll strive to be more understanding, supportive, and validating, while still providing accurate and helpful information. Let's communicate in a way that feels more personal and sensitive to your concerns and needs."}, {'role': 'user', 'content': 'What other languages can you recognize apart from English?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:20:28,787 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:20:28,787 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:20:28,787 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:20:28,787 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:20:28,787 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:20:28,787 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:20:29,648 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:20:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'18654'), (b'x-ratelimit-reset-requests', b'11.47s'), (b'x-ratelimit-reset-tokens', b'4.038s'), (b'x-request-id', b'req_01jaq61gdbem3bj9axwzhtsk71'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602c07ffd54ed9-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:20:29,648 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:20:29,648 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:20:29,648 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:20:29,648 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:20:29,648 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:20:29,648 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:20:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '18654', 'x-ratelimit-reset-requests': '11.47s', 'x-ratelimit-reset-tokens': '4.038s', 'x-request-id': 'req_01jaq61gdbem3bj9axwzhtsk71', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602c07ffd54ed9-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:20:29,827 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I've been trained on a broad range of languages, but I'm not fluent in the same way I am in English. I can understand and respond in dozens of languages, including Spanish, French, German, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, and many others. My proficiency might vary, but I can still be of help and provide basic information, translations, or simple conversations in multiple languages. If you need a more detailed or nuanced conversation in a specific language, I can try to point you in the right direction or find a resource that can assist you better.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:20:29,827 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:20:29,827 - httpcore.connection - DEBUG - close.started
2024-10-21 12:20:29,827 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:20:29,827 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:20:29,951 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F098B380>
2024-10-21 12:20:29,951 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:20:30,143 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26A9670>
2024-10-21 12:20:30,143 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:20:30,143 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:20:30,143 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:20:30,143 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:20:30,143 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:20:30,735 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:20:31 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_cfc2ad4401e9acaf8c7d0c0d48e0fc03'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602c10deba4ebb-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:20:30,736 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:20:30,737 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:20:31 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_cfc2ad4401e9acaf8c7d0c0d48e0fc03', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602c10deba4ebb-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:20:30,737 - openai._base_client - DEBUG - request_id: req_cfc2ad4401e9acaf8c7d0c0d48e0fc03
2024-10-21 12:20:30,737 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:20:30,740 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:20:30,740 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:20:30,741 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:20:30,741 - openai._base_client - DEBUG - 2 retries left
2024-10-21 12:20:30,741 - openai._base_client - INFO - Retrying request to /audio/speech in 0.493186 seconds
2024-10-21 12:20:31,236 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I've been trained on a broad range of languages, but I'm not fluent in the same way I am in English. I can understand and respond in dozens of languages, including Spanish, French, German, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, and many others. My proficiency might vary, but I can still be of help and provide basic information, translations, or simple conversations in multiple languages. If you need a more detailed or nuanced conversation in a specific language, I can try to point you in the right direction or find a resource that can assist you better.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:20:31,236 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:20:31,236 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:20:31,387 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EB4A0>
2024-10-21 12:20:31,387 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:20:31,513 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E9FD0>
2024-10-21 12:20:31,513 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:20:31,513 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:20:31,513 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:20:31,513 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:20:31,513 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:20:32,064 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:20:32 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_98a5c942fce3ac55e6551a4ce7b6b04e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602c18f8364eb4-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:20:32,064 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:20:32,064 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:20:32 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_98a5c942fce3ac55e6551a4ce7b6b04e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602c18f8364eb4-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:20:32,064 - openai._base_client - DEBUG - request_id: req_98a5c942fce3ac55e6551a4ce7b6b04e
2024-10-21 12:20:32,064 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:20:32,064 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:20:32,080 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:20:32,080 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:20:32,080 - openai._base_client - DEBUG - 1 retry left
2024-10-21 12:20:32,080 - openai._base_client - INFO - Retrying request to /audio/speech in 0.875671 seconds
2024-10-21 12:20:32,957 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I've been trained on a broad range of languages, but I'm not fluent in the same way I am in English. I can understand and respond in dozens of languages, including Spanish, French, German, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, and many others. My proficiency might vary, but I can still be of help and provide basic information, translations, or simple conversations in multiple languages. If you need a more detailed or nuanced conversation in a specific language, I can try to point you in the right direction or find a resource that can assist you better.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:20:32,957 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:20:32,957 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:20:33,072 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26CC5C0>
2024-10-21 12:20:33,072 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:20:33,182 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26CC4A0>
2024-10-21 12:20:33,182 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:20:33,182 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:20:33,182 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:20:33,182 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:20:33,182 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:20:34,929 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:20:35 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1202'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_d1f876d5e6cd5f2383a6b104298d8998'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602c23ad9e739e-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:20:34,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:20:34,929 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:20:35 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1202', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_d1f876d5e6cd5f2383a6b104298d8998', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602c23ad9e739e-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:20:34,929 - openai._base_client - DEBUG - request_id: req_d1f876d5e6cd5f2383a6b104298d8998
2024-10-21 12:20:34,929 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:21:09,156 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:21:09,156 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:21:09,156 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:21:30,063 - faster_whisper - INFO - Processing audio with duration 00:16.904
2024-10-21 12:21:30,806 - faster_whisper - INFO - Detected language 'en' with probability 0.63
2024-10-21 12:21:30,806 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:21:30,994 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Translate this French statement into English, Komotitapel.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:21:30,994 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:21:30,994 - httpcore.connection - DEBUG - close.started
2024-10-21 12:21:30,994 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:21:30,994 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:21:31,104 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EB9E0>
2024-10-21 12:21:31,104 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:21:31,223 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EBBC0>
2024-10-21 12:21:31,236 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:21:31,237 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:21:31,237 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:21:31,238 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:21:31,238 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:21:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19867'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'399ms'), (b'x-request-id', b'req_01jaq63dcceh5bbt7g6pjrzyd2'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602d8e3c7373bc-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:21:31,736 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:21:31,736 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:21:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19867', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '399ms', 'x-request-id': 'req_01jaq63dcceh5bbt7g6pjrzyd2', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602d8e3c7373bc-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:21:31,736 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}, {'role': 'assistant', 'content': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?"}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}, {'role': 'assistant', 'content': 'Directions from Nairobi City to Mombasa City typically involve driving via the Mombasa Highway or A109 highway, which is a major road network connecting the two cities. The journey is approximately 480 kilometers and usually takes around 8-10 hours by car, depending on traffic and road conditions. You can take regular breaks along the way through towns like Machakos, Kitale and Voi and it is also advisable to consider hiring a guided tour or driving with a local.'}, {'role': 'user', 'content': "Do you have access to Google Maps API's?"}, {'role': 'assistant', 'content': "No, I don't have direct access to the Google Maps API or any external APIs for that matter. My previous response was based on pre-existing knowledge and general information. I can provide directions and distances but will not have real-time traffic updates or exact route information."}, {'role': 'user', 'content': "Does Jimmy know, can I change your voice? Can I change it to someone else's voice?"}, {'role': 'assistant', 'content': 'I don\'t have personal relationships or interactions with individuals, so I\'m not aware of a "Jimmy" who knows anything about me. Regarding changing my voice, I can mimic the tones, pace, and language styles of different human voices, but I don\'t have direct control over external synthesis or persona modeling that would allow me to perfectly emulate someone else\'s voice, such as a well-known celebrity or an individual. However, I can modify my voice to fit various personas or reflect different emotional tones with varying levels of success, based on pre-existing data and modeling.'}, {'role': 'user', 'content': 'Okay, so now from now on be sound more empathetic.'}, {'role': 'assistant', 'content': "I'll do my best to adapt my tone and language to be more empathetic and compassionate, acknowledging the emotional and personal contexts that users bring to our conversations. I'll strive to be more understanding, supportive, and validating, while still providing accurate and helpful information. Let's communicate in a way that feels more personal and sensitive to your concerns and needs."}, {'role': 'user', 'content': 'What other languages can you recognize apart from English?'}, {'role': 'assistant', 'content': "I've been trained on a broad range of languages, but I'm not fluent in the same way I am in English. I can understand and respond in dozens of languages, including Spanish, French, German, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, and many others. My proficiency might vary, but I can still be of help and provide basic information, translations, or simple conversations in multiple languages. If you need a more detailed or nuanced conversation in a specific language, I can try to point you in the right direction or find a resource that can assist you better."}, {'role': 'user', 'content': 'Translate this French statement into English, Komotitapel.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:21:31,736 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:21:32,831 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:21:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'18486'), (b'x-ratelimit-reset-requests', b'11.215s'), (b'x-ratelimit-reset-tokens', b'4.542s'), (b'x-request-id', b'req_01jaq63e40e5vtscfvas1fg5x4'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602d91a8a473bc-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:21:32,831 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:21:32,831 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:21:32,831 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:21:32,831 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:21:32,831 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:21:32,831 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:21:33 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '18486', 'x-ratelimit-reset-requests': '11.215s', 'x-ratelimit-reset-tokens': '4.542s', 'x-request-id': 'req_01jaq63e40e5vtscfvas1fg5x4', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602d91a8a473bc-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:21:33,003 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'The phrase "Komotitapel" doesn\'t seem to be a real French word or phrase. It\'s possible that it\'s a made-up word, a word from another language, or a word with no meaning. If you can provide the actual context or a correct translation attempt of the word, I\'ll do my best to help you understand its meaning or offer a correct translation.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:21:33,003 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:21:33,003 - httpcore.connection - DEBUG - close.started
2024-10-21 12:21:33,003 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:21:33,003 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:21:33,134 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26A9550>
2024-10-21 12:21:33,134 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:21:33,263 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26AA180>
2024-10-21 12:21:33,263 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:21:33,263 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:21:33,263 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:21:33,263 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:21:33,263 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:21:38,759 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:21:39 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'4885'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_4e7b62e61f0a01f361066aa952173d09'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602d9afcde73b5-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:21:38,759 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:21:38,759 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:21:39 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '4885', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_4e7b62e61f0a01f361066aa952173d09', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602d9afcde73b5-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:21:38,759 - openai._base_client - DEBUG - request_id: req_4e7b62e61f0a01f361066aa952173d09
2024-10-21 12:21:38,759 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:21:59,110 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:21:59,110 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:21:59,110 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:22:10,389 - faster_whisper - INFO - Processing audio with duration 00:10.797
2024-10-21 12:22:11,070 - faster_whisper - INFO - Detected language 'fr' with probability 0.90
2024-10-21 12:22:11,070 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:22:11,201 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Et ce que tu fais de la vie.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:22:11,201 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:22:11,217 - httpcore.connection - DEBUG - close.started
2024-10-21 12:22:11,217 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:22:11,217 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:22:11,323 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269F2F0>
2024-10-21 12:22:11,323 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:22:11,446 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269DD00>
2024-10-21 12:22:11,446 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:22:11,446 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:22:11,447 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:22:11,447 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:22:11,447 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:22:11,952 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:22:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19874'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'378ms'), (b'x-request-id', b'req_01jaq64mndf20rd0nk2sk7zxaw'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602e89a87b93d0-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:22:11,952 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:22:11,952 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:22:11,952 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:22:11,952 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:22:11,952 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:22:11,952 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:22:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19874', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '378ms', 'x-request-id': 'req_01jaq64mndf20rd0nk2sk7zxaw', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602e89a87b93d0-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:22:11,968 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}, {'role': 'assistant', 'content': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?"}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}, {'role': 'assistant', 'content': 'Directions from Nairobi City to Mombasa City typically involve driving via the Mombasa Highway or A109 highway, which is a major road network connecting the two cities. The journey is approximately 480 kilometers and usually takes around 8-10 hours by car, depending on traffic and road conditions. You can take regular breaks along the way through towns like Machakos, Kitale and Voi and it is also advisable to consider hiring a guided tour or driving with a local.'}, {'role': 'user', 'content': "Do you have access to Google Maps API's?"}, {'role': 'assistant', 'content': "No, I don't have direct access to the Google Maps API or any external APIs for that matter. My previous response was based on pre-existing knowledge and general information. I can provide directions and distances but will not have real-time traffic updates or exact route information."}, {'role': 'user', 'content': "Does Jimmy know, can I change your voice? Can I change it to someone else's voice?"}, {'role': 'assistant', 'content': 'I don\'t have personal relationships or interactions with individuals, so I\'m not aware of a "Jimmy" who knows anything about me. Regarding changing my voice, I can mimic the tones, pace, and language styles of different human voices, but I don\'t have direct control over external synthesis or persona modeling that would allow me to perfectly emulate someone else\'s voice, such as a well-known celebrity or an individual. However, I can modify my voice to fit various personas or reflect different emotional tones with varying levels of success, based on pre-existing data and modeling.'}, {'role': 'user', 'content': 'Okay, so now from now on be sound more empathetic.'}, {'role': 'assistant', 'content': "I'll do my best to adapt my tone and language to be more empathetic and compassionate, acknowledging the emotional and personal contexts that users bring to our conversations. I'll strive to be more understanding, supportive, and validating, while still providing accurate and helpful information. Let's communicate in a way that feels more personal and sensitive to your concerns and needs."}, {'role': 'user', 'content': 'What other languages can you recognize apart from English?'}, {'role': 'assistant', 'content': "I've been trained on a broad range of languages, but I'm not fluent in the same way I am in English. I can understand and respond in dozens of languages, including Spanish, French, German, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, and many others. My proficiency might vary, but I can still be of help and provide basic information, translations, or simple conversations in multiple languages. If you need a more detailed or nuanced conversation in a specific language, I can try to point you in the right direction or find a resource that can assist you better."}, {'role': 'user', 'content': 'Translate this French statement into English, Komotitapel.'}, {'role': 'assistant', 'content': 'The phrase "Komotitapel" doesn\'t seem to be a real French word or phrase. It\'s possible that it\'s a made-up word, a word from another language, or a word with no meaning. If you can provide the actual context or a correct translation attempt of the word, I\'ll do my best to help you understand its meaning or offer a correct translation.'}, {'role': 'user', 'content': 'Et ce que tu fais de la vie.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:22:11,970 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:22:11,970 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:22:11,970 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:22:11,970 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:22:11,970 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:22:11,970 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:22:12,856 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:22:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'18385'), (b'x-ratelimit-reset-requests', b'11.448999999s'), (b'x-ratelimit-reset-tokens', b'4.845s'), (b'x-request-id', b'req_01jaq64n5bf9m95y03nqaf86ra'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602e8cdc8593d0-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:22:12,856 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:22:12,856 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:22:12,856 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:22:12,856 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:22:12,856 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:22:12,856 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:22:13 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '18385', 'x-ratelimit-reset-requests': '11.448999999s', 'x-ratelimit-reset-tokens': '4.845s', 'x-request-id': 'req_01jaq64n5bf9m95y03nqaf86ra', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602e8cdc8593d0-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:22:13,020 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'The phrase "Et ce que tu fais de la vie" is a French expression that translates to "And what do you make of life" in English. This phrase is asking someone how they perceive life, what they think it is all about, or how they approach their existence. It\'s a philosophical and introspective question that invites the person to share their thoughts and feelings about life.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:22:13,020 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:22:13,020 - httpcore.connection - DEBUG - close.started
2024-10-21 12:22:13,020 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:22:13,020 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:22:13,134 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26A8D70>
2024-10-21 12:22:13,134 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:22:13,268 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26ABBF0>
2024-10-21 12:22:13,268 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:22:13,268 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:22:13,268 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:22:13,268 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:22:13,268 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:22:15,356 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:22:15 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'948'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_992da4c2079ef5a35a12f6622e967485'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602e94f9544ec8-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:22:15,356 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:22:15,356 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:22:15 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '948', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_992da4c2079ef5a35a12f6622e967485', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602e94f9544ec8-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:22:15,356 - openai._base_client - DEBUG - request_id: req_992da4c2079ef5a35a12f6622e967485
2024-10-21 12:22:15,356 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:22:38,058 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:22:38,058 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:22:38,058 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:22:55,106 - faster_whisper - INFO - Processing audio with duration 00:10.890
2024-10-21 12:22:55,762 - faster_whisper - INFO - Detected language 'ar' with probability 0.76
2024-10-21 12:22:55,762 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:22:55,935 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.0 (-1.106405 < -1.000000)
2024-10-21 12:22:56,264 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.2 (-1.142616 < -1.000000)
2024-10-21 12:22:56,594 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.4 (-1.483379 < -1.000000)
2024-10-21 12:22:56,910 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.6 (-1.238541 < -1.000000)
2024-10-21 12:22:57,240 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.8 (-1.948776 < -1.000000)
2024-10-21 12:22:57,511 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 1.0 (-3.143185 < -1.000000)
2024-10-21 12:22:57,524 - faster_whisper - DEBUG - Reset prompt. prompt_reset_on_temperature threshold is met 1.000000 > 0.500000
2024-10-21 12:23:13,093 - comtypes._post_coinit.unknwn - DEBUG - Calling CoUninitialize()
2024-10-21 12:23:13,093 - comtypes._post_coinit.unknwn - DEBUG - CoUninitialize() done.
2024-10-21 12:23:13,140 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>.Release() -> 0
2024-10-21 12:23:13,140 - comtypes._comobject - DEBUG - 0 active COM objects: Removed <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>
2024-10-21 12:23:13,140 - comtypes._comobject - DEBUG - Remaining: []
2024-10-21 12:23:13,203 - httpcore.connection - DEBUG - close.started
2024-10-21 12:23:13,203 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:23:13,203 - httpcore.connection - DEBUG - close.started
2024-10-21 12:23:13,203 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:27:35,649 - __main__ - INFO - Starting main.py
2024-10-21 12:27:35,649 - __main__ - INFO - Chat log file path: C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\chat_history\2024\10\21.log
2024-10-21 12:27:35,649 - __main__ - INFO - API keys loaded successfully
2024-10-21 12:27:35,664 - comtypes - DEBUG - CoInitializeEx(None, 2)
2024-10-21 12:27:35,700 - comtypes.client._code_cache - INFO - Imported existing <module 'comtypes.gen' from 'C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\comtypes\\gen\\__init__.py'>
2024-10-21 12:27:35,701 - comtypes.client._code_cache - INFO - Using writeable comtypes cache directory: 'C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\comtypes\gen'
2024-10-21 12:27:35,746 - comtypes.client - DEBUG - SAPI.SPVoice -> {96749377-3391-11D2-9EE3-00C04F797396}
2024-10-21 12:27:35,746 - comtypes.client - DEBUG - CoCreateInstance({96749377-3391-11D2-9EE3-00C04F797396}, clsctx=None, interface=None)
2024-10-21 12:27:35,762 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IUnknown) ptr=0x1569f78f640 at 156b6abaf50>)
2024-10-21 12:27:35,763 - comtypes.client - DEBUG - Does implement IProvideClassInfo
2024-10-21 12:27:35,764 - comtypes.client - DEBUG - Default interface is {269316D8-57BD-11D2-9EEE-00C04F797396}
2024-10-21 12:27:35,765 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1569f78f680 at 156b6abb350>
2024-10-21 12:27:35,765 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:27:35,766 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechVoice'>
2024-10-21 12:27:35,766 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechVoice) ptr=0x1569f78f680 at 156b6abb2d0>
2024-10-21 12:27:35,766 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo) ptr=0x1569f78f6a0 at 156b6abaed0>
2024-10-21 12:27:35,767 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x156b51a95e8 at 156b6abafd0>
2024-10-21 12:27:35,767 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x156b51a9640 at 156b6abb050>
2024-10-21 12:27:35,767 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x156b5144870 at 156b6abb350>
2024-10-21 12:27:35,768 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1569f78f640 at 156b6abaf50>
2024-10-21 12:27:35,768 - comtypes.client._events - DEBUG - <POINTER(ISpeechVoice) ptr=0x1569f78f680 at 156b6abb2d0> using sinkinterface from clsid <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:27:35,796 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo2) ptr=0x1569f78f6a0 at 156b6abaf50>
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>: _ISpeechVoiceEvents.VoiceChange not implemented
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>: _ISpeechVoiceEvents.Bookmark not implemented
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>: _ISpeechVoiceEvents.Sentence not implemented
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>: _ISpeechVoiceEvents.Phoneme not implemented
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>: _ISpeechVoiceEvents.Viseme not implemented
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>: _ISpeechVoiceEvents.AudioLevel not implemented
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>: _ISpeechVoiceEvents.EnginePrivate not implemented
2024-10-21 12:27:35,796 - comtypes.client._events - DEBUG - Start advise <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>.QueryInterface({A372ACD1-3BEF-4BBD-8FFB-CB3E2B416AF8}) -> S_OK
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - 1 active COM objects: Added   <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>.AddRef() -> 1
2024-10-21 12:27:35,796 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IConnectionPointContainer) ptr=0x1569f78f6a8 at 156b6b20750>
2024-10-21 12:27:35,874 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectToken) ptr=0x1569f7d0f70 at 156b6b20750>)
2024-10-21 12:27:35,874 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x1569f7d0f70 at 156b6b20750>
2024-10-21 12:27:35,875 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x156b6ece3d0 at 156b6b20750>)
2024-10-21 12:27:35,875 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x156b6ef7100 at 156b6b20850>
2024-10-21 12:27:35,875 - comtypes.client - DEBUG - wrap_outparam(<POINTER(IDispatch) ptr=0x156b6e0a160 at 156b6b20a50>)
2024-10-21 12:27:35,876 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IDispatch) ptr=0x156b6e0a160 at 156b6b20a50>)
2024-10-21 12:27:35,876 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo, trying IProvideClassInfo2
2024-10-21 12:27:35,877 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo/IProvideClassInfo2
2024-10-21 12:27:35,878 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x156b51a96f0 at 156b6b20c50>
2024-10-21 12:27:35,878 - comtypes.client - DEBUG - Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}
2024-10-21 12:27:35,878 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x156b6e0a160 at 156b6b20d50>
2024-10-21 12:27:35,879 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:27:35,879 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>
2024-10-21 12:27:35,879 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechObjectToken) ptr=0x156b6e0a160 at 156b6b20c50>
2024-10-21 12:27:35,879 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x156b6e0a160 at 156b6b20bd0>
2024-10-21 12:27:35,879 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x156b51a96f0 at 156b6b20cd0>
2024-10-21 12:27:35,879 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x156b5144870 at 156b6b20d50>
2024-10-21 12:27:35,880 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x156b6e0a160 at 156b6b20a50>
2024-10-21 12:27:35,880 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IEnumVARIANT) ptr=0x156b6ef7100 at 156b6b208d0>
2024-10-21 12:27:35,880 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectTokens) ptr=0x156b6ece3d0 at 156b6b20750>
2024-10-21 12:27:35,880 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x156b6e0a160 at 156b6b20c50>
2024-10-21 12:27:35,881 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:27:35,882 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:27:36,104 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:27:36,104 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:27:36,491 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2024-10-21 12:27:37,238 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/Systran/faster-whisper-base/revision/main HTTP/1.1" 200 1848
2024-10-21 12:27:37,830 - __main__ - INFO - Siri instance initialized
2024-10-21 12:27:43,239 - faster_whisper - INFO - Processing audio with duration 00:01.834
2024-10-21 12:27:43,885 - faster_whisper - INFO - Detected language 'en' with probability 0.63
2024-10-21 12:27:43,885 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:27:44,010 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'end of it again.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:27:44,136 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:27:44,136 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:27:44,275 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156B9BE5DC0>
2024-10-21 12:27:44,275 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B20950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:27:44,492 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156B9B8EE40>
2024-10-21 12:27:44,492 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:27:44,492 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:27:44,492 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:27:44,492 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:27:44,492 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:27:44,994 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:27:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19877'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'369ms'), (b'x-request-id', b'req_01jaq6esx4faaraas0fwxxv8a0'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pPHZ_dMbq8xuIsWLLGulqxE76tYVFLvq6aVQy8IFndI-1729502865-1.0.1.1-5Pf2VUNaTFsCUZ6b7Jn6mWdFAjsJHMF_e6C_2NmP4UDnMYiDRuctN9FQu8C.jSu0CcqEEmKXXz9YxUOTieaBtA; path=/; expires=Mon, 21-Oct-24 09:57:45 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6036ab3e3d73e2-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:27:44,995 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:27:44,995 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:27:44,995 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:27:44,995 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:27:44,995 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:27:44,995 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:27:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19877', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '369ms', 'x-request-id': 'req_01jaq6esx4faaraas0fwxxv8a0', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=pPHZ_dMbq8xuIsWLLGulqxE76tYVFLvq6aVQy8IFndI-1729502865-1.0.1.1-5Pf2VUNaTFsCUZ6b7Jn6mWdFAjsJHMF_e6C_2NmP4UDnMYiDRuctN9FQu8C.jSu0CcqEEmKXXz9YxUOTieaBtA; path=/; expires=Mon, 21-Oct-24 09:57:45 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8d6036ab3e3d73e2-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:27:45,004 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'end of it again.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:27:45,006 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:27:45,006 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:27:45,007 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:27:45,007 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:27:45,007 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:27:45,007 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:27:45,589 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:27:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19823'), (b'x-ratelimit-reset-requests', b'11.491999999s'), (b'x-ratelimit-reset-tokens', b'531ms'), (b'x-request-id', b'req_01jaq6etd2esxv4fqzcvsvkn5a'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6036ae7a1c73e2-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:27:45,605 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:27:45,605 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:27:45,605 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:27:45,605 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:27:45,605 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:27:45,605 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:27:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19823', 'x-ratelimit-reset-requests': '11.491999999s', 'x-ratelimit-reset-tokens': '531ms', 'x-request-id': 'req_01jaq6etd2esxv4fqzcvsvkn5a', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6036ae7a1c73e2-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:27:45,779 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'The phrase "end of it again" is likely a reference to the phrase "back to the start." This phrase often accompanies the SpongeBob SquarePants theme song when the episode is supposed to end in order to begin with the start again, indicating another error in the system at the end of an otherwise completed format of its 1999 television production', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:27:45,781 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:27:45,781 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:27:45,908 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB816120>
2024-10-21 12:27:45,909 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B211D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:27:46,044 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB815E80>
2024-10-21 12:27:46,044 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:27:46,049 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:27:46,049 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:27:46,049 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:27:46,049 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:27:47,016 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:27:47 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_c47bf6f27d268f2f9f0b948dbbf80210'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=blL3Y_M7ukF00xlC435Tmft7GV1uSy94QIYP3QNjQyQ-1729502867-1.0.1.1-pTKKsuTw9egsmUEqjiSe93wCFKL7pnc8dj36Ck6ZIKOGE5F4pKQM6m2pXbw_zKZzvoqiLLwcoKnT4zV2gv5Egg; path=/; expires=Mon, 21-Oct-24 09:57:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=p3Vc2oKlMPm20WUV.VOeB3titAhOn8qRWRDCWzF4rSI-1729502867537-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6036b4dc187410-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:27:47,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:27:47,016 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers([('date', 'Mon, 21 Oct 2024 09:27:47 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_c47bf6f27d268f2f9f0b948dbbf80210'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=blL3Y_M7ukF00xlC435Tmft7GV1uSy94QIYP3QNjQyQ-1729502867-1.0.1.1-pTKKsuTw9egsmUEqjiSe93wCFKL7pnc8dj36Ck6ZIKOGE5F4pKQM6m2pXbw_zKZzvoqiLLwcoKnT4zV2gv5Egg; path=/; expires=Mon, 21-Oct-24 09:57:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=p3Vc2oKlMPm20WUV.VOeB3titAhOn8qRWRDCWzF4rSI-1729502867537-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8d6036b4dc187410-JNB'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-10-21 12:27:47,016 - openai._base_client - DEBUG - request_id: req_c47bf6f27d268f2f9f0b948dbbf80210
2024-10-21 12:27:47,016 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:27:47,024 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:27:47,025 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:27:47,025 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:27:47,025 - openai._base_client - DEBUG - 2 retries left
2024-10-21 12:27:47,026 - openai._base_client - INFO - Retrying request to /audio/speech in 0.439467 seconds
2024-10-21 12:27:47,466 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'The phrase "end of it again" is likely a reference to the phrase "back to the start." This phrase often accompanies the SpongeBob SquarePants theme song when the episode is supposed to end in order to begin with the start again, indicating another error in the system at the end of an otherwise completed format of its 1999 television production', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:27:47,466 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:27:47,466 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:27:47,592 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB8175C0>
2024-10-21 12:27:47,592 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B211D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:27:47,712 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB815AF0>
2024-10-21 12:27:47,712 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:27:47,712 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:27:47,712 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:27:47,712 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:27:47,712 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:27:49,791 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:27:50 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1343'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_c63db1d62ca51aa84d87fafff648696f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6036bfca970526-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:27:49,791 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:27:49,791 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:27:50 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1343', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_c63db1d62ca51aa84d87fafff648696f', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6036bfca970526-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:27:49,791 - openai._base_client - DEBUG - request_id: req_c63db1d62ca51aa84d87fafff648696f
2024-10-21 12:27:49,791 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:28:11,672 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:28:11,672 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:28:11,672 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:28:28,934 - faster_whisper - INFO - Processing audio with duration 00:13.607
2024-10-21 12:28:29,571 - faster_whisper - INFO - Detected language 'en' with probability 0.70
2024-10-21 12:28:29,571 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:28:29,756 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'I wanted to ask you next, um, what more do you are?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:28:29,756 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:28:29,756 - httpcore.connection - DEBUG - close.started
2024-10-21 12:28:29,756 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:28:29,756 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:28:29,879 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156B9BE5BB0>
2024-10-21 12:28:29,879 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B20950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:28:30,012 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156B9BE5A00>
2024-10-21 12:28:30,013 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:28:30,013 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:28:30,013 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:28:30,014 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:28:30,014 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:28:30,528 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19869'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'393ms'), (b'x-request-id', b'req_01jaq6g6c5e2w93f1e4nnxhxcf'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6037c7cffc4fc4-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:28:30,528 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:28:30,528 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:28:30,528 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:28:30,528 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:28:30,528 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:28:30,528 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:28:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19869', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '393ms', 'x-request-id': 'req_01jaq6g6c5e2w93f1e4nnxhxcf', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6037c7cffc4fc4-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:28:30,694 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2024-10-21 12:28:30,694 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2024-10-21 12:28:35,326 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'end of it again.'}, {'role': 'assistant', 'content': 'The phrase "end of it again" is likely a reference to the phrase "back to the start." This phrase often accompanies the SpongeBob SquarePants theme song when the episode is supposed to end in order to begin with the start again, indicating another error in the system at the end of an otherwise completed format of its 1999 television production'}, {'role': 'user', 'content': 'USER_PROMPT: I wanted to ask you next, um, what more do you are?\n\nIMAGE_CONTEXT: The image shows a code for a Python script that defines a class called `Siri`. This class appears to be a multi-modal AI voice assistant that processes voice commands and context. The script is shown to be in the process of being developed and contains comments explaining different parts of the code.  Within the comments, there are lines of code and a section called Summary, which provides a synopsis of the program\'s functionality.  The Summary section highlights the assistant\'s capability to capture images from a webcam using the `webcam.capture_webcam_image()` function.  The image also shows a terminal window with outputs from a program, possibly related to a web server request. There is also a small pop-up window with a message about the Siri assistant being initialized.  However, there is no mention of what the assistant is "more" than a multi-modal AI voice assistant that processes voice commands and context.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:28:35,326 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:28:35,326 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:28:35,326 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:28:35,326 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:28:35,326 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:28:35,326 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:28:36,096 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:28:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19474'), (b'x-ratelimit-reset-requests', b'6.640999999s'), (b'x-ratelimit-reset-tokens', b'1.578s'), (b'x-request-id', b'req_01jaq6gbkne9a8jw40gya2gpt3'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6037e8de294fc4-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:28:36,096 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:28:36,096 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:28:36,096 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:28:36,096 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:28:36,096 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:28:36,096 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:28:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19474', 'x-ratelimit-reset-requests': '6.640999999s', 'x-ratelimit-reset-tokens': '1.578s', 'x-request-id': 'req_01jaq6gbkne9a8jw40gya2gpt3', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6037e8de294fc4-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:28:36,341 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'It appears you are referring to the `Siri` class in a Python script, which is likely where the concept of a "Siri"-like assistant is being formalized; there\'s no indication that the code or comments explicitly describe the assistant being "more" than this multi-modal voice Assistant; more context or information would likely be required to identify any additional capabilities beyond its core voice command functionality.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:28:36,343 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:28:36,343 - httpcore.connection - DEBUG - close.started
2024-10-21 12:28:36,344 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:28:36,344 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:28:36,457 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB914080>
2024-10-21 12:28:36,458 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B211D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:28:36,577 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB903D40>
2024-10-21 12:28:36,581 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:28:36,581 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:28:36,581 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:28:36,581 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:28:36,581 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:28:38,886 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:28:39 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1411'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_534dcd0754ca05448c1e73864cc4b408'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6037f0bb3c4ec6-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:28:38,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:28:38,886 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:28:39 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1411', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_534dcd0754ca05448c1e73864cc4b408', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6037f0bb3c4ec6-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:28:38,886 - openai._base_client - DEBUG - request_id: req_534dcd0754ca05448c1e73864cc4b408
2024-10-21 12:28:38,886 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:29:04,732 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:29:04,732 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:29:04,732 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:29:18,255 - faster_whisper - INFO - Processing audio with duration 00:11.842
2024-10-21 12:29:18,901 - faster_whisper - INFO - Detected language 'en' with probability 0.80
2024-10-21 12:29:18,901 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:29:19,057 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Watch our webcom and tell me what you see.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:29:19,057 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:29:19,057 - httpcore.connection - DEBUG - close.started
2024-10-21 12:29:19,057 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:29:19,057 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:29:19,185 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB901310>
2024-10-21 12:29:19,185 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B20950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:29:19,326 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB902D50>
2024-10-21 12:29:19,326 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:29:19,326 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:29:19,326 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:29:19,326 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:29:19,326 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:29:19,893 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:29:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19871'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'387ms'), (b'x-request-id', b'req_01jaq6hpgwfag8sgpzvtm6nf8e'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6038fbec2073f5-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:29:19,893 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:29:19,893 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:29:19,893 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:29:19,893 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:29:19,893 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:29:19,893 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:29:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19871', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '387ms', 'x-request-id': 'req_01jaq6hpgwfag8sgpzvtm6nf8e', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6038fbec2073f5-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:29:20,940 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2024-10-21 12:29:20,940 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 8192
2024-10-21 12:29:23,747 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'end of it again.'}, {'role': 'assistant', 'content': 'The phrase "end of it again" is likely a reference to the phrase "back to the start." This phrase often accompanies the SpongeBob SquarePants theme song when the episode is supposed to end in order to begin with the start again, indicating another error in the system at the end of an otherwise completed format of its 1999 television production'}, {'role': 'user', 'content': 'USER_PROMPT: I wanted to ask you next, um, what more do you are?\n\nIMAGE_CONTEXT: The image shows a code for a Python script that defines a class called `Siri`. This class appears to be a multi-modal AI voice assistant that processes voice commands and context. The script is shown to be in the process of being developed and contains comments explaining different parts of the code.  Within the comments, there are lines of code and a section called Summary, which provides a synopsis of the program\'s functionality.  The Summary section highlights the assistant\'s capability to capture images from a webcam using the `webcam.capture_webcam_image()` function.  The image also shows a terminal window with outputs from a program, possibly related to a web server request. There is also a small pop-up window with a message about the Siri assistant being initialized.  However, there is no mention of what the assistant is "more" than a multi-modal AI voice assistant that processes voice commands and context.'}, {'role': 'assistant', 'content': 'It appears you are referring to the `Siri` class in a Python script, which is likely where the concept of a "Siri"-like assistant is being formalized; there\'s no indication that the code or comments explicitly describe the assistant being "more" than this multi-modal voice Assistant; more context or information would likely be required to identify any additional capabilities beyond its core voice command functionality.'}, {'role': 'user', 'content': "USER_PROMPT: Watch our webcom and tell me what you see.\n\nIMAGE_CONTEXT: The image shows a dark-skinned person, likely male, with short hair, looking directly at the camera. The person is partially obscured by shadows and is in a dimly lit room. Part of a sheer curtain or mosquito net is visible in the background, along with a portion of a window with a sheer curtain. The window is partially obscured by a bright light source outside, casting a glow onto the curtain.  The person's expression is obscured by the shadows."}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:29:23,763 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:29:23,763 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:29:23,763 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:29:23,763 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:29:23,763 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:29:23,763 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:29:24,550 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:29:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19229'), (b'x-ratelimit-reset-requests', b'7.471s'), (b'x-ratelimit-reset-tokens', b'2.313s'), (b'x-request-id', b'req_01jaq6htxtedd8796fabh5eb4f'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d603917d9be73f5-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:29:24,550 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:29:24,550 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:29:24,550 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:29:24,550 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:29:24,550 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:29:24,550 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:29:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19229', 'x-ratelimit-reset-requests': '7.471s', 'x-ratelimit-reset-tokens': '2.313s', 'x-request-id': 'req_01jaq6htxtedd8796fabh5eb4f', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d603917d9be73f5-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:29:24,726 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "Based on the provided image, I see a person with a dark skin tone, having short hair, partially obscured by shadows. The room appears to be dimly lit and there's a window in the background with a sheer curtain, partially lit by an external light source which casts a glow onto the curtain. Unfortunately, the person's expression is not clearly visible due to the shadows.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:29:24,726 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:29:24,726 - httpcore.connection - DEBUG - close.started
2024-10-21 12:29:24,726 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:29:24,726 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:29:24,875 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB9157C0>
2024-10-21 12:29:24,875 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B211D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:29:25,025 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB9153A0>
2024-10-21 12:29:25,025 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:29:25,025 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:29:25,025 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:29:25,025 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:29:25,025 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:29:25,524 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:29:26 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_3df2000efb97e5e954b5f08c6233b722'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60391fdbbf73e0-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:29:25,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:29:25,526 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:29:26 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_3df2000efb97e5e954b5f08c6233b722', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d60391fdbbf73e0-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:29:25,526 - openai._base_client - DEBUG - request_id: req_3df2000efb97e5e954b5f08c6233b722
2024-10-21 12:29:25,526 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:29:25,526 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:29:25,526 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:29:25,526 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:29:25,526 - openai._base_client - DEBUG - 2 retries left
2024-10-21 12:29:25,532 - openai._base_client - INFO - Retrying request to /audio/speech in 0.386093 seconds
2024-10-21 12:29:25,919 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "Based on the provided image, I see a person with a dark skin tone, having short hair, partially obscured by shadows. The room appears to be dimly lit and there's a window in the background with a sheer curtain, partially lit by an external light source which casts a glow onto the curtain. Unfortunately, the person's expression is not clearly visible due to the shadows.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:29:25,919 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:29:25,919 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:29:26,042 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB916720>
2024-10-21 12:29:26,042 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B211D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:29:26,160 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB916420>
2024-10-21 12:29:26,160 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:29:26,160 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:29:26,160 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:29:26,160 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:29:26,160 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:29:26,546 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:29:27 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_beb3ec8c41f7f9c43912f09834a4e55a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6039269b57738b-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:29:26,546 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:29:26,546 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:29:27 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_beb3ec8c41f7f9c43912f09834a4e55a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6039269b57738b-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:29:26,561 - openai._base_client - DEBUG - request_id: req_beb3ec8c41f7f9c43912f09834a4e55a
2024-10-21 12:29:26,561 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:29:26,565 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:29:26,565 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:29:26,565 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:29:26,566 - openai._base_client - DEBUG - 1 retry left
2024-10-21 12:29:26,567 - openai._base_client - INFO - Retrying request to /audio/speech in 0.768365 seconds
2024-10-21 12:29:27,336 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "Based on the provided image, I see a person with a dark skin tone, having short hair, partially obscured by shadows. The room appears to be dimly lit and there's a window in the background with a sheer curtain, partially lit by an external light source which casts a glow onto the curtain. Unfortunately, the person's expression is not clearly visible due to the shadows.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:29:27,336 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:29:27,336 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:29:27,459 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB914500>
2024-10-21 12:29:27,459 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B211D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:29:27,576 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB917710>
2024-10-21 12:29:27,576 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:29:27,576 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:29:27,576 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:29:27,576 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:29:27,576 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:29:29,298 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:29:29 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1045'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_4e66dbdccc6ecb6a1a3554ad16aa8bd4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60392f6bbf0526-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:29:29,298 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:29:29,298 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:29:29 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1045', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_4e66dbdccc6ecb6a1a3554ad16aa8bd4', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d60392f6bbf0526-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:29:29,298 - openai._base_client - DEBUG - request_id: req_4e66dbdccc6ecb6a1a3554ad16aa8bd4
2024-10-21 12:29:29,298 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:29:52,169 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:29:52,170 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:29:52,170 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:29:57,446 - faster_whisper - INFO - Processing audio with duration 00:01.718
2024-10-21 12:29:58,108 - faster_whisper - INFO - Detected language 'en' with probability 0.44
2024-10-21 12:29:58,108 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:29:58,209 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:29:58,209 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:29:58,209 - httpcore.connection - DEBUG - close.started
2024-10-21 12:29:58,209 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:29:58,209 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:29:58,330 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156A154BC50>
2024-10-21 12:29:58,330 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B20950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:29:58,333 - comtypes._post_coinit.unknwn - DEBUG - Calling CoUninitialize()
2024-10-21 12:29:58,333 - comtypes._post_coinit.unknwn - DEBUG - CoUninitialize() done.
2024-10-21 12:35:28,865 - __main__ - INFO - Starting main.py
2024-10-21 12:35:28,865 - __main__ - INFO - Chat log file path: C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\chat_history\2024\10\21.log
2024-10-21 12:35:28,865 - __main__ - INFO - API keys loaded successfully
2024-10-21 12:35:28,886 - comtypes - DEBUG - CoInitializeEx(None, 2)
2024-10-21 12:35:28,907 - comtypes.client._code_cache - INFO - Imported existing <module 'comtypes.gen' from 'C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\comtypes\\gen\\__init__.py'>
2024-10-21 12:35:28,907 - comtypes.client._code_cache - INFO - Using writeable comtypes cache directory: 'C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\comtypes\gen'
2024-10-21 12:35:28,958 - comtypes.client - DEBUG - SAPI.SPVoice -> {96749377-3391-11D2-9EE3-00C04F797396}
2024-10-21 12:35:28,958 - comtypes.client - DEBUG - CoCreateInstance({96749377-3391-11D2-9EE3-00C04F797396}, clsctx=None, interface=None)
2024-10-21 12:35:28,968 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IUnknown) ptr=0x11c65d8f640 at 11c7d0b6fd0>)
2024-10-21 12:35:28,968 - comtypes.client - DEBUG - Does implement IProvideClassInfo
2024-10-21 12:35:28,980 - comtypes.client - DEBUG - Default interface is {269316D8-57BD-11D2-9EEE-00C04F797396}
2024-10-21 12:35:28,981 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x11c65d8f680 at 11c7d0b73d0>
2024-10-21 12:35:28,981 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:35:28,982 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechVoice'>
2024-10-21 12:35:28,982 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechVoice) ptr=0x11c65d8f680 at 11c7d0b7350>
2024-10-21 12:35:28,982 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo) ptr=0x11c65d8f6a0 at 11c7d0b6f50>
2024-10-21 12:35:28,983 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x11c7b8dc928 at 11c7d0b7050>
2024-10-21 12:35:28,983 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x11c7b8dc980 at 11c7d0b70d0>
2024-10-21 12:35:28,984 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x11c7b6fd0a0 at 11c7d0b73d0>
2024-10-21 12:35:28,984 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x11c65d8f640 at 11c7d0b6fd0>
2024-10-21 12:35:28,985 - comtypes.client._events - DEBUG - <POINTER(ISpeechVoice) ptr=0x11c65d8f680 at 11c7d0b7350> using sinkinterface from clsid <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:35:28,985 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo2) ptr=0x11c65d8f6a0 at 11c7d0b6fd0>
2024-10-21 12:35:28,985 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000011C7CE11400>: _ISpeechVoiceEvents.VoiceChange not implemented
2024-10-21 12:35:28,987 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000011C7CE11400>: _ISpeechVoiceEvents.Bookmark not implemented
2024-10-21 12:35:28,987 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000011C7CE11400>: _ISpeechVoiceEvents.Sentence not implemented
2024-10-21 12:35:28,988 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000011C7CE11400>: _ISpeechVoiceEvents.Phoneme not implemented
2024-10-21 12:35:28,988 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000011C7CE11400>: _ISpeechVoiceEvents.Viseme not implemented
2024-10-21 12:35:28,988 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000011C7CE11400>: _ISpeechVoiceEvents.AudioLevel not implemented
2024-10-21 12:35:28,989 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000011C7CE11400>: _ISpeechVoiceEvents.EnginePrivate not implemented
2024-10-21 12:35:28,989 - comtypes.client._events - DEBUG - Start advise <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:35:28,990 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000011C7CE11400>.QueryInterface({A372ACD1-3BEF-4BBD-8FFB-CB3E2B416AF8}) -> S_OK
2024-10-21 12:35:28,990 - comtypes._comobject - DEBUG - 1 active COM objects: Added   <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000011C7CE11400>
2024-10-21 12:35:28,990 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000011C7CE11400>.AddRef() -> 1
2024-10-21 12:35:28,991 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IConnectionPointContainer) ptr=0x11c65d8f6a8 at 11c7d11c7d0>
2024-10-21 12:35:29,052 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectToken) ptr=0x11c65dd0f70 at 11c7d11c7d0>)
2024-10-21 12:35:29,052 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x11c65dd0f70 at 11c7d11c7d0>
2024-10-21 12:35:29,052 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x11c7bfce5d0 at 11c7d11c7d0>)
2024-10-21 12:35:29,052 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x11c7bff7880 at 11c7d11c8d0>
2024-10-21 12:35:29,052 - comtypes.client - DEBUG - wrap_outparam(<POINTER(IDispatch) ptr=0x11c7bf0aca0 at 11c7d11cad0>)
2024-10-21 12:35:29,052 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IDispatch) ptr=0x11c7bf0aca0 at 11c7d11cad0>)
2024-10-21 12:35:29,052 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo, trying IProvideClassInfo2
2024-10-21 12:35:29,052 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo/IProvideClassInfo2
2024-10-21 12:35:29,067 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x11c7b8dca30 at 11c7d11ccd0>
2024-10-21 12:35:29,067 - comtypes.client - DEBUG - Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}
2024-10-21 12:35:29,068 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x11c7bf0aca0 at 11c7d11cdd0>
2024-10-21 12:35:29,068 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:35:29,068 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>
2024-10-21 12:35:29,069 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechObjectToken) ptr=0x11c7bf0aca0 at 11c7d11ccd0>
2024-10-21 12:35:29,069 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x11c7bf0aca0 at 11c7d11cc50>
2024-10-21 12:35:29,069 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x11c7b8dca30 at 11c7d11cd50>
2024-10-21 12:35:29,069 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x11c7b6fd0a0 at 11c7d11cdd0>
2024-10-21 12:35:29,070 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x11c7bf0aca0 at 11c7d11cad0>
2024-10-21 12:35:29,070 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IEnumVARIANT) ptr=0x11c7bff7880 at 11c7d11c950>
2024-10-21 12:35:29,071 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectTokens) ptr=0x11c7bfce5d0 at 11c7d11c7d0>
2024-10-21 12:35:29,071 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x11c7bf0aca0 at 11c7d11ccd0>
2024-10-21 12:35:29,072 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:35:29,073 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:35:29,348 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:35:29,348 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:35:29,768 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2024-10-21 12:35:30,469 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/Systran/faster-whisper-base/revision/main HTTP/1.1" 200 1848
2024-10-21 12:35:31,160 - __main__ - INFO - Siri instance initialized
2024-10-21 12:35:39,196 - faster_whisper - INFO - Processing audio with duration 00:01.393
2024-10-21 12:35:39,875 - faster_whisper - INFO - Detected language 'en' with probability 0.41
2024-10-21 12:35:39,876 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:35:40,008 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:35:40,086 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:35:40,086 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:35:40,201 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C802E9D00>
2024-10-21 12:35:40,201 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000011C7D11C9D0> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:35:40,318 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C802E9940>
2024-10-21 12:35:40,318 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:35:40,318 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:35:40,318 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:35:40,318 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:35:40,318 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:35:40,818 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:35:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19881'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'357ms'), (b'x-request-id', b'req_01jaq6xajmenwvvyheqqhq3djs'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=x91_HDfL.vWGABybpXfRUGCD1cAYmQa7anM8JxoioTk-1729503341-1.0.1.1-rDrJ1EUUw1pNZdRLLunl2P31dz4yvs0tiX.hVGcwstWmeshIBo3TX1OTHpuhlrbMwADHO32pRRqtdjb2EqmtIA; path=/; expires=Mon, 21-Oct-24 10:05:41 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6042491baf73da-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:35:40,818 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:35:40,818 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:35:40,818 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:35:40,818 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:35:40,818 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:35:40,818 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:35:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19881', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '357ms', 'x-request-id': 'req_01jaq6xajmenwvvyheqqhq3djs', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=x91_HDfL.vWGABybpXfRUGCD1cAYmQa7anM8JxoioTk-1729503341-1.0.1.1-rDrJ1EUUw1pNZdRLLunl2P31dz4yvs0tiX.hVGcwstWmeshIBo3TX1OTHpuhlrbMwADHO32pRRqtdjb2EqmtIA; path=/; expires=Mon, 21-Oct-24 10:05:41 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8d6042491baf73da-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:35:40,818 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:35:40,818 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:35:40,818 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:35:40,831 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:35:40,832 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:35:40,832 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:35:40,832 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:35:41,418 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:35:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19827'), (b'x-ratelimit-reset-requests', b'11.477s'), (b'x-ratelimit-reset-tokens', b'519ms'), (b'x-request-id', b'req_01jaq6xb2zfwk8f0v53y0n5nvg'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60424c480c73da-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:35:41,418 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:35:41,418 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:35:41,418 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:35:41,418 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:35:41,418 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:35:41,418 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:35:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19827', 'x-ratelimit-reset-requests': '11.477s', 'x-ratelimit-reset-tokens': '519ms', 'x-request-id': 'req_01jaq6xb2zfwk8f0v53y0n5nvg', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60424c480c73da-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:35:41,418 - gtts.tts - DEBUG - text: I'm a multi-modal AI voice assistant designed to provide informative and helpful responses to your questions and engage in conversations based on the context you provide whether it's through voice commands, text prompts, or visual aids like photos.
2024-10-21 12:35:41,433 - gtts.tts - DEBUG - tld: com
2024-10-21 12:35:41,434 - gtts.tts - DEBUG - lang: en
2024-10-21 12:35:41,434 - gtts.tts - DEBUG - slow: False
2024-10-21 12:35:41,434 - gtts.tts - DEBUG - lang_check: True
2024-10-21 12:35:41,435 - gtts.tts - DEBUG - pre_processor_funcs: [<function tone_marks at 0x0000011C7BA687C0>, <function end_of_line at 0x0000011C7BA68860>, <function abbreviations at 0x0000011C7BA68900>, <function word_sub at 0x0000011C7BA691C0>]
2024-10-21 12:35:41,443 - gtts.tts - DEBUG - timeout: None
2024-10-21 12:35:41,443 - gtts.lang - DEBUG - langs: {'af': 'Afrikaans', 'am': 'Amharic', 'ar': 'Arabic', 'bg': 'Bulgarian', 'bn': 'Bengali', 'bs': 'Bosnian', 'ca': 'Catalan', 'cs': 'Czech', 'cy': 'Welsh', 'da': 'Danish', 'de': 'German', 'el': 'Greek', 'en': 'English', 'es': 'Spanish', 'et': 'Estonian', 'eu': 'Basque', 'fi': 'Finnish', 'fr': 'French', 'gl': 'Galician', 'gu': 'Gujarati', 'ha': 'Hausa', 'hi': 'Hindi', 'hr': 'Croatian', 'hu': 'Hungarian', 'id': 'Indonesian', 'is': 'Icelandic', 'it': 'Italian', 'iw': 'Hebrew', 'ja': 'Japanese', 'jw': 'Javanese', 'km': 'Khmer', 'kn': 'Kannada', 'ko': 'Korean', 'la': 'Latin', 'lt': 'Lithuanian', 'lv': 'Latvian', 'ml': 'Malayalam', 'mr': 'Marathi', 'ms': 'Malay', 'my': 'Myanmar (Burmese)', 'ne': 'Nepali', 'nl': 'Dutch', 'no': 'Norwegian', 'pa': 'Punjabi (Gurmukhi)', 'pl': 'Polish', 'pt': 'Portuguese (Brazil)', 'pt-PT': 'Portuguese (Portugal)', 'ro': 'Romanian', 'ru': 'Russian', 'si': 'Sinhala', 'sk': 'Slovak', 'sq': 'Albanian', 'sr': 'Serbian', 'su': 'Sundanese', 'sv': 'Swedish', 'sw': 'Swahili', 'ta': 'Tamil', 'te': 'Telugu', 'th': 'Thai', 'tl': 'Filipino', 'tr': 'Turkish', 'uk': 'Ukrainian', 'ur': 'Urdu', 'vi': 'Vietnamese', 'yue': 'Cantonese', 'zh-CN': 'Chinese (Simplified)', 'zh-TW': 'Chinese (Mandarin/Taiwan)', 'zh': 'Chinese (Mandarin)'}
2024-10-21 12:35:41,445 - gtts.tts - DEBUG - pre-processing: <function tone_marks at 0x0000011C7BA687C0>
2024-10-21 12:35:41,445 - gtts.tts - DEBUG - pre-processing: <function end_of_line at 0x0000011C7BA68860>
2024-10-21 12:35:41,445 - gtts.tts - DEBUG - pre-processing: <function abbreviations at 0x0000011C7BA68900>
2024-10-21 12:35:41,446 - gtts.tts - DEBUG - pre-processing: <function word_sub at 0x0000011C7BA691C0>
2024-10-21 12:35:41,451 - gtts.tts - DEBUG - text_parts: ["I'm a multi-modal AI voice assistant designed to provide informative and helpful responses to your", "questions and engage in conversations based on the context you provide whether it's through voice", 'commands', 'text prompts', 'or visual aids like photos.']
2024-10-21 12:35:41,451 - gtts.tts - DEBUG - text_parts: 5
2024-10-21 12:35:41,451 - gtts.tts - DEBUG - data-0: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22I%27m%20a%20multi-modal%20AI%20voice%20assistant%20designed%20to%20provide%20informative%20and%20helpful%20responses%20to%20your%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:35:41,451 - gtts.tts - DEBUG - data-1: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22questions%20and%20engage%20in%20conversations%20based%20on%20the%20context%20you%20provide%20whether%20it%27s%20through%20voice%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:35:41,451 - gtts.tts - DEBUG - data-2: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22commands%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:35:41,451 - gtts.tts - DEBUG - data-3: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22text%20prompts%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:35:41,451 - gtts.tts - DEBUG - data-4: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22or%20visual%20aids%20like%20photos.%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:35:41,451 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:35:42,518 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:35:42,880 - gtts.tts - DEBUG - headers-0: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '258'}
2024-10-21 12:35:42,880 - gtts.tts - DEBUG - url-0: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:35:42,880 - gtts.tts - DEBUG - status-0: 200
2024-10-21 12:35:42,884 - gtts.tts - DEBUG - part-0 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:35:42,884 - gtts.tts - DEBUG - part-0 created
2024-10-21 12:35:42,885 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:35:43,894 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:35:44,411 - gtts.tts - DEBUG - headers-1: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '257'}
2024-10-21 12:35:44,411 - gtts.tts - DEBUG - url-1: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:35:44,411 - gtts.tts - DEBUG - status-1: 200
2024-10-21 12:35:44,426 - gtts.tts - DEBUG - part-1 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:35:44,426 - gtts.tts - DEBUG - part-1 created
2024-10-21 12:35:44,426 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:35:45,540 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:35:45,648 - gtts.tts - DEBUG - headers-2: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '138'}
2024-10-21 12:35:45,649 - gtts.tts - DEBUG - url-2: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:35:45,649 - gtts.tts - DEBUG - status-2: 200
2024-10-21 12:35:45,649 - gtts.tts - DEBUG - part-2 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:35:45,650 - gtts.tts - DEBUG - part-2 created
2024-10-21 12:35:45,650 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:35:46,416 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:35:46,485 - gtts.tts - DEBUG - headers-3: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '144'}
2024-10-21 12:35:46,485 - gtts.tts - DEBUG - url-3: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:35:46,485 - gtts.tts - DEBUG - status-3: 200
2024-10-21 12:35:46,501 - gtts.tts - DEBUG - part-3 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:35:46,501 - gtts.tts - DEBUG - part-3 created
2024-10-21 12:35:46,502 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:35:47,390 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:35:47,548 - gtts.tts - DEBUG - headers-4: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '165'}
2024-10-21 12:35:47,548 - gtts.tts - DEBUG - url-4: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:35:47,548 - gtts.tts - DEBUG - status-4: 200
2024-10-21 12:35:47,548 - gtts.tts - DEBUG - part-4 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:35:47,548 - gtts.tts - DEBUG - part-4 created
2024-10-21 12:35:47,548 - gtts.tts - DEBUG - Saved to C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\ai_response\ai_response_audio.mp3
2024-10-21 12:35:48,016 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-f', 'mp3', '-i', 'C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
2024-10-21 12:36:18,667 - faster_whisper - INFO - Processing audio with duration 00:07.338
2024-10-21 12:36:19,311 - faster_whisper - INFO - Detected language 'en' with probability 0.46
2024-10-21 12:36:19,311 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:36:19,450 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.0 (-1.120089 < -1.000000)
2024-10-21 12:36:19,771 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.2 (-1.113496 < -1.000000)
2024-10-21 12:36:20,050 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.4 (-1.232417 < -1.000000)
2024-10-21 12:36:20,383 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.6 (-1.329542 < -1.000000)
2024-10-21 12:36:20,736 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.8 (-1.434691 < -1.000000)
2024-10-21 12:36:21,096 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 1.0 (-2.213074 < -1.000000)
2024-10-21 12:36:21,096 - faster_whisper - DEBUG - Reset prompt. prompt_reset_on_temperature threshold is met 1.000000 > 0.500000
2024-10-21 12:36:21,096 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': "I think I'll be the first to"}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:36:21,096 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:36:21,108 - httpcore.connection - DEBUG - close.started
2024-10-21 12:36:21,109 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:36:21,109 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:36:21,284 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C802EB9B0>
2024-10-21 12:36:21,284 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000011C7D11C9D0> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:36:21,564 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C802EA4E0>
2024-10-21 12:36:21,565 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:36:21,566 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:36:21,566 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:36:21,566 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:36:21,566 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:36:22,134 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:36:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19874'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'378ms'), (b'x-request-id', b'req_01jaq6yjxkf3jtwevc3a7h4652'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60434b4a0a7406-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:36:22,134 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:36:22,134 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:36:22,134 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:36:22,134 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:36:22,134 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:36:22,134 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:36:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19874', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '378ms', 'x-request-id': 'req_01jaq6yjxkf3jtwevc3a7h4652', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60434b4a0a7406-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:36:23,070 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2024-10-21 12:36:23,070 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 8192
2024-10-21 12:36:26,133 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': "I'm a multi-modal AI voice assistant designed to provide informative and helpful responses to your questions and engage in conversations based on the context you provide whether it's through voice commands, text prompts, or visual aids like photos."}, {'role': 'user', 'content': "USER_PROMPT: I think I'll be the first to\n\nIMAGE_CONTEXT: The image is a black screen. There are no objects or people in the image.  It is impossible to determine any relevant information about the user's statement in relation to the image.  The user is likely making a statement about something else, rather than the image. \n"}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:36:26,133 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:36:26,133 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:36:26,133 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:36:26,133 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:36:26,133 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:36:26,149 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:36:26,882 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:36:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19674'), (b'x-ratelimit-reset-requests', b'7.368999999s'), (b'x-ratelimit-reset-tokens', b'978ms'), (b'x-request-id', b'req_01jaq6yqebe5frrwjhweyybyzg'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d604367ef6c7406-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:36:26,886 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:36:26,886 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:36:26,886 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:36:26,886 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:36:26,886 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:36:26,886 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:36:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19674', 'x-ratelimit-reset-requests': '7.368999999s', 'x-ratelimit-reset-tokens': '978ms', 'x-request-id': 'req_01jaq6yqebe5frrwjhweyybyzg', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d604367ef6c7406-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:36:26,890 - gtts.tts - DEBUG - text: Based on the voice input and considering the image context, it seems like you're making a general statement about being the first, which might be referring to an achievement, a discovery, or something similar, but without further information or context, it's difficult to provide a specific response, could you please provide more context or clarify what you mean.
2024-10-21 12:36:26,890 - gtts.tts - DEBUG - tld: com
2024-10-21 12:36:26,890 - gtts.tts - DEBUG - lang: en
2024-10-21 12:36:26,890 - gtts.tts - DEBUG - slow: False
2024-10-21 12:36:26,892 - gtts.tts - DEBUG - lang_check: True
2024-10-21 12:36:26,892 - gtts.tts - DEBUG - pre_processor_funcs: [<function tone_marks at 0x0000011C7BA687C0>, <function end_of_line at 0x0000011C7BA68860>, <function abbreviations at 0x0000011C7BA68900>, <function word_sub at 0x0000011C7BA691C0>]
2024-10-21 12:36:26,896 - gtts.tts - DEBUG - timeout: None
2024-10-21 12:36:26,897 - gtts.lang - DEBUG - langs: {'af': 'Afrikaans', 'am': 'Amharic', 'ar': 'Arabic', 'bg': 'Bulgarian', 'bn': 'Bengali', 'bs': 'Bosnian', 'ca': 'Catalan', 'cs': 'Czech', 'cy': 'Welsh', 'da': 'Danish', 'de': 'German', 'el': 'Greek', 'en': 'English', 'es': 'Spanish', 'et': 'Estonian', 'eu': 'Basque', 'fi': 'Finnish', 'fr': 'French', 'gl': 'Galician', 'gu': 'Gujarati', 'ha': 'Hausa', 'hi': 'Hindi', 'hr': 'Croatian', 'hu': 'Hungarian', 'id': 'Indonesian', 'is': 'Icelandic', 'it': 'Italian', 'iw': 'Hebrew', 'ja': 'Japanese', 'jw': 'Javanese', 'km': 'Khmer', 'kn': 'Kannada', 'ko': 'Korean', 'la': 'Latin', 'lt': 'Lithuanian', 'lv': 'Latvian', 'ml': 'Malayalam', 'mr': 'Marathi', 'ms': 'Malay', 'my': 'Myanmar (Burmese)', 'ne': 'Nepali', 'nl': 'Dutch', 'no': 'Norwegian', 'pa': 'Punjabi (Gurmukhi)', 'pl': 'Polish', 'pt': 'Portuguese (Brazil)', 'pt-PT': 'Portuguese (Portugal)', 'ro': 'Romanian', 'ru': 'Russian', 'si': 'Sinhala', 'sk': 'Slovak', 'sq': 'Albanian', 'sr': 'Serbian', 'su': 'Sundanese', 'sv': 'Swedish', 'sw': 'Swahili', 'ta': 'Tamil', 'te': 'Telugu', 'th': 'Thai', 'tl': 'Filipino', 'tr': 'Turkish', 'uk': 'Ukrainian', 'ur': 'Urdu', 'vi': 'Vietnamese', 'yue': 'Cantonese', 'zh-CN': 'Chinese (Simplified)', 'zh-TW': 'Chinese (Mandarin/Taiwan)', 'zh': 'Chinese (Mandarin)'}
2024-10-21 12:36:26,898 - gtts.tts - DEBUG - pre-processing: <function tone_marks at 0x0000011C7BA687C0>
2024-10-21 12:36:26,898 - gtts.tts - DEBUG - pre-processing: <function end_of_line at 0x0000011C7BA68860>
2024-10-21 12:36:26,898 - gtts.tts - DEBUG - pre-processing: <function abbreviations at 0x0000011C7BA68900>
2024-10-21 12:36:26,898 - gtts.tts - DEBUG - pre-processing: <function word_sub at 0x0000011C7BA691C0>
2024-10-21 12:36:26,905 - gtts.tts - DEBUG - text_parts: ['Based on the voice input and considering the image context', "it seems like you're making a general statement about being the first", 'which might be referring to an achievement', 'a discovery', 'or something similar', 'but without further information or context', "it's difficult to provide a specific response", 'could you please provide more context or clarify what you mean.']
2024-10-21 12:36:26,905 - gtts.tts - DEBUG - text_parts: 8
2024-10-21 12:36:26,906 - gtts.tts - DEBUG - data-0: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22Based%20on%20the%20voice%20input%20and%20considering%20the%20image%20context%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:36:26,906 - gtts.tts - DEBUG - data-1: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22it%20seems%20like%20you%27re%20making%20a%20general%20statement%20about%20being%20the%20first%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:36:26,906 - gtts.tts - DEBUG - data-2: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22which%20might%20be%20referring%20to%20an%20achievement%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:36:26,906 - gtts.tts - DEBUG - data-3: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22a%20discovery%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:36:26,906 - gtts.tts - DEBUG - data-4: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22or%20something%20similar%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:36:26,906 - gtts.tts - DEBUG - data-5: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22but%20without%20further%20information%20or%20context%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:36:26,906 - gtts.tts - DEBUG - data-6: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22it%27s%20difficult%20to%20provide%20a%20specific%20response%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:36:26,906 - gtts.tts - DEBUG - data-7: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22could%20you%20please%20provide%20more%20context%20or%20clarify%20what%20you%20mean.%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:36:26,906 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:36:27,734 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:36:27,934 - gtts.tts - DEBUG - headers-0: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '206'}
2024-10-21 12:36:27,949 - gtts.tts - DEBUG - url-0: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:36:27,950 - gtts.tts - DEBUG - status-0: 200
2024-10-21 12:36:27,950 - gtts.tts - DEBUG - part-0 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:36:27,950 - gtts.tts - DEBUG - part-0 created
2024-10-21 12:36:27,950 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:36:28,983 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:36:29,305 - gtts.tts - DEBUG - headers-1: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '223'}
2024-10-21 12:36:29,320 - gtts.tts - DEBUG - url-1: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:36:29,320 - gtts.tts - DEBUG - status-1: 200
2024-10-21 12:36:29,320 - gtts.tts - DEBUG - part-1 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:36:29,323 - gtts.tts - DEBUG - part-1 created
2024-10-21 12:36:29,323 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:36:30,336 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:36:30,537 - gtts.tts - DEBUG - headers-2: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '184'}
2024-10-21 12:36:30,537 - gtts.tts - DEBUG - url-2: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:36:30,537 - gtts.tts - DEBUG - status-2: 200
2024-10-21 12:36:30,537 - gtts.tts - DEBUG - part-2 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:36:30,537 - gtts.tts - DEBUG - part-2 created
2024-10-21 12:36:30,537 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:36:31,462 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:36:31,502 - gtts.tts - DEBUG - headers-3: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '143'}
2024-10-21 12:36:31,502 - gtts.tts - DEBUG - url-3: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:36:31,502 - gtts.tts - DEBUG - status-3: 200
2024-10-21 12:36:31,503 - gtts.tts - DEBUG - part-3 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:36:31,503 - gtts.tts - DEBUG - part-3 created
2024-10-21 12:36:31,503 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:36:32,481 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:36:32,632 - gtts.tts - DEBUG - headers-4: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '154'}
2024-10-21 12:36:32,632 - gtts.tts - DEBUG - url-4: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:36:32,632 - gtts.tts - DEBUG - status-4: 200
2024-10-21 12:36:32,632 - gtts.tts - DEBUG - part-4 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:36:32,632 - gtts.tts - DEBUG - part-4 created
2024-10-21 12:36:32,648 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:36:33,610 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:36:33,812 - gtts.tts - DEBUG - headers-5: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '182'}
2024-10-21 12:36:33,812 - gtts.tts - DEBUG - url-5: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:36:33,812 - gtts.tts - DEBUG - status-5: 200
2024-10-21 12:36:33,812 - gtts.tts - DEBUG - part-5 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:36:33,812 - gtts.tts - DEBUG - part-5 created
2024-10-21 12:36:33,828 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:36:34,788 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:36:35,011 - gtts.tts - DEBUG - headers-6: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '189'}
2024-10-21 12:36:35,011 - gtts.tts - DEBUG - url-6: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:36:35,011 - gtts.tts - DEBUG - status-6: 200
2024-10-21 12:36:35,011 - gtts.tts - DEBUG - part-6 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:36:35,011 - gtts.tts - DEBUG - part-6 created
2024-10-21 12:36:35,011 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:36:36,737 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:36:36,948 - gtts.tts - DEBUG - headers-7: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '213'}
2024-10-21 12:36:36,948 - gtts.tts - DEBUG - url-7: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:36:36,948 - gtts.tts - DEBUG - status-7: 200
2024-10-21 12:36:36,948 - gtts.tts - DEBUG - part-7 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:36:36,948 - gtts.tts - DEBUG - part-7 created
2024-10-21 12:36:36,948 - gtts.tts - DEBUG - Saved to C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\ai_response\ai_response_audio.mp3
2024-10-21 12:36:36,994 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-f', 'mp3', '-i', 'C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
2024-10-21 12:37:13,061 - faster_whisper - INFO - Processing audio with duration 00:08.661
2024-10-21 12:37:13,716 - faster_whisper - INFO - Detected language 'en' with probability 0.89
2024-10-21 12:37:13,716 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:37:13,829 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Can you give directions?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:37:13,830 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:37:13,831 - httpcore.connection - DEBUG - close.started
2024-10-21 12:37:13,831 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:37:13,831 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:37:13,933 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C82645040>
2024-10-21 12:37:13,933 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000011C7D11C9D0> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:37:14,078 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C82646E70>
2024-10-21 12:37:14,078 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:37:14,078 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:37:14,078 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:37:14,078 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:37:14,078 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:37:14,566 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:37:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19875'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'375ms'), (b'x-request-id', b'req_01jaq7064rf3nb8w7b4ac17qxm'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6044932e2873fe-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:37:14,566 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:37:14,566 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:37:14,566 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:37:14,566 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:37:14,566 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:37:14,566 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:37:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19875', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '375ms', 'x-request-id': 'req_01jaq7064rf3nb8w7b4ac17qxm', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6044932e2873fe-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:37:14,566 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': "I'm a multi-modal AI voice assistant designed to provide informative and helpful responses to your questions and engage in conversations based on the context you provide whether it's through voice commands, text prompts, or visual aids like photos."}, {'role': 'user', 'content': "USER_PROMPT: I think I'll be the first to\n\nIMAGE_CONTEXT: The image is a black screen. There are no objects or people in the image.  It is impossible to determine any relevant information about the user's statement in relation to the image.  The user is likely making a statement about something else, rather than the image. \n"}, {'role': 'assistant', 'content': "Based on the voice input and considering the image context, it seems like you're making a general statement about being the first, which might be referring to an achievement, a discovery, or something similar, but without further information or context, it's difficult to provide a specific response, could you please provide more context or clarify what you mean."}, {'role': 'user', 'content': 'Can you give directions?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:37:14,580 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:37:14,580 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:37:14,581 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:37:14,581 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:37:14,582 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:37:14,582 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:37:15,166 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:37:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19567'), (b'x-ratelimit-reset-requests', b'11.527s'), (b'x-ratelimit-reset-tokens', b'1.299s'), (b'x-request-id', b'req_01jaq706knfv4swecfs7jxtycw'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6044962af773fe-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:37:15,166 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:37:15,166 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:37:15,166 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:37:15,166 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:37:15,166 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:37:15,166 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:37:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19567', 'x-ratelimit-reset-requests': '11.527s', 'x-ratelimit-reset-tokens': '1.299s', 'x-request-id': 'req_01jaq706knfv4swecfs7jxtycw', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6044962af773fe-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:37:15,166 - gtts.tts - DEBUG - text: You're looking for directions, is there a specific location or destination in mind or is there something else I can help with like providing navigation or assisting with route planning, please provide more context or clarify your request.
2024-10-21 12:37:15,166 - gtts.tts - DEBUG - tld: com
2024-10-21 12:37:15,166 - gtts.tts - DEBUG - lang: en
2024-10-21 12:37:15,166 - gtts.tts - DEBUG - slow: False
2024-10-21 12:37:15,173 - gtts.tts - DEBUG - lang_check: True
2024-10-21 12:37:15,173 - gtts.tts - DEBUG - pre_processor_funcs: [<function tone_marks at 0x0000011C7BA687C0>, <function end_of_line at 0x0000011C7BA68860>, <function abbreviations at 0x0000011C7BA68900>, <function word_sub at 0x0000011C7BA691C0>]
2024-10-21 12:37:15,178 - gtts.tts - DEBUG - timeout: None
2024-10-21 12:37:15,178 - gtts.lang - DEBUG - langs: {'af': 'Afrikaans', 'am': 'Amharic', 'ar': 'Arabic', 'bg': 'Bulgarian', 'bn': 'Bengali', 'bs': 'Bosnian', 'ca': 'Catalan', 'cs': 'Czech', 'cy': 'Welsh', 'da': 'Danish', 'de': 'German', 'el': 'Greek', 'en': 'English', 'es': 'Spanish', 'et': 'Estonian', 'eu': 'Basque', 'fi': 'Finnish', 'fr': 'French', 'gl': 'Galician', 'gu': 'Gujarati', 'ha': 'Hausa', 'hi': 'Hindi', 'hr': 'Croatian', 'hu': 'Hungarian', 'id': 'Indonesian', 'is': 'Icelandic', 'it': 'Italian', 'iw': 'Hebrew', 'ja': 'Japanese', 'jw': 'Javanese', 'km': 'Khmer', 'kn': 'Kannada', 'ko': 'Korean', 'la': 'Latin', 'lt': 'Lithuanian', 'lv': 'Latvian', 'ml': 'Malayalam', 'mr': 'Marathi', 'ms': 'Malay', 'my': 'Myanmar (Burmese)', 'ne': 'Nepali', 'nl': 'Dutch', 'no': 'Norwegian', 'pa': 'Punjabi (Gurmukhi)', 'pl': 'Polish', 'pt': 'Portuguese (Brazil)', 'pt-PT': 'Portuguese (Portugal)', 'ro': 'Romanian', 'ru': 'Russian', 'si': 'Sinhala', 'sk': 'Slovak', 'sq': 'Albanian', 'sr': 'Serbian', 'su': 'Sundanese', 'sv': 'Swedish', 'sw': 'Swahili', 'ta': 'Tamil', 'te': 'Telugu', 'th': 'Thai', 'tl': 'Filipino', 'tr': 'Turkish', 'uk': 'Ukrainian', 'ur': 'Urdu', 'vi': 'Vietnamese', 'yue': 'Cantonese', 'zh-CN': 'Chinese (Simplified)', 'zh-TW': 'Chinese (Mandarin/Taiwan)', 'zh': 'Chinese (Mandarin)'}
2024-10-21 12:37:15,178 - gtts.tts - DEBUG - pre-processing: <function tone_marks at 0x0000011C7BA687C0>
2024-10-21 12:37:15,178 - gtts.tts - DEBUG - pre-processing: <function end_of_line at 0x0000011C7BA68860>
2024-10-21 12:37:15,178 - gtts.tts - DEBUG - pre-processing: <function abbreviations at 0x0000011C7BA68900>
2024-10-21 12:37:15,178 - gtts.tts - DEBUG - pre-processing: <function word_sub at 0x0000011C7BA691C0>
2024-10-21 12:37:15,184 - gtts.tts - DEBUG - text_parts: ["You're looking for directions", 'is there a specific location or destination in mind or is there something else I can help with like', 'providing navigation or assisting with route planning', 'please provide more context or clarify your request']
2024-10-21 12:37:15,185 - gtts.tts - DEBUG - text_parts: 4
2024-10-21 12:37:15,185 - gtts.tts - DEBUG - data-0: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22You%27re%20looking%20for%20directions%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:37:15,185 - gtts.tts - DEBUG - data-1: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22is%20there%20a%20specific%20location%20or%20destination%20in%20mind%20or%20is%20there%20something%20else%20I%20can%20help%20with%20like%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:37:15,186 - gtts.tts - DEBUG - data-2: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22providing%20navigation%20or%20assisting%20with%20route%20planning%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:37:15,186 - gtts.tts - DEBUG - data-3: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22please%20provide%20more%20context%20or%20clarify%20your%20request%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:37:15,187 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:37:16,166 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:37:16,284 - gtts.tts - DEBUG - headers-0: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '167'}
2024-10-21 12:37:16,284 - gtts.tts - DEBUG - url-0: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:37:16,284 - gtts.tts - DEBUG - status-0: 200
2024-10-21 12:37:16,284 - gtts.tts - DEBUG - part-0 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:37:16,284 - gtts.tts - DEBUG - part-0 created
2024-10-21 12:37:16,284 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:37:17,233 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:37:17,483 - gtts.tts - DEBUG - headers-1: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '265'}
2024-10-21 12:37:17,483 - gtts.tts - DEBUG - url-1: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:37:17,483 - gtts.tts - DEBUG - status-1: 200
2024-10-21 12:37:17,483 - gtts.tts - DEBUG - part-1 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:37:17,483 - gtts.tts - DEBUG - part-1 created
2024-10-21 12:37:17,483 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:37:18,321 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:37:18,516 - gtts.tts - DEBUG - headers-2: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '195'}
2024-10-21 12:37:18,516 - gtts.tts - DEBUG - url-2: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:37:18,516 - gtts.tts - DEBUG - status-2: 200
2024-10-21 12:37:18,516 - gtts.tts - DEBUG - part-2 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:37:18,516 - gtts.tts - DEBUG - part-2 created
2024-10-21 12:37:18,516 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:37:19,468 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:37:19,766 - gtts.tts - DEBUG - headers-3: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '195'}
2024-10-21 12:37:19,766 - gtts.tts - DEBUG - url-3: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:37:19,766 - gtts.tts - DEBUG - status-3: 200
2024-10-21 12:37:19,766 - gtts.tts - DEBUG - part-3 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:37:19,766 - gtts.tts - DEBUG - part-3 created
2024-10-21 12:37:19,766 - gtts.tts - DEBUG - Saved to C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\ai_response\ai_response_audio.mp3
2024-10-21 12:37:19,806 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-f', 'mp3', '-i', 'C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
2024-10-21 12:37:52,511 - faster_whisper - INFO - Processing audio with duration 00:14.675
2024-10-21 12:37:53,148 - faster_whisper - INFO - Detected language 'en' with probability 0.47
2024-10-21 12:37:53,148 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:37:53,312 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Can you give directions from Strathmo University to Karin?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:37:53,312 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:37:53,312 - httpcore.connection - DEBUG - close.started
2024-10-21 12:37:53,312 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:37:53,312 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:37:53,438 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C826666C0>
2024-10-21 12:37:53,438 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000011C7D11C9D0> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:37:53,589 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C82665CA0>
2024-10-21 12:37:53,590 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:37:53,591 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:37:53,591 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:37:53,591 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:37:53,592 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:37:54,149 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:37:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19867'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'399ms'), (b'x-request-id', b'req_01jaq71crxecrac2ph8p8bgt8e'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60458a598173c8-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:37:54,164 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:37:54,164 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:37:54,165 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:37:54,165 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:37:54,165 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:37:54,165 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:37:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19867', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '399ms', 'x-request-id': 'req_01jaq71crxecrac2ph8p8bgt8e', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60458a598173c8-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:37:54,165 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': "I'm a multi-modal AI voice assistant designed to provide informative and helpful responses to your questions and engage in conversations based on the context you provide whether it's through voice commands, text prompts, or visual aids like photos."}, {'role': 'user', 'content': "USER_PROMPT: I think I'll be the first to\n\nIMAGE_CONTEXT: The image is a black screen. There are no objects or people in the image.  It is impossible to determine any relevant information about the user's statement in relation to the image.  The user is likely making a statement about something else, rather than the image. \n"}, {'role': 'assistant', 'content': "Based on the voice input and considering the image context, it seems like you're making a general statement about being the first, which might be referring to an achievement, a discovery, or something similar, but without further information or context, it's difficult to provide a specific response, could you please provide more context or clarify what you mean."}, {'role': 'user', 'content': 'Can you give directions?'}, {'role': 'assistant', 'content': "You're looking for directions, is there a specific location or destination in mind or is there something else I can help with like providing navigation or assisting with route planning, please provide more context or clarify your request."}, {'role': 'user', 'content': 'Can you give directions from Strathmo University to Karin?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:37:54,172 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:37:54,173 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:37:54,173 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:37:54,174 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:37:54,174 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:37:54,175 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:37:54,881 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:37:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19484'), (b'x-ratelimit-reset-requests', b'11.411s'), (b'x-ratelimit-reset-tokens', b'1.548s'), (b'x-request-id', b'req_01jaq71dbaf3q820zmn34xyc4f'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60458dff3b73c8-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:37:54,881 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:37:54,883 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:37:54,883 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:37:54,884 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:37:54,884 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:37:54,884 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:37:55 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19484', 'x-ratelimit-reset-requests': '11.411s', 'x-ratelimit-reset-tokens': '1.548s', 'x-request-id': 'req_01jaq71dbaf3q820zmn34xyc4f', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60458dff3b73c8-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:37:54,886 - gtts.tts - DEBUG - text: However, I need more specific information about Strathmo University and Karin to provide accurate directions. Could you please provide the name of the city or area where Strathmo University is located, and also clarify Karin, is that a location, a person, or something else, providing more context will help me provide a more accurate response.
2024-10-21 12:37:54,886 - gtts.tts - DEBUG - tld: com
2024-10-21 12:37:54,886 - gtts.tts - DEBUG - lang: en
2024-10-21 12:37:54,887 - gtts.tts - DEBUG - slow: False
2024-10-21 12:37:54,887 - gtts.tts - DEBUG - lang_check: True
2024-10-21 12:37:54,887 - gtts.tts - DEBUG - pre_processor_funcs: [<function tone_marks at 0x0000011C7BA687C0>, <function end_of_line at 0x0000011C7BA68860>, <function abbreviations at 0x0000011C7BA68900>, <function word_sub at 0x0000011C7BA691C0>]
2024-10-21 12:37:54,891 - gtts.tts - DEBUG - timeout: None
2024-10-21 12:37:54,892 - gtts.lang - DEBUG - langs: {'af': 'Afrikaans', 'am': 'Amharic', 'ar': 'Arabic', 'bg': 'Bulgarian', 'bn': 'Bengali', 'bs': 'Bosnian', 'ca': 'Catalan', 'cs': 'Czech', 'cy': 'Welsh', 'da': 'Danish', 'de': 'German', 'el': 'Greek', 'en': 'English', 'es': 'Spanish', 'et': 'Estonian', 'eu': 'Basque', 'fi': 'Finnish', 'fr': 'French', 'gl': 'Galician', 'gu': 'Gujarati', 'ha': 'Hausa', 'hi': 'Hindi', 'hr': 'Croatian', 'hu': 'Hungarian', 'id': 'Indonesian', 'is': 'Icelandic', 'it': 'Italian', 'iw': 'Hebrew', 'ja': 'Japanese', 'jw': 'Javanese', 'km': 'Khmer', 'kn': 'Kannada', 'ko': 'Korean', 'la': 'Latin', 'lt': 'Lithuanian', 'lv': 'Latvian', 'ml': 'Malayalam', 'mr': 'Marathi', 'ms': 'Malay', 'my': 'Myanmar (Burmese)', 'ne': 'Nepali', 'nl': 'Dutch', 'no': 'Norwegian', 'pa': 'Punjabi (Gurmukhi)', 'pl': 'Polish', 'pt': 'Portuguese (Brazil)', 'pt-PT': 'Portuguese (Portugal)', 'ro': 'Romanian', 'ru': 'Russian', 'si': 'Sinhala', 'sk': 'Slovak', 'sq': 'Albanian', 'sr': 'Serbian', 'su': 'Sundanese', 'sv': 'Swedish', 'sw': 'Swahili', 'ta': 'Tamil', 'te': 'Telugu', 'th': 'Thai', 'tl': 'Filipino', 'tr': 'Turkish', 'uk': 'Ukrainian', 'ur': 'Urdu', 'vi': 'Vietnamese', 'yue': 'Cantonese', 'zh-CN': 'Chinese (Simplified)', 'zh-TW': 'Chinese (Mandarin/Taiwan)', 'zh': 'Chinese (Mandarin)'}
2024-10-21 12:37:54,893 - gtts.tts - DEBUG - pre-processing: <function tone_marks at 0x0000011C7BA687C0>
2024-10-21 12:37:54,893 - gtts.tts - DEBUG - pre-processing: <function end_of_line at 0x0000011C7BA68860>
2024-10-21 12:37:54,893 - gtts.tts - DEBUG - pre-processing: <function abbreviations at 0x0000011C7BA68900>
2024-10-21 12:37:54,893 - gtts.tts - DEBUG - pre-processing: <function word_sub at 0x0000011C7BA691C0>
2024-10-21 12:37:54,896 - gtts.tts - DEBUG - text_parts: ['However', 'I need more specific information about Strathmo University and Karin to provide accurate directions', 'Could you please provide the name of the city or area where Strathmo University is located', 'and also clarify Karin', 'is that a location', 'a person', 'or something else', 'providing more context will help me provide a more accurate response.']
2024-10-21 12:37:54,896 - gtts.tts - DEBUG - text_parts: 8
2024-10-21 12:37:54,897 - gtts.tts - DEBUG - data-0: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22However%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:37:54,898 - gtts.tts - DEBUG - data-1: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22I%20need%20more%20specific%20information%20about%20Strathmo%20University%20and%20Karin%20to%20provide%20accurate%20directions%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:37:54,898 - gtts.tts - DEBUG - data-2: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22Could%20you%20please%20provide%20the%20name%20of%20the%20city%20or%20area%20where%20Strathmo%20University%20is%20located%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:37:54,899 - gtts.tts - DEBUG - data-3: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22and%20also%20clarify%20Karin%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:37:54,899 - gtts.tts - DEBUG - data-4: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22is%20that%20a%20location%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:37:54,899 - gtts.tts - DEBUG - data-5: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22a%20person%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:37:54,900 - gtts.tts - DEBUG - data-6: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22or%20something%20else%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:37:54,900 - gtts.tts - DEBUG - data-7: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22providing%20more%20context%20will%20help%20me%20provide%20a%20more%20accurate%20response.%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:37:54,901 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:37:55,699 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:37:55,737 - gtts.tts - DEBUG - headers-0: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '137'}
2024-10-21 12:37:55,737 - gtts.tts - DEBUG - url-0: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:37:55,738 - gtts.tts - DEBUG - status-0: 200
2024-10-21 12:37:55,738 - gtts.tts - DEBUG - part-0 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:37:55,739 - gtts.tts - DEBUG - part-0 created
2024-10-21 12:37:55,739 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:37:56,689 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:37:57,036 - gtts.tts - DEBUG - headers-1: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '255'}
2024-10-21 12:37:57,036 - gtts.tts - DEBUG - url-1: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:37:57,036 - gtts.tts - DEBUG - status-1: 200
2024-10-21 12:37:57,036 - gtts.tts - DEBUG - part-1 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:37:57,036 - gtts.tts - DEBUG - part-1 created
2024-10-21 12:37:57,036 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:37:58,050 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:37:58,332 - gtts.tts - DEBUG - headers-2: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '250'}
2024-10-21 12:37:58,332 - gtts.tts - DEBUG - url-2: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:37:58,332 - gtts.tts - DEBUG - status-2: 200
2024-10-21 12:37:58,332 - gtts.tts - DEBUG - part-2 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:37:58,332 - gtts.tts - DEBUG - part-2 created
2024-10-21 12:37:58,332 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:37:59,227 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:37:59,347 - gtts.tts - DEBUG - headers-3: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '158'}
2024-10-21 12:37:59,347 - gtts.tts - DEBUG - url-3: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:37:59,347 - gtts.tts - DEBUG - status-3: 200
2024-10-21 12:37:59,347 - gtts.tts - DEBUG - part-3 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:37:59,347 - gtts.tts - DEBUG - part-3 created
2024-10-21 12:37:59,347 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:38:00,261 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:38:00,444 - gtts.tts - DEBUG - headers-4: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '154'}
2024-10-21 12:38:00,444 - gtts.tts - DEBUG - url-4: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:38:00,444 - gtts.tts - DEBUG - status-4: 200
2024-10-21 12:38:00,444 - gtts.tts - DEBUG - part-4 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:38:00,458 - gtts.tts - DEBUG - part-4 created
2024-10-21 12:38:00,458 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:38:01,453 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:38:01,488 - gtts.tts - DEBUG - headers-5: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '140'}
2024-10-21 12:38:01,488 - gtts.tts - DEBUG - url-5: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:38:01,488 - gtts.tts - DEBUG - status-5: 200
2024-10-21 12:38:01,488 - gtts.tts - DEBUG - part-5 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:38:01,488 - gtts.tts - DEBUG - part-5 created
2024-10-21 12:38:01,488 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:38:02,367 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:38:02,452 - gtts.tts - DEBUG - headers-6: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '151'}
2024-10-21 12:38:02,453 - gtts.tts - DEBUG - url-6: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:38:02,453 - gtts.tts - DEBUG - status-6: 200
2024-10-21 12:38:02,454 - gtts.tts - DEBUG - part-6 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:38:02,454 - gtts.tts - DEBUG - part-6 created
2024-10-21 12:38:02,455 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:38:03,520 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:38:03,950 - gtts.tts - DEBUG - headers-7: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '219'}
2024-10-21 12:38:03,951 - gtts.tts - DEBUG - url-7: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:38:03,951 - gtts.tts - DEBUG - status-7: 200
2024-10-21 12:38:03,952 - gtts.tts - DEBUG - part-7 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:38:03,953 - gtts.tts - DEBUG - part-7 created
2024-10-21 12:38:03,954 - gtts.tts - DEBUG - Saved to C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\ai_response\ai_response_audio.mp3
2024-10-21 12:38:03,988 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-f', 'mp3', '-i', 'C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
2024-10-21 12:38:51,249 - faster_whisper - INFO - Processing audio with duration 00:17.786
2024-10-21 12:38:51,907 - faster_whisper - INFO - Detected language 'en' with probability 0.59
2024-10-21 12:38:51,907 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:38:52,146 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': "They are both in Nairobi, Kenya, it's Strathmore, University and Karin."}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:38:52,146 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:38:52,146 - httpcore.connection - DEBUG - close.started
2024-10-21 12:38:52,146 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:38:52,146 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:38:52,270 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C82645520>
2024-10-21 12:38:52,270 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000011C7D11C9D0> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:38:52,390 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C82645070>
2024-10-21 12:38:52,397 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:38:52,397 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:38:52,397 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:38:52,397 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:38:52,397 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:38:52,894 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:38:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19864'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'408ms'), (b'x-request-id', b'req_01jaq7364jeva8hsb3b7t4p5xd'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6046f98cfa73e4-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:38:52,894 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:38:52,894 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:38:52,894 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:38:52,894 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:38:52,894 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:38:52,894 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:38:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19864', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '408ms', 'x-request-id': 'req_01jaq7364jeva8hsb3b7t4p5xd', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6046f98cfa73e4-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:38:52,905 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': "I'm a multi-modal AI voice assistant designed to provide informative and helpful responses to your questions and engage in conversations based on the context you provide whether it's through voice commands, text prompts, or visual aids like photos."}, {'role': 'user', 'content': "USER_PROMPT: I think I'll be the first to\n\nIMAGE_CONTEXT: The image is a black screen. There are no objects or people in the image.  It is impossible to determine any relevant information about the user's statement in relation to the image.  The user is likely making a statement about something else, rather than the image. \n"}, {'role': 'assistant', 'content': "Based on the voice input and considering the image context, it seems like you're making a general statement about being the first, which might be referring to an achievement, a discovery, or something similar, but without further information or context, it's difficult to provide a specific response, could you please provide more context or clarify what you mean."}, {'role': 'user', 'content': 'Can you give directions?'}, {'role': 'assistant', 'content': "You're looking for directions, is there a specific location or destination in mind or is there something else I can help with like providing navigation or assisting with route planning, please provide more context or clarify your request."}, {'role': 'user', 'content': 'Can you give directions from Strathmo University to Karin?'}, {'role': 'assistant', 'content': 'However, I need more specific information about Strathmo University and Karin to provide accurate directions. Could you please provide the name of the city or area where Strathmo University is located, and also clarify Karin, is that a location, a person, or something else, providing more context will help me provide a more accurate response.'}, {'role': 'user', 'content': "They are both in Nairobi, Kenya, it's Strathmore, University and Karin."}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:38:52,909 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:38:52,909 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:38:52,910 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:38:52,910 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:38:52,911 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:38:52,911 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:38:53,662 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:38:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19371'), (b'x-ratelimit-reset-requests', b'11.48s'), (b'x-ratelimit-reset-tokens', b'1.887s'), (b'x-request-id', b'req_01jaq736mxf5japnmrf1azdt9j'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6046fcc91e73e4-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:38:53,664 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:38:53,664 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:38:53,665 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:38:53,665 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:38:53,665 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:38:53,665 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:38:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19371', 'x-ratelimit-reset-requests': '11.48s', 'x-ratelimit-reset-tokens': '1.887s', 'x-request-id': 'req_01jaq736mxf5japnmrf1azdt9j', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6046fcc91e73e4-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:38:53,665 - gtts.tts - DEBUG - text: Karin is likely a street or area in Nairobi, I'm assuming you're asking for directions from Strathmore University to Karin, to provide accurate directions, what would be the most likely destination in Karin, such as a street address, a landmark, or a popular location in the area, please provide this information to assist you further.
2024-10-21 12:38:53,665 - gtts.tts - DEBUG - tld: com
2024-10-21 12:38:53,665 - gtts.tts - DEBUG - lang: en
2024-10-21 12:38:53,665 - gtts.tts - DEBUG - slow: False
2024-10-21 12:38:53,665 - gtts.tts - DEBUG - lang_check: True
2024-10-21 12:38:53,669 - gtts.tts - DEBUG - pre_processor_funcs: [<function tone_marks at 0x0000011C7BA687C0>, <function end_of_line at 0x0000011C7BA68860>, <function abbreviations at 0x0000011C7BA68900>, <function word_sub at 0x0000011C7BA691C0>]
2024-10-21 12:38:53,672 - gtts.tts - DEBUG - timeout: None
2024-10-21 12:38:53,672 - gtts.lang - DEBUG - langs: {'af': 'Afrikaans', 'am': 'Amharic', 'ar': 'Arabic', 'bg': 'Bulgarian', 'bn': 'Bengali', 'bs': 'Bosnian', 'ca': 'Catalan', 'cs': 'Czech', 'cy': 'Welsh', 'da': 'Danish', 'de': 'German', 'el': 'Greek', 'en': 'English', 'es': 'Spanish', 'et': 'Estonian', 'eu': 'Basque', 'fi': 'Finnish', 'fr': 'French', 'gl': 'Galician', 'gu': 'Gujarati', 'ha': 'Hausa', 'hi': 'Hindi', 'hr': 'Croatian', 'hu': 'Hungarian', 'id': 'Indonesian', 'is': 'Icelandic', 'it': 'Italian', 'iw': 'Hebrew', 'ja': 'Japanese', 'jw': 'Javanese', 'km': 'Khmer', 'kn': 'Kannada', 'ko': 'Korean', 'la': 'Latin', 'lt': 'Lithuanian', 'lv': 'Latvian', 'ml': 'Malayalam', 'mr': 'Marathi', 'ms': 'Malay', 'my': 'Myanmar (Burmese)', 'ne': 'Nepali', 'nl': 'Dutch', 'no': 'Norwegian', 'pa': 'Punjabi (Gurmukhi)', 'pl': 'Polish', 'pt': 'Portuguese (Brazil)', 'pt-PT': 'Portuguese (Portugal)', 'ro': 'Romanian', 'ru': 'Russian', 'si': 'Sinhala', 'sk': 'Slovak', 'sq': 'Albanian', 'sr': 'Serbian', 'su': 'Sundanese', 'sv': 'Swedish', 'sw': 'Swahili', 'ta': 'Tamil', 'te': 'Telugu', 'th': 'Thai', 'tl': 'Filipino', 'tr': 'Turkish', 'uk': 'Ukrainian', 'ur': 'Urdu', 'vi': 'Vietnamese', 'yue': 'Cantonese', 'zh-CN': 'Chinese (Simplified)', 'zh-TW': 'Chinese (Mandarin/Taiwan)', 'zh': 'Chinese (Mandarin)'}
2024-10-21 12:38:53,674 - gtts.tts - DEBUG - pre-processing: <function tone_marks at 0x0000011C7BA687C0>
2024-10-21 12:38:53,674 - gtts.tts - DEBUG - pre-processing: <function end_of_line at 0x0000011C7BA68860>
2024-10-21 12:38:53,674 - gtts.tts - DEBUG - pre-processing: <function abbreviations at 0x0000011C7BA68900>
2024-10-21 12:38:53,674 - gtts.tts - DEBUG - pre-processing: <function word_sub at 0x0000011C7BA691C0>
2024-10-21 12:38:53,679 - gtts.tts - DEBUG - text_parts: ['Karin is likely a street or area in Nairobi', "I'm assuming you're asking for directions from Strathmore University to Karin", 'to provide accurate directions', 'what would be the most likely destination in Karin', 'such as a street address', 'a landmark', 'or a popular location in the area', 'please provide this information to assist you further.']
2024-10-21 12:38:53,679 - gtts.tts - DEBUG - text_parts: 8
2024-10-21 12:38:53,679 - gtts.tts - DEBUG - data-0: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22Karin%20is%20likely%20a%20street%20or%20area%20in%20Nairobi%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:38:53,680 - gtts.tts - DEBUG - data-1: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22I%27m%20assuming%20you%27re%20asking%20for%20directions%20from%20Strathmore%20University%20to%20Karin%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:38:53,680 - gtts.tts - DEBUG - data-2: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22to%20provide%20accurate%20directions%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:38:53,680 - gtts.tts - DEBUG - data-3: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22what%20would%20be%20the%20most%20likely%20destination%20in%20Karin%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:38:53,680 - gtts.tts - DEBUG - data-4: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22such%20as%20a%20street%20address%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:38:53,681 - gtts.tts - DEBUG - data-5: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22a%20landmark%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:38:53,681 - gtts.tts - DEBUG - data-6: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22or%20a%20popular%20location%20in%20the%20area%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:38:53,681 - gtts.tts - DEBUG - data-7: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22please%20provide%20this%20information%20to%20assist%20you%20further.%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:38:53,682 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:38:54,542 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:38:54,725 - gtts.tts - DEBUG - headers-0: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '189'}
2024-10-21 12:38:54,725 - gtts.tts - DEBUG - url-0: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:38:54,725 - gtts.tts - DEBUG - status-0: 200
2024-10-21 12:38:54,725 - gtts.tts - DEBUG - part-0 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:38:54,725 - gtts.tts - DEBUG - part-0 created
2024-10-21 12:38:54,725 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:38:55,609 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:38:55,863 - gtts.tts - DEBUG - headers-1: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '231'}
2024-10-21 12:38:55,863 - gtts.tts - DEBUG - url-1: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:38:55,863 - gtts.tts - DEBUG - status-1: 200
2024-10-21 12:38:55,865 - gtts.tts - DEBUG - part-1 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:38:55,865 - gtts.tts - DEBUG - part-1 created
2024-10-21 12:38:55,866 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:38:56,774 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:38:56,919 - gtts.tts - DEBUG - headers-2: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '166'}
2024-10-21 12:38:56,919 - gtts.tts - DEBUG - url-2: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:38:56,919 - gtts.tts - DEBUG - status-2: 200
2024-10-21 12:38:56,919 - gtts.tts - DEBUG - part-2 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:38:56,919 - gtts.tts - DEBUG - part-2 created
2024-10-21 12:38:56,919 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:38:57,919 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:38:58,208 - gtts.tts - DEBUG - headers-3: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '196'}
2024-10-21 12:38:58,209 - gtts.tts - DEBUG - url-3: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:38:58,209 - gtts.tts - DEBUG - status-3: 200
2024-10-21 12:38:58,210 - gtts.tts - DEBUG - part-3 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:38:58,210 - gtts.tts - DEBUG - part-3 created
2024-10-21 12:38:58,211 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:38:59,186 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:38:59,586 - gtts.tts - DEBUG - headers-4: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '162'}
2024-10-21 12:38:59,586 - gtts.tts - DEBUG - url-4: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:38:59,596 - gtts.tts - DEBUG - status-4: 200
2024-10-21 12:38:59,597 - gtts.tts - DEBUG - part-4 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:38:59,597 - gtts.tts - DEBUG - part-4 created
2024-10-21 12:38:59,598 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:39:00,516 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:39:00,640 - gtts.tts - DEBUG - headers-5: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '142'}
2024-10-21 12:39:00,641 - gtts.tts - DEBUG - url-5: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:39:00,641 - gtts.tts - DEBUG - status-5: 200
2024-10-21 12:39:00,642 - gtts.tts - DEBUG - part-5 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:39:00,642 - gtts.tts - DEBUG - part-5 created
2024-10-21 12:39:00,643 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:39:01,612 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:39:01,778 - gtts.tts - DEBUG - headers-6: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '175'}
2024-10-21 12:39:01,778 - gtts.tts - DEBUG - url-6: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:39:01,778 - gtts.tts - DEBUG - status-6: 200
2024-10-21 12:39:01,778 - gtts.tts - DEBUG - part-6 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:39:01,778 - gtts.tts - DEBUG - part-6 created
2024-10-21 12:39:01,778 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:39:02,653 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:39:02,830 - gtts.tts - DEBUG - headers-7: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '198'}
2024-10-21 12:39:02,830 - gtts.tts - DEBUG - url-7: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:39:02,830 - gtts.tts - DEBUG - status-7: 200
2024-10-21 12:39:02,830 - gtts.tts - DEBUG - part-7 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:39:02,830 - gtts.tts - DEBUG - part-7 created
2024-10-21 12:39:02,830 - gtts.tts - DEBUG - Saved to C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\ai_response\ai_response_audio.mp3
2024-10-21 12:39:02,881 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-f', 'mp3', '-i', 'C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
2024-10-21 12:39:38,287 - faster_whisper - INFO - Processing audio with duration 00:09.056
2024-10-21 12:39:38,914 - faster_whisper - INFO - Detected language 'en' with probability 0.48
2024-10-21 12:39:38,914 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:39:39,022 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.0 (-1.202545 < -1.000000)
2024-10-21 12:39:39,224 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.2 (-1.202546 < -1.000000)
2024-10-21 12:39:39,487 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.4 (-1.240364 < -1.000000)
2024-10-21 12:39:39,711 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.6 (-1.319539 < -1.000000)
2024-10-21 12:39:39,967 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.8 (-1.361990 < -1.000000)
2024-10-21 12:39:40,256 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 1.0 (-2.575430 < -1.000000)
2024-10-21 12:39:40,256 - faster_whisper - DEBUG - Reset prompt. prompt_reset_on_temperature threshold is met 1.000000 > 0.500000
2024-10-21 12:39:40,256 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'in Karin.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:39:40,256 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:39:40,256 - httpcore.connection - DEBUG - close.started
2024-10-21 12:39:40,256 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:39:40,256 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:39:40,384 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C82647740>
2024-10-21 12:39:40,384 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000011C7D11C9D0> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:39:40,496 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C826468D0>
2024-10-21 12:39:40,496 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:39:40,496 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:39:40,512 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:39:40,512 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:39:40,512 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:39:41,009 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:39:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19879'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'363ms'), (b'x-request-id', b'req_01jaq74n54etqby9zn3myk0b3h'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6048265b827401-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:39:41,009 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:39:41,009 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:39:41,009 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:39:41,009 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:39:41,009 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:39:41,009 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:39:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19879', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '363ms', 'x-request-id': 'req_01jaq74n54etqby9zn3myk0b3h', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6048265b827401-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:39:41,025 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': "I'm a multi-modal AI voice assistant designed to provide informative and helpful responses to your questions and engage in conversations based on the context you provide whether it's through voice commands, text prompts, or visual aids like photos."}, {'role': 'user', 'content': "USER_PROMPT: I think I'll be the first to\n\nIMAGE_CONTEXT: The image is a black screen. There are no objects or people in the image.  It is impossible to determine any relevant information about the user's statement in relation to the image.  The user is likely making a statement about something else, rather than the image. \n"}, {'role': 'assistant', 'content': "Based on the voice input and considering the image context, it seems like you're making a general statement about being the first, which might be referring to an achievement, a discovery, or something similar, but without further information or context, it's difficult to provide a specific response, could you please provide more context or clarify what you mean."}, {'role': 'user', 'content': 'Can you give directions?'}, {'role': 'assistant', 'content': "You're looking for directions, is there a specific location or destination in mind or is there something else I can help with like providing navigation or assisting with route planning, please provide more context or clarify your request."}, {'role': 'user', 'content': 'Can you give directions from Strathmo University to Karin?'}, {'role': 'assistant', 'content': 'However, I need more specific information about Strathmo University and Karin to provide accurate directions. Could you please provide the name of the city or area where Strathmo University is located, and also clarify Karin, is that a location, a person, or something else, providing more context will help me provide a more accurate response.'}, {'role': 'user', 'content': "They are both in Nairobi, Kenya, it's Strathmore, University and Karin."}, {'role': 'assistant', 'content': "Karin is likely a street or area in Nairobi, I'm assuming you're asking for directions from Strathmore University to Karin, to provide accurate directions, what would be the most likely destination in Karin, such as a street address, a landmark, or a popular location in the area, please provide this information to assist you further."}, {'role': 'user', 'content': 'in Karin.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:39:41,031 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:39:41,032 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:39:41,032 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:39:41,032 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:39:41,033 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:39:41,033 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:39:41,755 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:39:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19276'), (b'x-ratelimit-reset-requests', b'11.462999999s'), (b'x-ratelimit-reset-tokens', b'2.172s'), (b'x-request-id', b'req_01jaq74np0eafrcht7xchtfqbe'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6048299f9e7401-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:39:41,755 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:39:41,755 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:39:41,755 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:39:41,755 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:39:41,755 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:39:41,755 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:39:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19276', 'x-ratelimit-reset-requests': '11.462999999s', 'x-ratelimit-reset-tokens': '2.172s', 'x-request-id': 'req_01jaq74np0eafrcht7xchtfqbe', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6048299f9e7401-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:39:41,755 - gtts.tts - DEBUG - text: Unfortunately, Karin is a relatively small estate in Nairobi and it appears that there are multiple Karin locations, one within the area of Parklands and another near the Green ParkTeria area (Kari-n in Nairobi and, Karin also exists within the Muthaiga's neighborhood in Thika Road vicinity, Park or Muthaiga area Karin.
2024-10-21 12:39:41,755 - gtts.tts - DEBUG - tld: com
2024-10-21 12:39:41,755 - gtts.tts - DEBUG - lang: en
2024-10-21 12:39:41,769 - gtts.tts - DEBUG - slow: False
2024-10-21 12:39:41,769 - gtts.tts - DEBUG - lang_check: True
2024-10-21 12:39:41,769 - gtts.tts - DEBUG - pre_processor_funcs: [<function tone_marks at 0x0000011C7BA687C0>, <function end_of_line at 0x0000011C7BA68860>, <function abbreviations at 0x0000011C7BA68900>, <function word_sub at 0x0000011C7BA691C0>]
2024-10-21 12:39:41,774 - gtts.tts - DEBUG - timeout: None
2024-10-21 12:39:41,774 - gtts.lang - DEBUG - langs: {'af': 'Afrikaans', 'am': 'Amharic', 'ar': 'Arabic', 'bg': 'Bulgarian', 'bn': 'Bengali', 'bs': 'Bosnian', 'ca': 'Catalan', 'cs': 'Czech', 'cy': 'Welsh', 'da': 'Danish', 'de': 'German', 'el': 'Greek', 'en': 'English', 'es': 'Spanish', 'et': 'Estonian', 'eu': 'Basque', 'fi': 'Finnish', 'fr': 'French', 'gl': 'Galician', 'gu': 'Gujarati', 'ha': 'Hausa', 'hi': 'Hindi', 'hr': 'Croatian', 'hu': 'Hungarian', 'id': 'Indonesian', 'is': 'Icelandic', 'it': 'Italian', 'iw': 'Hebrew', 'ja': 'Japanese', 'jw': 'Javanese', 'km': 'Khmer', 'kn': 'Kannada', 'ko': 'Korean', 'la': 'Latin', 'lt': 'Lithuanian', 'lv': 'Latvian', 'ml': 'Malayalam', 'mr': 'Marathi', 'ms': 'Malay', 'my': 'Myanmar (Burmese)', 'ne': 'Nepali', 'nl': 'Dutch', 'no': 'Norwegian', 'pa': 'Punjabi (Gurmukhi)', 'pl': 'Polish', 'pt': 'Portuguese (Brazil)', 'pt-PT': 'Portuguese (Portugal)', 'ro': 'Romanian', 'ru': 'Russian', 'si': 'Sinhala', 'sk': 'Slovak', 'sq': 'Albanian', 'sr': 'Serbian', 'su': 'Sundanese', 'sv': 'Swedish', 'sw': 'Swahili', 'ta': 'Tamil', 'te': 'Telugu', 'th': 'Thai', 'tl': 'Filipino', 'tr': 'Turkish', 'uk': 'Ukrainian', 'ur': 'Urdu', 'vi': 'Vietnamese', 'yue': 'Cantonese', 'zh-CN': 'Chinese (Simplified)', 'zh-TW': 'Chinese (Mandarin/Taiwan)', 'zh': 'Chinese (Mandarin)'}
2024-10-21 12:39:41,775 - gtts.tts - DEBUG - pre-processing: <function tone_marks at 0x0000011C7BA687C0>
2024-10-21 12:39:41,775 - gtts.tts - DEBUG - pre-processing: <function end_of_line at 0x0000011C7BA68860>
2024-10-21 12:39:41,776 - gtts.tts - DEBUG - pre-processing: <function abbreviations at 0x0000011C7BA68900>
2024-10-21 12:39:41,776 - gtts.tts - DEBUG - pre-processing: <function word_sub at 0x0000011C7BA691C0>
2024-10-21 12:39:41,781 - gtts.tts - DEBUG - text_parts: ['Unfortunately', 'Karin is a relatively small estate in Nairobi and it appears that there are multiple Karin locations', 'one within the area of Parklands and another near the Green ParkTeria area', 'Kari-n in Nairobi and', "Karin also exists within the Muthaiga's neighborhood in Thika Road vicinity", 'Park or Muthaiga area Karin.']
2024-10-21 12:39:41,781 - gtts.tts - DEBUG - text_parts: 6
2024-10-21 12:39:41,782 - gtts.tts - DEBUG - data-0: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22Unfortunately%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:39:41,782 - gtts.tts - DEBUG - data-1: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22Karin%20is%20a%20relatively%20small%20estate%20in%20Nairobi%20and%20it%20appears%20that%20there%20are%20multiple%20Karin%20locations%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:39:41,782 - gtts.tts - DEBUG - data-2: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22one%20within%20the%20area%20of%20Parklands%20and%20another%20near%20the%20Green%20ParkTeria%20area%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:39:41,783 - gtts.tts - DEBUG - data-3: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22Kari-n%20in%20Nairobi%20and%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:39:41,783 - gtts.tts - DEBUG - data-4: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22Karin%20also%20exists%20within%20the%20Muthaiga%27s%20neighborhood%20in%20Thika%20Road%20vicinity%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:39:41,784 - gtts.tts - DEBUG - data-5: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22Park%20or%20Muthaiga%20area%20Karin.%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:39:41,784 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:39:42,557 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:39:42,663 - gtts.tts - DEBUG - headers-0: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '143'}
2024-10-21 12:39:42,663 - gtts.tts - DEBUG - url-0: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:39:42,663 - gtts.tts - DEBUG - status-0: 200
2024-10-21 12:39:42,663 - gtts.tts - DEBUG - part-0 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:39:42,663 - gtts.tts - DEBUG - part-0 created
2024-10-21 12:39:42,663 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:39:43,661 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:39:44,014 - gtts.tts - DEBUG - headers-1: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '262'}
2024-10-21 12:39:44,014 - gtts.tts - DEBUG - url-1: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:39:44,014 - gtts.tts - DEBUG - status-1: 200
2024-10-21 12:39:44,014 - gtts.tts - DEBUG - part-1 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:39:44,014 - gtts.tts - DEBUG - part-1 created
2024-10-21 12:39:44,014 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:39:44,937 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:39:45,255 - gtts.tts - DEBUG - headers-2: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '228'}
2024-10-21 12:39:45,255 - gtts.tts - DEBUG - url-2: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:39:45,255 - gtts.tts - DEBUG - status-2: 200
2024-10-21 12:39:45,255 - gtts.tts - DEBUG - part-2 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:39:45,255 - gtts.tts - DEBUG - part-2 created
2024-10-21 12:39:45,255 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:39:46,960 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:39:47,122 - gtts.tts - DEBUG - headers-3: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '157'}
2024-10-21 12:39:47,123 - gtts.tts - DEBUG - url-3: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:39:47,124 - gtts.tts - DEBUG - status-3: 200
2024-10-21 12:39:47,124 - gtts.tts - DEBUG - part-3 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:39:47,125 - gtts.tts - DEBUG - part-3 created
2024-10-21 12:39:47,126 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:39:48,239 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:39:48,479 - gtts.tts - DEBUG - headers-4: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '227'}
2024-10-21 12:39:48,479 - gtts.tts - DEBUG - url-4: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:39:48,479 - gtts.tts - DEBUG - status-4: 200
2024-10-21 12:39:48,479 - gtts.tts - DEBUG - part-4 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:39:48,479 - gtts.tts - DEBUG - part-4 created
2024-10-21 12:39:48,479 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:39:49,303 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:39:49,492 - gtts.tts - DEBUG - headers-5: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '166'}
2024-10-21 12:39:49,492 - gtts.tts - DEBUG - url-5: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:39:49,492 - gtts.tts - DEBUG - status-5: 200
2024-10-21 12:39:49,492 - gtts.tts - DEBUG - part-5 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:39:49,492 - gtts.tts - DEBUG - part-5 created
2024-10-21 12:39:49,492 - gtts.tts - DEBUG - Saved to C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\ai_response\ai_response_audio.mp3
2024-10-21 12:39:49,531 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-f', 'mp3', '-i', 'C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
2024-10-21 12:40:35,963 - faster_whisper - INFO - Processing audio with duration 00:16.602
2024-10-21 12:40:36,626 - faster_whisper - INFO - Detected language 'en' with probability 0.70
2024-10-21 12:40:36,627 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:40:36,822 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': "We're going to directions from Strathmore University to Mothiga."}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:40:36,822 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:40:36,822 - httpcore.connection - DEBUG - close.started
2024-10-21 12:40:36,822 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:40:36,822 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:40:36,945 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C82645670>
2024-10-21 12:40:36,945 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000011C7D11C9D0> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:40:37,146 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C82646D50>
2024-10-21 12:40:37,146 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:40:37,146 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:40:37,147 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:40:37,147 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:40:37,147 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:40:37,858 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:40:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19865'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'405ms'), (b'x-request-id', b'req_01jaq76cgpfqx9rn05z1gj1b18'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6049886fbc7404-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:40:37,858 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:40:37,858 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:40:37,858 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:40:37,858 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:40:37,858 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:40:37,858 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:40:38 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19865', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '405ms', 'x-request-id': 'req_01jaq76cgpfqx9rn05z1gj1b18', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6049886fbc7404-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:40:37,858 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': "I'm a multi-modal AI voice assistant designed to provide informative and helpful responses to your questions and engage in conversations based on the context you provide whether it's through voice commands, text prompts, or visual aids like photos."}, {'role': 'user', 'content': "USER_PROMPT: I think I'll be the first to\n\nIMAGE_CONTEXT: The image is a black screen. There are no objects or people in the image.  It is impossible to determine any relevant information about the user's statement in relation to the image.  The user is likely making a statement about something else, rather than the image. \n"}, {'role': 'assistant', 'content': "Based on the voice input and considering the image context, it seems like you're making a general statement about being the first, which might be referring to an achievement, a discovery, or something similar, but without further information or context, it's difficult to provide a specific response, could you please provide more context or clarify what you mean."}, {'role': 'user', 'content': 'Can you give directions?'}, {'role': 'assistant', 'content': "You're looking for directions, is there a specific location or destination in mind or is there something else I can help with like providing navigation or assisting with route planning, please provide more context or clarify your request."}, {'role': 'user', 'content': 'Can you give directions from Strathmo University to Karin?'}, {'role': 'assistant', 'content': 'However, I need more specific information about Strathmo University and Karin to provide accurate directions. Could you please provide the name of the city or area where Strathmo University is located, and also clarify Karin, is that a location, a person, or something else, providing more context will help me provide a more accurate response.'}, {'role': 'user', 'content': "They are both in Nairobi, Kenya, it's Strathmore, University and Karin."}, {'role': 'assistant', 'content': "Karin is likely a street or area in Nairobi, I'm assuming you're asking for directions from Strathmore University to Karin, to provide accurate directions, what would be the most likely destination in Karin, such as a street address, a landmark, or a popular location in the area, please provide this information to assist you further."}, {'role': 'user', 'content': 'in Karin.'}, {'role': 'assistant', 'content': "Unfortunately, Karin is a relatively small estate in Nairobi and it appears that there are multiple Karin locations, one within the area of Parklands and another near the Green ParkTeria area (Kari-n in Nairobi and, Karin also exists within the Muthaiga's neighborhood in Thika Road vicinity, Park or Muthaiga area Karin."}, {'role': 'user', 'content': "We're going to directions from Strathmore University to Mothiga."}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:40:37,869 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:40:37,869 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:40:37,870 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:40:37,870 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:40:37,870 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:40:37,871 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:40:38,739 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:40:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19170'), (b'x-ratelimit-reset-requests', b'11.242999999s'), (b'x-ratelimit-reset-tokens', b'2.49s'), (b'x-request-id', b'req_01jaq76d7rfdtt8kvhbx5sd302'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60498cdd347404-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:40:38,739 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:40:38,739 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:40:38,739 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:40:38,739 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:40:38,739 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:40:38,739 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:40:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19170', 'x-ratelimit-reset-requests': '11.242999999s', 'x-ratelimit-reset-tokens': '2.49s', 'x-request-id': 'req_01jaq76d7rfdtt8kvhbx5sd302', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60498cdd347404-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:40:38,739 - gtts.tts - DEBUG - text: From Strathmore University, driving directions to Muthaiga area would usually mean heading southwest towards Thika Road. Take the Thika Road highway, after approximately 5-7 minutes, you should take the exit for Muthaiga-Garissa Road, and then continue on the road, taking a left turn onto Sussex Road which will lead to the Muthaiga neighborhood and other surrounding estates, please note these directions might vary depending on real-time traffic conditions or personal preference, do you need turn-by-turn directions or more detailed information.
2024-10-21 12:40:38,754 - gtts.tts - DEBUG - tld: com
2024-10-21 12:40:38,754 - gtts.tts - DEBUG - lang: en
2024-10-21 12:40:38,754 - gtts.tts - DEBUG - slow: False
2024-10-21 12:40:38,755 - gtts.tts - DEBUG - lang_check: True
2024-10-21 12:40:38,755 - gtts.tts - DEBUG - pre_processor_funcs: [<function tone_marks at 0x0000011C7BA687C0>, <function end_of_line at 0x0000011C7BA68860>, <function abbreviations at 0x0000011C7BA68900>, <function word_sub at 0x0000011C7BA691C0>]
2024-10-21 12:40:38,761 - gtts.tts - DEBUG - timeout: None
2024-10-21 12:40:38,761 - gtts.lang - DEBUG - langs: {'af': 'Afrikaans', 'am': 'Amharic', 'ar': 'Arabic', 'bg': 'Bulgarian', 'bn': 'Bengali', 'bs': 'Bosnian', 'ca': 'Catalan', 'cs': 'Czech', 'cy': 'Welsh', 'da': 'Danish', 'de': 'German', 'el': 'Greek', 'en': 'English', 'es': 'Spanish', 'et': 'Estonian', 'eu': 'Basque', 'fi': 'Finnish', 'fr': 'French', 'gl': 'Galician', 'gu': 'Gujarati', 'ha': 'Hausa', 'hi': 'Hindi', 'hr': 'Croatian', 'hu': 'Hungarian', 'id': 'Indonesian', 'is': 'Icelandic', 'it': 'Italian', 'iw': 'Hebrew', 'ja': 'Japanese', 'jw': 'Javanese', 'km': 'Khmer', 'kn': 'Kannada', 'ko': 'Korean', 'la': 'Latin', 'lt': 'Lithuanian', 'lv': 'Latvian', 'ml': 'Malayalam', 'mr': 'Marathi', 'ms': 'Malay', 'my': 'Myanmar (Burmese)', 'ne': 'Nepali', 'nl': 'Dutch', 'no': 'Norwegian', 'pa': 'Punjabi (Gurmukhi)', 'pl': 'Polish', 'pt': 'Portuguese (Brazil)', 'pt-PT': 'Portuguese (Portugal)', 'ro': 'Romanian', 'ru': 'Russian', 'si': 'Sinhala', 'sk': 'Slovak', 'sq': 'Albanian', 'sr': 'Serbian', 'su': 'Sundanese', 'sv': 'Swedish', 'sw': 'Swahili', 'ta': 'Tamil', 'te': 'Telugu', 'th': 'Thai', 'tl': 'Filipino', 'tr': 'Turkish', 'uk': 'Ukrainian', 'ur': 'Urdu', 'vi': 'Vietnamese', 'yue': 'Cantonese', 'zh-CN': 'Chinese (Simplified)', 'zh-TW': 'Chinese (Mandarin/Taiwan)', 'zh': 'Chinese (Mandarin)'}
2024-10-21 12:40:38,763 - gtts.tts - DEBUG - pre-processing: <function tone_marks at 0x0000011C7BA687C0>
2024-10-21 12:40:38,763 - gtts.tts - DEBUG - pre-processing: <function end_of_line at 0x0000011C7BA68860>
2024-10-21 12:40:38,763 - gtts.tts - DEBUG - pre-processing: <function abbreviations at 0x0000011C7BA68900>
2024-10-21 12:40:38,764 - gtts.tts - DEBUG - pre-processing: <function word_sub at 0x0000011C7BA691C0>
2024-10-21 12:40:38,767 - gtts.tts - DEBUG - text_parts: ['From Strathmore University', 'driving directions to Muthaiga area would usually mean heading southwest towards Thika Road', 'Take the Thika Road highway', 'after approximately 5-7 minutes', 'you should take the exit for Muthaiga-Garissa Road', 'and then continue on the road', 'taking a left turn onto Sussex Road which will lead to the Muthaiga neighborhood and other', 'surrounding estates', 'please note these directions might vary depending on real-time traffic conditions or personal', 'preference', 'do you need turn-by-turn directions or more detailed information.']
2024-10-21 12:40:38,768 - gtts.tts - DEBUG - text_parts: 11
2024-10-21 12:40:38,768 - gtts.tts - DEBUG - data-0: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22From%20Strathmore%20University%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:40:38,769 - gtts.tts - DEBUG - data-1: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22driving%20directions%20to%20Muthaiga%20area%20would%20usually%20mean%20heading%20southwest%20towards%20Thika%20Road%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:40:38,770 - gtts.tts - DEBUG - data-2: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22Take%20the%20Thika%20Road%20highway%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:40:38,770 - gtts.tts - DEBUG - data-3: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22after%20approximately%205-7%20minutes%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:40:38,771 - gtts.tts - DEBUG - data-4: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22you%20should%20take%20the%20exit%20for%20Muthaiga-Garissa%20Road%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:40:38,772 - gtts.tts - DEBUG - data-5: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22and%20then%20continue%20on%20the%20road%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:40:38,772 - gtts.tts - DEBUG - data-6: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22taking%20a%20left%20turn%20onto%20Sussex%20Road%20which%20will%20lead%20to%20the%20Muthaiga%20neighborhood%20and%20other%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:40:38,773 - gtts.tts - DEBUG - data-7: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22surrounding%20estates%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:40:38,773 - gtts.tts - DEBUG - data-8: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22please%20note%20these%20directions%20might%20vary%20depending%20on%20real-time%20traffic%20conditions%20or%20personal%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:40:38,773 - gtts.tts - DEBUG - data-9: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22preference%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:40:38,774 - gtts.tts - DEBUG - data-10: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22do%20you%20need%20turn-by-turn%20directions%20or%20more%20detailed%20information.%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:40:38,774 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:40:39,645 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:40:39,792 - gtts.tts - DEBUG - headers-0: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '160'}
2024-10-21 12:40:39,792 - gtts.tts - DEBUG - url-0: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:40:39,792 - gtts.tts - DEBUG - status-0: 200
2024-10-21 12:40:39,792 - gtts.tts - DEBUG - part-0 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:40:39,792 - gtts.tts - DEBUG - part-0 created
2024-10-21 12:40:39,792 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:40:40,817 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:40:41,144 - gtts.tts - DEBUG - headers-1: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '245'}
2024-10-21 12:40:41,144 - gtts.tts - DEBUG - url-1: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:40:41,144 - gtts.tts - DEBUG - status-1: 200
2024-10-21 12:40:41,144 - gtts.tts - DEBUG - part-1 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:40:41,144 - gtts.tts - DEBUG - part-1 created
2024-10-21 12:40:41,144 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:40:42,355 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:40:42,510 - gtts.tts - DEBUG - headers-2: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '165'}
2024-10-21 12:40:42,510 - gtts.tts - DEBUG - url-2: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:40:42,510 - gtts.tts - DEBUG - status-2: 200
2024-10-21 12:40:42,510 - gtts.tts - DEBUG - part-2 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:40:42,510 - gtts.tts - DEBUG - part-2 created
2024-10-21 12:40:42,510 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:40:43,410 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:40:43,618 - gtts.tts - DEBUG - headers-3: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '167'}
2024-10-21 12:40:43,619 - gtts.tts - DEBUG - url-3: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:40:43,619 - gtts.tts - DEBUG - status-3: 200
2024-10-21 12:40:43,620 - gtts.tts - DEBUG - part-3 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:40:43,621 - gtts.tts - DEBUG - part-3 created
2024-10-21 12:40:43,621 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:40:44,642 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:40:44,872 - gtts.tts - DEBUG - headers-4: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '194'}
2024-10-21 12:40:44,872 - gtts.tts - DEBUG - url-4: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:40:44,872 - gtts.tts - DEBUG - status-4: 200
2024-10-21 12:40:44,872 - gtts.tts - DEBUG - part-4 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:40:44,872 - gtts.tts - DEBUG - part-4 created
2024-10-21 12:40:44,872 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:40:45,724 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:40:45,845 - gtts.tts - DEBUG - headers-5: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '169'}
2024-10-21 12:40:45,845 - gtts.tts - DEBUG - url-5: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:40:45,845 - gtts.tts - DEBUG - status-5: 200
2024-10-21 12:40:45,845 - gtts.tts - DEBUG - part-5 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:40:45,845 - gtts.tts - DEBUG - part-5 created
2024-10-21 12:40:45,845 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:40:46,858 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:40:47,147 - gtts.tts - DEBUG - headers-6: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '250'}
2024-10-21 12:40:47,147 - gtts.tts - DEBUG - url-6: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:40:47,147 - gtts.tts - DEBUG - status-6: 200
2024-10-21 12:40:47,160 - gtts.tts - DEBUG - part-6 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:40:47,160 - gtts.tts - DEBUG - part-6 created
2024-10-21 12:40:47,160 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:40:48,022 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:40:48,140 - gtts.tts - DEBUG - headers-7: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '151'}
2024-10-21 12:40:48,141 - gtts.tts - DEBUG - url-7: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:40:48,141 - gtts.tts - DEBUG - status-7: 200
2024-10-21 12:40:48,141 - gtts.tts - DEBUG - part-7 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:40:48,142 - gtts.tts - DEBUG - part-7 created
2024-10-21 12:40:48,143 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:40:49,227 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:40:49,950 - gtts.tts - DEBUG - headers-8: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '247'}
2024-10-21 12:40:49,950 - gtts.tts - DEBUG - url-8: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:40:49,950 - gtts.tts - DEBUG - status-8: 200
2024-10-21 12:40:49,950 - gtts.tts - DEBUG - part-8 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:40:49,950 - gtts.tts - DEBUG - part-8 created
2024-10-21 12:40:49,950 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:40:50,766 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:40:50,862 - gtts.tts - DEBUG - headers-9: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '140'}
2024-10-21 12:40:50,862 - gtts.tts - DEBUG - url-9: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:40:50,863 - gtts.tts - DEBUG - status-9: 200
2024-10-21 12:40:50,863 - gtts.tts - DEBUG - part-9 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:40:50,864 - gtts.tts - DEBUG - part-9 created
2024-10-21 12:40:50,864 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:40:51,755 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:40:51,988 - gtts.tts - DEBUG - headers-10: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '211'}
2024-10-21 12:40:51,988 - gtts.tts - DEBUG - url-10: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:40:51,988 - gtts.tts - DEBUG - status-10: 200
2024-10-21 12:40:51,988 - gtts.tts - DEBUG - part-10 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:40:51,988 - gtts.tts - DEBUG - part-10 created
2024-10-21 12:40:51,988 - gtts.tts - DEBUG - Saved to C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\ai_response\ai_response_audio.mp3
2024-10-21 12:40:52,033 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-f', 'mp3', '-i', 'C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
2024-10-21 12:41:49,960 - faster_whisper - INFO - Processing audio with duration 00:02.554
2024-10-21 12:41:50,873 - faster_whisper - INFO - Detected language 'en' with probability 0.49
2024-10-21 12:41:50,873 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:41:51,090 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:41:51,090 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:41:51,090 - httpcore.connection - DEBUG - close.started
2024-10-21 12:41:51,090 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:41:51,090 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:41:51,227 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C82646F00>
2024-10-21 12:41:51,227 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000011C7D11C9D0> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:41:51,402 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000011C826464E0>
2024-10-21 12:41:51,403 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:41:51,404 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:41:51,404 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:41:51,404 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:41:51,405 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:41:51,877 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:41:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19881'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'357ms'), (b'x-request-id', b'req_01jaq78myxf4xv92mqajvewars'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d604b585fd373c6-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:41:51,877 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:41:51,877 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:41:51,877 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:41:51,877 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:41:51,877 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:41:51,877 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:41:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19881', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '357ms', 'x-request-id': 'req_01jaq78myxf4xv92mqajvewars', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d604b585fd373c6-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:41:51,897 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': "I'm a multi-modal AI voice assistant designed to provide informative and helpful responses to your questions and engage in conversations based on the context you provide whether it's through voice commands, text prompts, or visual aids like photos."}, {'role': 'user', 'content': "USER_PROMPT: I think I'll be the first to\n\nIMAGE_CONTEXT: The image is a black screen. There are no objects or people in the image.  It is impossible to determine any relevant information about the user's statement in relation to the image.  The user is likely making a statement about something else, rather than the image. \n"}, {'role': 'assistant', 'content': "Based on the voice input and considering the image context, it seems like you're making a general statement about being the first, which might be referring to an achievement, a discovery, or something similar, but without further information or context, it's difficult to provide a specific response, could you please provide more context or clarify what you mean."}, {'role': 'user', 'content': 'Can you give directions?'}, {'role': 'assistant', 'content': "You're looking for directions, is there a specific location or destination in mind or is there something else I can help with like providing navigation or assisting with route planning, please provide more context or clarify your request."}, {'role': 'user', 'content': 'Can you give directions from Strathmo University to Karin?'}, {'role': 'assistant', 'content': 'However, I need more specific information about Strathmo University and Karin to provide accurate directions. Could you please provide the name of the city or area where Strathmo University is located, and also clarify Karin, is that a location, a person, or something else, providing more context will help me provide a more accurate response.'}, {'role': 'user', 'content': "They are both in Nairobi, Kenya, it's Strathmore, University and Karin."}, {'role': 'assistant', 'content': "Karin is likely a street or area in Nairobi, I'm assuming you're asking for directions from Strathmore University to Karin, to provide accurate directions, what would be the most likely destination in Karin, such as a street address, a landmark, or a popular location in the area, please provide this information to assist you further."}, {'role': 'user', 'content': 'in Karin.'}, {'role': 'assistant', 'content': "Unfortunately, Karin is a relatively small estate in Nairobi and it appears that there are multiple Karin locations, one within the area of Parklands and another near the Green ParkTeria area (Kari-n in Nairobi and, Karin also exists within the Muthaiga's neighborhood in Thika Road vicinity, Park or Muthaiga area Karin."}, {'role': 'user', 'content': "We're going to directions from Strathmore University to Mothiga."}, {'role': 'assistant', 'content': 'From Strathmore University, driving directions to Muthaiga area would usually mean heading southwest towards Thika Road. Take the Thika Road highway, after approximately 5-7 minutes, you should take the exit for Muthaiga-Garissa Road, and then continue on the road, taking a left turn onto Sussex Road which will lead to the Muthaiga neighborhood and other surrounding estates, please note these directions might vary depending on real-time traffic conditions or personal preference, do you need turn-by-turn directions or more detailed information.'}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:41:51,900 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:41:51,900 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:41:51,904 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:41:51,905 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:41:51,905 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:41:51,905 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:41:52,654 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:41:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19023'), (b'x-ratelimit-reset-requests', b'11.448999999s'), (b'x-ratelimit-reset-tokens', b'2.931s'), (b'x-request-id', b'req_01jaq78nfgekns8e8ehqxbqfdy'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d604b5babed73c6-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:41:52,654 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:41:52,654 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:41:52,654 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:41:52,654 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:41:52,654 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:41:52,654 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:41:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19023', 'x-ratelimit-reset-requests': '11.448999999s', 'x-ratelimit-reset-tokens': '2.931s', 'x-request-id': 'req_01jaq78nfgekns8e8ehqxbqfdy', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d604b5babed73c6-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:41:52,654 - gtts.tts - DEBUG - text: As I mentioned earlier, I'm a multi-modal AI voice assistant designed to provide informative and helpful responses to your questions and engage in conversations based on the context you provide, my capabilities include text-based and voice-based interactions, and I can respond to voice commands, text prompts, and even visually-aided requests like image recognition.
2024-10-21 12:41:52,662 - gtts.tts - DEBUG - tld: com
2024-10-21 12:41:52,662 - gtts.tts - DEBUG - lang: en
2024-10-21 12:41:52,662 - gtts.tts - DEBUG - slow: False
2024-10-21 12:41:52,663 - gtts.tts - DEBUG - lang_check: True
2024-10-21 12:41:52,663 - gtts.tts - DEBUG - pre_processor_funcs: [<function tone_marks at 0x0000011C7BA687C0>, <function end_of_line at 0x0000011C7BA68860>, <function abbreviations at 0x0000011C7BA68900>, <function word_sub at 0x0000011C7BA691C0>]
2024-10-21 12:41:52,668 - gtts.tts - DEBUG - timeout: None
2024-10-21 12:41:52,668 - gtts.lang - DEBUG - langs: {'af': 'Afrikaans', 'am': 'Amharic', 'ar': 'Arabic', 'bg': 'Bulgarian', 'bn': 'Bengali', 'bs': 'Bosnian', 'ca': 'Catalan', 'cs': 'Czech', 'cy': 'Welsh', 'da': 'Danish', 'de': 'German', 'el': 'Greek', 'en': 'English', 'es': 'Spanish', 'et': 'Estonian', 'eu': 'Basque', 'fi': 'Finnish', 'fr': 'French', 'gl': 'Galician', 'gu': 'Gujarati', 'ha': 'Hausa', 'hi': 'Hindi', 'hr': 'Croatian', 'hu': 'Hungarian', 'id': 'Indonesian', 'is': 'Icelandic', 'it': 'Italian', 'iw': 'Hebrew', 'ja': 'Japanese', 'jw': 'Javanese', 'km': 'Khmer', 'kn': 'Kannada', 'ko': 'Korean', 'la': 'Latin', 'lt': 'Lithuanian', 'lv': 'Latvian', 'ml': 'Malayalam', 'mr': 'Marathi', 'ms': 'Malay', 'my': 'Myanmar (Burmese)', 'ne': 'Nepali', 'nl': 'Dutch', 'no': 'Norwegian', 'pa': 'Punjabi (Gurmukhi)', 'pl': 'Polish', 'pt': 'Portuguese (Brazil)', 'pt-PT': 'Portuguese (Portugal)', 'ro': 'Romanian', 'ru': 'Russian', 'si': 'Sinhala', 'sk': 'Slovak', 'sq': 'Albanian', 'sr': 'Serbian', 'su': 'Sundanese', 'sv': 'Swedish', 'sw': 'Swahili', 'ta': 'Tamil', 'te': 'Telugu', 'th': 'Thai', 'tl': 'Filipino', 'tr': 'Turkish', 'uk': 'Ukrainian', 'ur': 'Urdu', 'vi': 'Vietnamese', 'yue': 'Cantonese', 'zh-CN': 'Chinese (Simplified)', 'zh-TW': 'Chinese (Mandarin/Taiwan)', 'zh': 'Chinese (Mandarin)'}
2024-10-21 12:41:52,669 - gtts.tts - DEBUG - pre-processing: <function tone_marks at 0x0000011C7BA687C0>
2024-10-21 12:41:52,670 - gtts.tts - DEBUG - pre-processing: <function end_of_line at 0x0000011C7BA68860>
2024-10-21 12:41:52,670 - gtts.tts - DEBUG - pre-processing: <function abbreviations at 0x0000011C7BA68900>
2024-10-21 12:41:52,670 - gtts.tts - DEBUG - pre-processing: <function word_sub at 0x0000011C7BA691C0>
2024-10-21 12:41:52,674 - gtts.tts - DEBUG - text_parts: ['As I mentioned earlier', "I'm a multi-modal AI voice assistant designed to provide informative and helpful responses to your", 'questions and engage in conversations based on the context you provide', 'my capabilities include text-based and voice-based interactions', 'and I can respond to voice commands', 'text prompts', 'and even visually-aided requests like image recognition.']
2024-10-21 12:41:52,675 - gtts.tts - DEBUG - text_parts: 7
2024-10-21 12:41:52,675 - gtts.tts - DEBUG - data-0: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22As%20I%20mentioned%20earlier%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:41:52,675 - gtts.tts - DEBUG - data-1: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22I%27m%20a%20multi-modal%20AI%20voice%20assistant%20designed%20to%20provide%20informative%20and%20helpful%20responses%20to%20your%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:41:52,675 - gtts.tts - DEBUG - data-2: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22questions%20and%20engage%20in%20conversations%20based%20on%20the%20context%20you%20provide%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:41:52,676 - gtts.tts - DEBUG - data-3: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22my%20capabilities%20include%20text-based%20and%20voice-based%20interactions%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:41:52,676 - gtts.tts - DEBUG - data-4: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22and%20I%20can%20respond%20to%20voice%20commands%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:41:52,677 - gtts.tts - DEBUG - data-5: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22text%20prompts%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:41:52,677 - gtts.tts - DEBUG - data-6: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22and%20even%20visually-aided%20requests%20like%20image%20recognition.%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 12:41:52,678 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:41:53,643 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:41:53,744 - gtts.tts - DEBUG - headers-0: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '158'}
2024-10-21 12:41:53,744 - gtts.tts - DEBUG - url-0: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:41:53,744 - gtts.tts - DEBUG - status-0: 200
2024-10-21 12:41:53,744 - gtts.tts - DEBUG - part-0 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:41:53,744 - gtts.tts - DEBUG - part-0 created
2024-10-21 12:41:53,744 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:41:54,632 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:41:55,142 - gtts.tts - DEBUG - headers-1: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '258'}
2024-10-21 12:41:55,153 - gtts.tts - DEBUG - url-1: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:41:55,153 - gtts.tts - DEBUG - status-1: 200
2024-10-21 12:41:55,153 - gtts.tts - DEBUG - part-1 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:41:55,153 - gtts.tts - DEBUG - part-1 created
2024-10-21 12:41:55,153 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:41:56,813 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:41:57,076 - gtts.tts - DEBUG - headers-2: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '220'}
2024-10-21 12:41:57,077 - gtts.tts - DEBUG - url-2: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:41:57,077 - gtts.tts - DEBUG - status-2: 200
2024-10-21 12:41:57,079 - gtts.tts - DEBUG - part-2 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:41:57,080 - gtts.tts - DEBUG - part-2 created
2024-10-21 12:41:57,080 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:41:57,911 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:41:58,158 - gtts.tts - DEBUG - headers-3: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '205'}
2024-10-21 12:41:58,158 - gtts.tts - DEBUG - url-3: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:41:58,158 - gtts.tts - DEBUG - status-3: 200
2024-10-21 12:41:58,158 - gtts.tts - DEBUG - part-3 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:41:58,158 - gtts.tts - DEBUG - part-3 created
2024-10-21 12:41:58,158 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:41:58,990 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:41:59,153 - gtts.tts - DEBUG - headers-4: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '177'}
2024-10-21 12:41:59,153 - gtts.tts - DEBUG - url-4: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:41:59,153 - gtts.tts - DEBUG - status-4: 200
2024-10-21 12:41:59,154 - gtts.tts - DEBUG - part-4 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:41:59,155 - gtts.tts - DEBUG - part-4 created
2024-10-21 12:41:59,155 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:42:00,010 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:42:00,118 - gtts.tts - DEBUG - headers-5: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '144'}
2024-10-21 12:42:00,119 - gtts.tts - DEBUG - url-5: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:42:00,119 - gtts.tts - DEBUG - status-5: 200
2024-10-21 12:42:00,119 - gtts.tts - DEBUG - part-5 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:42:00,120 - gtts.tts - DEBUG - part-5 created
2024-10-21 12:42:00,121 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 12:42:00,922 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 12:42:01,121 - gtts.tts - DEBUG - headers-6: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '198'}
2024-10-21 12:42:01,121 - gtts.tts - DEBUG - url-6: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 12:42:01,121 - gtts.tts - DEBUG - status-6: 200
2024-10-21 12:42:01,121 - gtts.tts - DEBUG - part-6 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 12:42:01,137 - gtts.tts - DEBUG - part-6 created
2024-10-21 12:42:01,137 - gtts.tts - DEBUG - Saved to C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\ai_response\ai_response_audio.mp3
2024-10-21 12:42:01,175 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-f', 'mp3', '-i', 'C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
2024-10-21 12:42:06,282 - comtypes._post_coinit.unknwn - DEBUG - Calling CoUninitialize()
2024-10-21 12:42:06,283 - comtypes._post_coinit.unknwn - DEBUG - CoUninitialize() done.
2024-10-21 12:44:04,371 - __main__ - INFO - Starting main.py
2024-10-21 12:44:04,372 - __main__ - INFO - Chat log file path: C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\chat_history\2024\10\21.log
2024-10-21 12:44:04,373 - __main__ - INFO - API keys loaded successfully
2024-10-21 12:44:04,379 - comtypes - DEBUG - CoInitializeEx(None, 2)
2024-10-21 12:44:04,405 - comtypes.client._code_cache - INFO - Imported existing <module 'comtypes.gen' from 'C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\comtypes\\gen\\__init__.py'>
2024-10-21 12:44:04,406 - comtypes.client._code_cache - INFO - Using writeable comtypes cache directory: 'C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\comtypes\gen'
2024-10-21 12:44:04,463 - comtypes.client - DEBUG - SAPI.SPVoice -> {96749377-3391-11D2-9EE3-00C04F797396}
2024-10-21 12:44:04,463 - comtypes.client - DEBUG - CoCreateInstance({96749377-3391-11D2-9EE3-00C04F797396}, clsctx=None, interface=None)
2024-10-21 12:44:04,474 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IUnknown) ptr=0x187d618f640 at 187ed4b6f50>)
2024-10-21 12:44:04,474 - comtypes.client - DEBUG - Does implement IProvideClassInfo
2024-10-21 12:44:04,477 - comtypes.client - DEBUG - Default interface is {269316D8-57BD-11D2-9EEE-00C04F797396}
2024-10-21 12:44:04,477 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x187d618f680 at 187ed4b7350>
2024-10-21 12:44:04,478 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:44:04,478 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechVoice'>
2024-10-21 12:44:04,479 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechVoice) ptr=0x187d618f680 at 187ed4b72d0>
2024-10-21 12:44:04,479 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo) ptr=0x187d618f6a0 at 187ed4b6ed0>
2024-10-21 12:44:04,480 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x187ebbe8048 at 187ed4b6fd0>
2024-10-21 12:44:04,480 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x187ebbe80a0 at 187ed4b7050>
2024-10-21 12:44:04,480 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x187eba098b0 at 187ed4b7350>
2024-10-21 12:44:04,481 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x187d618f640 at 187ed4b6f50>
2024-10-21 12:44:04,481 - comtypes.client._events - DEBUG - <POINTER(ISpeechVoice) ptr=0x187d618f680 at 187ed4b72d0> using sinkinterface from clsid <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:44:04,482 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo2) ptr=0x187d618f6a0 at 187ed4b6f50>
2024-10-21 12:44:04,483 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000187ED24DAC0>: _ISpeechVoiceEvents.VoiceChange not implemented
2024-10-21 12:44:04,483 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000187ED24DAC0>: _ISpeechVoiceEvents.Bookmark not implemented
2024-10-21 12:44:04,484 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000187ED24DAC0>: _ISpeechVoiceEvents.Sentence not implemented
2024-10-21 12:44:04,484 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000187ED24DAC0>: _ISpeechVoiceEvents.Phoneme not implemented
2024-10-21 12:44:04,484 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000187ED24DAC0>: _ISpeechVoiceEvents.Viseme not implemented
2024-10-21 12:44:04,485 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000187ED24DAC0>: _ISpeechVoiceEvents.AudioLevel not implemented
2024-10-21 12:44:04,485 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000187ED24DAC0>: _ISpeechVoiceEvents.EnginePrivate not implemented
2024-10-21 12:44:04,485 - comtypes.client._events - DEBUG - Start advise <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:44:04,485 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000187ED24DAC0>.QueryInterface({A372ACD1-3BEF-4BBD-8FFB-CB3E2B416AF8}) -> S_OK
2024-10-21 12:44:04,486 - comtypes._comobject - DEBUG - 1 active COM objects: Added   <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000187ED24DAC0>
2024-10-21 12:44:04,486 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000187ED24DAC0>.AddRef() -> 1
2024-10-21 12:44:04,488 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IConnectionPointContainer) ptr=0x187d618f6a8 at 187ed51c750>
2024-10-21 12:44:04,553 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectToken) ptr=0x187d61d0f70 at 187ed51c750>)
2024-10-21 12:44:04,554 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x187d61d0f70 at 187ed51c750>
2024-10-21 12:44:04,555 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x187ef0ce6d0 at 187ed51c750>)
2024-10-21 12:44:04,555 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x187ef0f7290 at 187ed51c850>
2024-10-21 12:44:04,555 - comtypes.client - DEBUG - wrap_outparam(<POINTER(IDispatch) ptr=0x187ef00a790 at 187ed51ca50>)
2024-10-21 12:44:04,556 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IDispatch) ptr=0x187ef00a790 at 187ed51ca50>)
2024-10-21 12:44:04,556 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo, trying IProvideClassInfo2
2024-10-21 12:44:04,556 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo/IProvideClassInfo2
2024-10-21 12:44:04,557 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x187ebbe8150 at 187ed51cc50>
2024-10-21 12:44:04,558 - comtypes.client - DEBUG - Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}
2024-10-21 12:44:04,558 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x187ef00a790 at 187ed51cd50>
2024-10-21 12:44:04,558 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:44:04,558 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>
2024-10-21 12:44:04,558 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechObjectToken) ptr=0x187ef00a790 at 187ed51cc50>
2024-10-21 12:44:04,559 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x187ef00a790 at 187ed51cbd0>
2024-10-21 12:44:04,559 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x187ebbe8150 at 187ed51ccd0>
2024-10-21 12:44:04,559 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x187eba098b0 at 187ed51cd50>
2024-10-21 12:44:04,559 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x187ef00a790 at 187ed51ca50>
2024-10-21 12:44:04,559 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IEnumVARIANT) ptr=0x187ef0f7290 at 187ed51c8d0>
2024-10-21 12:44:04,560 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectTokens) ptr=0x187ef0ce6d0 at 187ed51c750>
2024-10-21 12:44:04,560 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x187ef00a790 at 187ed51cc50>
2024-10-21 12:44:04,561 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:44:04,563 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:44:04,812 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:44:04,813 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:44:05,215 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2024-10-21 12:44:05,824 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/Systran/faster-whisper-base/revision/main HTTP/1.1" 200 1848
2024-10-21 12:44:06,400 - __main__ - INFO - Siri instance initialized
2024-10-21 12:44:11,478 - faster_whisper - INFO - Processing audio with duration 00:02.461
2024-10-21 12:44:12,165 - faster_whisper - INFO - Detected language 'en' with probability 0.80
2024-10-21 12:44:12,167 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:44:12,340 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'And show them, describe what you see.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:44:12,467 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:44:12,468 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:44:12,572 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F05E5EB0>
2024-10-21 12:44:12,572 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000187ED51C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:44:12,706 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F05E5BE0>
2024-10-21 12:44:12,707 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:44:12,708 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:44:12,708 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:44:12,708 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:44:12,709 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:44:13,287 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:44:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19872'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'384ms'), (b'x-request-id', b'req_01jaq7cz1gemhtzg9s0trz0yef'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=KOPV.x9RxBYKr8F6sN9lk0kKsZi0MvlJugtdivMontU-1729503853-1.0.1.1-q042SvPvTFjY77VR1n0xiv5hAv_RxSXgle935VH6I1dfh2XzKXoBJE9zFdj2o1dnPDtQOpe7cJ8HXbyauh.gEg; path=/; expires=Mon, 21-Oct-24 10:14:13 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d604ecc1ef44ebc-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:44:13,289 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:44:13,289 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:44:13,291 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:44:13,291 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:44:13,291 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:44:13,292 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:44:13 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19872', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '384ms', 'x-request-id': 'req_01jaq7cz1gemhtzg9s0trz0yef', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=KOPV.x9RxBYKr8F6sN9lk0kKsZi0MvlJugtdivMontU-1729503853-1.0.1.1-q042SvPvTFjY77VR1n0xiv5hAv_RxSXgle935VH6I1dfh2XzKXoBJE9zFdj2o1dnPDtQOpe7cJ8HXbyauh.gEg; path=/; expires=Mon, 21-Oct-24 10:14:13 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8d604ecc1ef44ebc-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:44:14,260 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2024-10-21 12:44:14,260 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 4202
2024-10-21 12:44:16,962 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'USER_PROMPT: And show them, describe what you see.\n\nIMAGE_CONTEXT: The image is a completely black square. There are no objects or features present.  This suggests the user may be trying to trick the AI or is requesting a response based on a missing image.  \n'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:44:16,964 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:44:16,965 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:44:16,965 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:44:16,966 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:44:16,966 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:44:16,967 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:44:17,482 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:44:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19763'), (b'x-ratelimit-reset-requests', b'7.839s'), (b'x-ratelimit-reset-tokens', b'711ms'), (b'x-request-id', b'req_01jaq7d33nemhrh61b7cbsgbz9'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d604ee63e1c4ebc-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:44:17,484 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:44:17,484 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:44:17,485 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:44:17,485 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:44:17,486 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:44:17,486 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:44:18 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19763', 'x-ratelimit-reset-requests': '7.839s', 'x-ratelimit-reset-tokens': '711ms', 'x-request-id': 'req_01jaq7d33nemhrh61b7cbsgbz9', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d604ee63e1c4ebc-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:44:17,761 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'Based on the provided image context, I see a black square with no objects or features visible within it.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:44:17,763 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:44:17,764 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:44:17,923 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D5FBC0>
2024-10-21 12:44:17,923 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000187ED51D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:44:18,107 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D70080>
2024-10-21 12:44:18,108 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:44:18,108 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:44:18,109 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:44:18,109 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:44:18,110 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:44:18,585 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:44:19 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_cd79d4bc447ad173330844ffd19be4cb'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Kh7uFlu.esN0cM5TsX12CfNKldtHSauPa9zyC19Lr1o-1729503859-1.0.1.1-lo9KqvdoYjqzIgXJu15oZce8VTifWfR4HtuSEuBGwnfFvuBGDqS9PTCldcI5x.POhZz5uiLo4WKJPq6aN6gTGg; path=/; expires=Mon, 21-Oct-24 10:14:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=BJUn3F8SD41gwZ7tNzWWH90bC1PNFnHh1pGsK9biQtA-1729503859076-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d604eed5fc1051d-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:44:18,586 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:44:18,586 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers([('date', 'Mon, 21 Oct 2024 09:44:19 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_cd79d4bc447ad173330844ffd19be4cb'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Kh7uFlu.esN0cM5TsX12CfNKldtHSauPa9zyC19Lr1o-1729503859-1.0.1.1-lo9KqvdoYjqzIgXJu15oZce8VTifWfR4HtuSEuBGwnfFvuBGDqS9PTCldcI5x.POhZz5uiLo4WKJPq6aN6gTGg; path=/; expires=Mon, 21-Oct-24 10:14:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=BJUn3F8SD41gwZ7tNzWWH90bC1PNFnHh1pGsK9biQtA-1729503859076-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8d604eed5fc1051d-JNB'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-10-21 12:44:18,588 - openai._base_client - DEBUG - request_id: req_cd79d4bc447ad173330844ffd19be4cb
2024-10-21 12:44:18,588 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:44:18,592 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:44:18,592 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:44:18,592 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:44:18,593 - openai._base_client - DEBUG - 2 retries left
2024-10-21 12:44:18,593 - openai._base_client - INFO - Retrying request to /audio/speech in 0.394695 seconds
2024-10-21 12:44:18,988 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'Based on the provided image context, I see a black square with no objects or features visible within it.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:44:18,989 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:44:18,990 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:44:19,130 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D71580>
2024-10-21 12:44:19,130 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000187ED51D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:44:19,322 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D70E90>
2024-10-21 12:44:19,323 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:44:19,323 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:44:19,324 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:44:19,324 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:44:19,324 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:44:20,546 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:44:21 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'628'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_d5bb199d05635850cc43ed4348e307a3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d604ef4ff7893c9-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:44:20,547 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:44:20,547 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:44:21 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '628', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_d5bb199d05635850cc43ed4348e307a3', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d604ef4ff7893c9-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:44:20,548 - openai._base_client - DEBUG - request_id: req_d5bb199d05635850cc43ed4348e307a3
2024-10-21 12:44:20,549 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:44:27,020 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:44:27,021 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:44:27,022 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:44:42,623 - faster_whisper - INFO - Processing audio with duration 00:01.556
2024-10-21 12:44:43,322 - faster_whisper - INFO - Detected language 'en' with probability 0.42
2024-10-21 12:44:43,323 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:44:43,455 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:44:43,457 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:44:43,457 - httpcore.connection - DEBUG - close.started
2024-10-21 12:44:43,458 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:44:43,458 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:44:43,636 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D5D880>
2024-10-21 12:44:43,637 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000187ED51C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:44:43,786 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D5E870>
2024-10-21 12:44:43,786 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:44:43,787 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:44:43,787 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:44:43,788 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:44:43,788 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:44:44,384 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:44:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19881'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'357ms'), (b'x-request-id', b'req_01jaq7dxd6fz5sakvnc2s63ehh'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d604f8e6e3973b9-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:44:44,385 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:44:44,386 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:44:44,386 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:44:44,386 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:44:44,387 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:44:44,387 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:44:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19881', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '357ms', 'x-request-id': 'req_01jaq7dxd6fz5sakvnc2s63ehh', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d604f8e6e3973b9-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:44:44,390 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'USER_PROMPT: And show them, describe what you see.\n\nIMAGE_CONTEXT: The image is a completely black square. There are no objects or features present.  This suggests the user may be trying to trick the AI or is requesting a response based on a missing image.  \n'}, {'role': 'assistant', 'content': 'Based on the provided image context, I see a black square with no objects or features visible within it.'}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:44:44,391 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:44:44,392 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:44:44,393 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:44:44,393 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:44:44,393 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:44:44,394 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:44:45,745 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:44:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19727'), (b'x-ratelimit-reset-requests', b'10.682s'), (b'x-ratelimit-reset-tokens', b'819ms'), (b'x-request-id', b'req_01jaq7dypge318ppkzbs2c72m4'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d604f91ba5273b9-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:44:45,746 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:44:45,746 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:44:45,747 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:44:45,747 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:44:45,748 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:44:45,748 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:44:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19727', 'x-ratelimit-reset-requests': '10.682s', 'x-ratelimit-reset-tokens': '819ms', 'x-request-id': 'req_01jaq7dypge318ppkzbs2c72m4', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d604f91ba5273b9-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:44:45,924 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "It appears I've completed the prompt given the image's absence of described content concerning myself.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:44:45,924 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:44:45,925 - httpcore.connection - DEBUG - close.started
2024-10-21 12:44:45,925 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:44:45,926 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:44:46,054 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D72330>
2024-10-21 12:44:46,054 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000187ED51D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:44:46,204 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F05E5BE0>
2024-10-21 12:44:46,204 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:44:46,205 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:44:46,205 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:44:46,206 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:44:46,206 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:44:46,637 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:44:47 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_e7ad0b11b4ce77129547b049264c23d2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d604f9ceeea73a2-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:44:46,639 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:44:46,639 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:44:47 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_e7ad0b11b4ce77129547b049264c23d2', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d604f9ceeea73a2-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:44:46,640 - openai._base_client - DEBUG - request_id: req_e7ad0b11b4ce77129547b049264c23d2
2024-10-21 12:44:46,641 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:44:46,643 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:44:46,643 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:44:46,644 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:44:46,644 - openai._base_client - DEBUG - 2 retries left
2024-10-21 12:44:46,644 - openai._base_client - INFO - Retrying request to /audio/speech in 0.436717 seconds
2024-10-21 12:44:47,082 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "It appears I've completed the prompt given the image's absence of described content concerning myself.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:44:47,083 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:44:47,083 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:44:47,200 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D70A40>
2024-10-21 12:44:47,201 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000187ED51D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:44:47,348 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D71EB0>
2024-10-21 12:44:47,349 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:44:47,349 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:44:47,350 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:44:47,350 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:44:47,351 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:44:47,865 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:44:48 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_01d31948840c12b965044f8caa43ba03'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d604fa43e654ed9-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:44:47,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:44:47,866 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:44:48 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_01d31948840c12b965044f8caa43ba03', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d604fa43e654ed9-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:44:47,867 - openai._base_client - DEBUG - request_id: req_01d31948840c12b965044f8caa43ba03
2024-10-21 12:44:47,868 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:44:47,871 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:44:47,871 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:44:47,872 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:44:47,872 - openai._base_client - DEBUG - 1 retry left
2024-10-21 12:44:47,872 - openai._base_client - INFO - Retrying request to /audio/speech in 0.892689 seconds
2024-10-21 12:44:48,765 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "It appears I've completed the prompt given the image's absence of described content concerning myself.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:44:48,767 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:44:48,767 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:44:48,876 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D72B10>
2024-10-21 12:44:48,876 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000187ED51D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:44:49,068 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D721E0>
2024-10-21 12:44:49,068 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:44:49,069 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:44:49,069 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:44:49,070 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:44:49,070 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:44:50,249 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:44:50 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'716'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_be705b4d6c2b0112b3572d2f08bc7803'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d604faedc344ebf-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:44:50,250 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:44:50,251 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:44:50 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '716', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_be705b4d6c2b0112b3572d2f08bc7803', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d604faedc344ebf-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:44:50,251 - openai._base_client - DEBUG - request_id: req_be705b4d6c2b0112b3572d2f08bc7803
2024-10-21 12:44:50,252 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:44:56,198 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:44:56,199 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:44:56,199 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:45:02,164 - faster_whisper - INFO - Processing audio with duration 00:02.624
2024-10-21 12:45:02,792 - faster_whisper - INFO - Detected language 'en' with probability 0.40
2024-10-21 12:45:02,793 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:45:02,925 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:45:02,926 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:45:02,926 - httpcore.connection - DEBUG - close.started
2024-10-21 12:45:02,927 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:45:02,927 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:45:03,030 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D5F2C0>
2024-10-21 12:45:03,031 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000187ED51C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:45:03,164 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F05E7B90>
2024-10-21 12:45:03,165 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:45:03,165 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:45:03,165 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:45:03,166 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:45:03,166 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:45:03,646 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:45:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19881'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'357ms'), (b'x-request-id', b'req_01jaq7eg75e5arwwshrqnt9q5w'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d605006d9cf051d-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:45:03,647 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:45:03,648 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:45:03,648 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:45:03,649 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:45:03,649 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:45:03,649 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:45:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19881', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '357ms', 'x-request-id': 'req_01jaq7eg75e5arwwshrqnt9q5w', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d605006d9cf051d-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:45:03,653 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'USER_PROMPT: And show them, describe what you see.\n\nIMAGE_CONTEXT: The image is a completely black square. There are no objects or features present.  This suggests the user may be trying to trick the AI or is requesting a response based on a missing image.  \n'}, {'role': 'assistant', 'content': 'Based on the provided image context, I see a black square with no objects or features visible within it.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': "It appears I've completed the prompt given the image's absence of described content concerning myself."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:45:03,654 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:45:03,655 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:45:03,655 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:45:03,655 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:45:03,656 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:45:03,656 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:45:04,184 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:45:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19692'), (b'x-ratelimit-reset-requests', b'11.506999999s'), (b'x-ratelimit-reset-tokens', b'924ms'), (b'x-request-id', b'req_01jaq7egpkfc5vqdx5ek9zgbjc'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d605009fd44051d-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:45:04,186 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:45:04,186 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:45:04,186 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:45:04,187 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:45:04,187 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:45:04,187 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:45:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19692', 'x-ratelimit-reset-requests': '11.506999999s', 'x-ratelimit-reset-tokens': '924ms', 'x-request-id': 'req_01jaq7egpkfc5vqdx5ek9zgbjc', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d605009fd44051d-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:45:04,360 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'There\'s no further information or image context provided to describe or respond to the context of "You".', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:45:04,360 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:45:04,361 - httpcore.connection - DEBUG - close.started
2024-10-21 12:45:04,361 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:45:04,361 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:45:04,503 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D73530>
2024-10-21 12:45:04,503 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000187ED51D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:45:04,640 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D73BF0>
2024-10-21 12:45:04,641 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:45:04,641 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:45:04,642 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:45:04,642 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:45:04,642 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:45:05,040 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:45:05 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_93a6b66503d9cb2e5deff8389cf31ce4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6050102e6f4ec1-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:45:05,041 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:45:05,041 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:45:05 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_93a6b66503d9cb2e5deff8389cf31ce4', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6050102e6f4ec1-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:45:05,042 - openai._base_client - DEBUG - request_id: req_93a6b66503d9cb2e5deff8389cf31ce4
2024-10-21 12:45:05,043 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:45:05,045 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:45:05,045 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:45:05,046 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:45:05,046 - openai._base_client - DEBUG - 2 retries left
2024-10-21 12:45:05,046 - openai._base_client - INFO - Retrying request to /audio/speech in 0.462924 seconds
2024-10-21 12:45:05,510 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'There\'s no further information or image context provided to describe or respond to the context of "You".', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:45:05,512 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:45:05,512 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:45:05,657 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D72030>
2024-10-21 12:45:05,657 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000187ED51D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:45:05,809 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D706B0>
2024-10-21 12:45:05,809 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:45:05,809 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:45:05,810 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:45:05,811 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:45:05,811 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:45:06,208 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:45:06 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_1d98b3094ad16edd676f49b61b6fb9b8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6050176a424fbd-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:45:06,209 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:45:06,210 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:45:06 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_1d98b3094ad16edd676f49b61b6fb9b8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6050176a424fbd-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:45:06,211 - openai._base_client - DEBUG - request_id: req_1d98b3094ad16edd676f49b61b6fb9b8
2024-10-21 12:45:06,211 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:45:06,214 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:45:06,215 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:45:06,215 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:45:06,216 - openai._base_client - DEBUG - 1 retry left
2024-10-21 12:45:06,216 - openai._base_client - INFO - Retrying request to /audio/speech in 0.752146 seconds
2024-10-21 12:45:06,969 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'There\'s no further information or image context provided to describe or respond to the context of "You".', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:45:06,971 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:45:06,971 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:45:07,140 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D725A0>
2024-10-21 12:45:07,140 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000187ED51D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:45:07,318 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000187F0D71970>
2024-10-21 12:45:07,319 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:45:07,320 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:45:07,321 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:45:07,321 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:45:07,322 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:45:07,790 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:45:08 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_41d42be55c6ee13bc65d0a18b8518fac'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d605020e8a873d6-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:45:07,791 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:45:07,792 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:45:08 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_41d42be55c6ee13bc65d0a18b8518fac', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d605020e8a873d6-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:45:07,793 - openai._base_client - DEBUG - request_id: req_41d42be55c6ee13bc65d0a18b8518fac
2024-10-21 12:45:07,793 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:45:07,797 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:45:07,797 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:45:07,797 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:45:07,798 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:45:07,798 - openai._base_client - DEBUG - Re-raising status error
2024-10-21 12:55:20,612 - comtypes._post_coinit.unknwn - DEBUG - Calling CoUninitialize()
2024-10-21 12:55:20,612 - comtypes._post_coinit.unknwn - DEBUG - CoUninitialize() done.
2024-10-21 12:55:20,849 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000187ED24DAC0>.Release() -> 0
2024-10-21 12:55:20,850 - comtypes._comobject - DEBUG - 0 active COM objects: Removed <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000187ED24DAC0>
2024-10-21 12:55:20,850 - comtypes._comobject - DEBUG - Remaining: []
2024-10-21 12:55:20,917 - httpcore.connection - DEBUG - close.started
2024-10-21 12:55:20,917 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:55:20,918 - httpcore.connection - DEBUG - close.started
2024-10-21 12:55:20,918 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:55:23,884 - __main__ - INFO - Starting main.py
2024-10-21 12:55:23,885 - __main__ - INFO - Chat log file path: C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\chat_history\2024\10\21.log
2024-10-21 12:55:23,886 - __main__ - INFO - API keys loaded successfully
2024-10-21 12:55:23,886 - __main__ - ERROR - An error occurred: module 'src.pro' has no attribute 'pro'
Traceback (most recent call last):
  File "C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\main.py", line 48, in <module>
    pro_instance = pro.pro(
                   ^^^^^^^
AttributeError: module 'src.pro' has no attribute 'pro'. Did you mean: 'Pro'?
2024-10-21 12:55:41,612 - __main__ - INFO - Starting main.py
2024-10-21 12:55:41,613 - __main__ - INFO - Chat log file path: C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\chat_history\2024\10\21.log
2024-10-21 12:55:41,614 - __main__ - INFO - API keys loaded successfully
2024-10-21 12:55:41,621 - comtypes - DEBUG - CoInitializeEx(None, 2)
2024-10-21 12:55:41,650 - comtypes.client._code_cache - INFO - Imported existing <module 'comtypes.gen' from 'C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\comtypes\\gen\\__init__.py'>
2024-10-21 12:55:41,651 - comtypes.client._code_cache - INFO - Using writeable comtypes cache directory: 'C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\comtypes\gen'
2024-10-21 12:55:41,699 - comtypes.client - DEBUG - SAPI.SPVoice -> {96749377-3391-11D2-9EE3-00C04F797396}
2024-10-21 12:55:41,699 - comtypes.client - DEBUG - CoCreateInstance({96749377-3391-11D2-9EE3-00C04F797396}, clsctx=None, interface=None)
2024-10-21 12:55:41,708 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IUnknown) ptr=0x1968e38f640 at 196a57b6f50>)
2024-10-21 12:55:41,709 - comtypes.client - DEBUG - Does implement IProvideClassInfo
2024-10-21 12:55:41,711 - comtypes.client - DEBUG - Default interface is {269316D8-57BD-11D2-9EEE-00C04F797396}
2024-10-21 12:55:41,711 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1968e38f680 at 196a57b7350>
2024-10-21 12:55:41,712 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:55:41,712 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechVoice'>
2024-10-21 12:55:41,712 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechVoice) ptr=0x1968e38f680 at 196a57b72d0>
2024-10-21 12:55:41,713 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo) ptr=0x1968e38f6a0 at 196a57b6ed0>
2024-10-21 12:55:41,713 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x196a4002048 at 196a57b6fd0>
2024-10-21 12:55:41,713 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x196a40020a0 at 196a57b7050>
2024-10-21 12:55:41,713 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x196a3cfc310 at 196a57b7350>
2024-10-21 12:55:41,714 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1968e38f640 at 196a57b6f50>
2024-10-21 12:55:41,714 - comtypes.client._events - DEBUG - <POINTER(ISpeechVoice) ptr=0x1968e38f680 at 196a57b72d0> using sinkinterface from clsid <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:55:41,715 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo2) ptr=0x1968e38f6a0 at 196a57b6f50>
2024-10-21 12:55:41,715 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000196A5544590>: _ISpeechVoiceEvents.VoiceChange not implemented
2024-10-21 12:55:41,716 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000196A5544590>: _ISpeechVoiceEvents.Bookmark not implemented
2024-10-21 12:55:41,716 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000196A5544590>: _ISpeechVoiceEvents.Sentence not implemented
2024-10-21 12:55:41,717 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000196A5544590>: _ISpeechVoiceEvents.Phoneme not implemented
2024-10-21 12:55:41,717 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000196A5544590>: _ISpeechVoiceEvents.Viseme not implemented
2024-10-21 12:55:41,717 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000196A5544590>: _ISpeechVoiceEvents.AudioLevel not implemented
2024-10-21 12:55:41,717 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000196A5544590>: _ISpeechVoiceEvents.EnginePrivate not implemented
2024-10-21 12:55:41,718 - comtypes.client._events - DEBUG - Start advise <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:55:41,718 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000196A5544590>.QueryInterface({A372ACD1-3BEF-4BBD-8FFB-CB3E2B416AF8}) -> S_OK
2024-10-21 12:55:41,718 - comtypes._comobject - DEBUG - 1 active COM objects: Added   <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000196A5544590>
2024-10-21 12:55:41,719 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000196A5544590>.AddRef() -> 1
2024-10-21 12:55:41,722 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IConnectionPointContainer) ptr=0x1968e38f6a8 at 196a581c750>
2024-10-21 12:55:41,782 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectToken) ptr=0x1968e3d0f70 at 196a581c750>)
2024-10-21 12:55:41,782 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x1968e3d0f70 at 196a581c750>
2024-10-21 12:55:41,783 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x196a5ace450 at 196a581c750>)
2024-10-21 12:55:41,784 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x196a5af71f0 at 196a581c850>
2024-10-21 12:55:41,784 - comtypes.client - DEBUG - wrap_outparam(<POINTER(IDispatch) ptr=0x196a5a0aee0 at 196a581ca50>)
2024-10-21 12:55:41,784 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IDispatch) ptr=0x196a5a0aee0 at 196a581ca50>)
2024-10-21 12:55:41,785 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo, trying IProvideClassInfo2
2024-10-21 12:55:41,785 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo/IProvideClassInfo2
2024-10-21 12:55:41,786 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x196a4002150 at 196a581cc50>
2024-10-21 12:55:41,786 - comtypes.client - DEBUG - Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}
2024-10-21 12:55:41,787 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x196a5a0aee0 at 196a581cd50>
2024-10-21 12:55:41,787 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:55:41,787 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>
2024-10-21 12:55:41,787 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechObjectToken) ptr=0x196a5a0aee0 at 196a581cc50>
2024-10-21 12:55:41,788 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x196a5a0aee0 at 196a581cbd0>
2024-10-21 12:55:41,788 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x196a4002150 at 196a581ccd0>
2024-10-21 12:55:41,788 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x196a3cfc310 at 196a581cd50>
2024-10-21 12:55:41,788 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x196a5a0aee0 at 196a581ca50>
2024-10-21 12:55:41,788 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IEnumVARIANT) ptr=0x196a5af71f0 at 196a581c8d0>
2024-10-21 12:55:41,789 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectTokens) ptr=0x196a5ace450 at 196a581c750>
2024-10-21 12:55:41,789 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x196a5a0aee0 at 196a581cc50>
2024-10-21 12:55:41,790 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:55:41,792 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:55:42,018 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:55:42,019 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:55:42,406 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2024-10-21 12:55:43,532 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/Systran/faster-whisper-base/revision/main HTTP/1.1" 200 1848
2024-10-21 12:55:44,173 - __main__ - INFO - pro instance initialized
2024-10-21 12:55:58,001 - faster_whisper - INFO - Processing audio with duration 00:01.440
2024-10-21 12:55:58,671 - faster_whisper - INFO - Detected language 'en' with probability 0.32
2024-10-21 12:55:58,672 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:55:58,769 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Hello.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:55:58,893 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:55:58,893 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:55:59,001 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196A88E5D60>
2024-10-21 12:55:59,001 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000196A581C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:55:59,129 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196A88E5940>
2024-10-21 12:55:59,129 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:55:59,129 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:55:59,129 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:55:59,130 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:55:59,130 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:56:00,461 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:56:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19880'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'360ms'), (b'x-request-id', b'req_01jaq82hmser988c0tntsf9914'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YKLqeARVdNLuGY2BOBOeXtSQhvOkhoaqdk4MuBqsEy0-1729504560-1.0.1.1-iom8XDzDgZkCriCjfnWphMMkewWi2tD3LwZcxP286r2IJmuWv5nNR9UkQ.p4FlqCyT7VbomELEOlo4VG6_JhpA; path=/; expires=Mon, 21-Oct-24 10:26:00 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60600abe564ed6-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:56:00,463 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:56:00,464 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:56:00,464 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:56:00,464 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:56:00,465 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:56:00,465 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:56:00 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19880', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '360ms', 'x-request-id': 'req_01jaq82hmser988c0tntsf9914', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=YKLqeARVdNLuGY2BOBOeXtSQhvOkhoaqdk4MuBqsEy0-1729504560-1.0.1.1-iom8XDzDgZkCriCjfnWphMMkewWi2tD3LwZcxP286r2IJmuWv5nNR9UkQ.p4FlqCyT7VbomELEOlo4VG6_JhpA; path=/; expires=Mon, 21-Oct-24 10:26:00 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8d60600abe564ed6-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:56:00,470 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'Hello.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:56:00,472 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:56:00,472 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:56:00,473 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:56:00,473 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:56:00,474 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:56:00,474 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:56:01,008 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:56:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19826'), (b'x-ratelimit-reset-requests', b'11.500999999s'), (b'x-ratelimit-reset-tokens', b'522ms'), (b'x-request-id', b'req_01jaq82j48f7gtc9wcsze70gqp'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60601319574ed6-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:56:01,009 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:56:01,010 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:56:01,010 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:56:01,010 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:56:01,011 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:56:01,011 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:56:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19826', 'x-ratelimit-reset-requests': '11.500999999s', 'x-ratelimit-reset-tokens': '522ms', 'x-request-id': 'req_01jaq82j48f7gtc9wcsze70gqp', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60601319574ed6-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:56:01,282 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I'm happy to help, could you please provide more information or ask a question, I'm here to assist you.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:56:01,283 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:56:01,283 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:56:01,395 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196AA5261B0>
2024-10-21 12:56:01,396 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000196A581D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:56:01,518 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196AA5260C0>
2024-10-21 12:56:01,519 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:56:01,520 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:56:01,520 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:56:01,521 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:56:01,521 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:57:32,584 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:57:33 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_f2c3632772bab7a920081c1828afd059'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=kAsUmSWZ3iF0vK34cCmIN1BgVsP7TNLXLlh._XR9XLo-1729504653-1.0.1.1-mfX9Ihm1n81XsCNEFrUb_dfZqp7mfZcpmbDkf9HeAIzdY0NNqMhFtqvGAZdkzWJXyDTR7kzqRZ95Cuq0iClfng; path=/; expires=Mon, 21-Oct-24 10:27:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=kdAsV.eVLfQOKKVhV4X20Ljm70aaPZcMLluAww33ziY-1729504653133-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d606019ba734ece-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:57:32,586 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:57:32,586 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers([('date', 'Mon, 21 Oct 2024 09:57:33 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_f2c3632772bab7a920081c1828afd059'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=kAsUmSWZ3iF0vK34cCmIN1BgVsP7TNLXLlh._XR9XLo-1729504653-1.0.1.1-mfX9Ihm1n81XsCNEFrUb_dfZqp7mfZcpmbDkf9HeAIzdY0NNqMhFtqvGAZdkzWJXyDTR7kzqRZ95Cuq0iClfng; path=/; expires=Mon, 21-Oct-24 10:27:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=kdAsV.eVLfQOKKVhV4X20Ljm70aaPZcMLluAww33ziY-1729504653133-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8d606019ba734ece-JNB'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-10-21 12:57:32,587 - openai._base_client - DEBUG - request_id: req_f2c3632772bab7a920081c1828afd059
2024-10-21 12:57:32,588 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:57:32,591 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:57:32,591 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:57:32,592 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:57:32,592 - openai._base_client - DEBUG - 2 retries left
2024-10-21 12:57:32,593 - openai._base_client - INFO - Retrying request to /audio/speech in 0.452299 seconds
2024-10-21 12:57:33,046 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I'm happy to help, could you please provide more information or ask a question, I'm here to assist you.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:57:33,048 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:57:33,049 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:57:33,158 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196AA527650>
2024-10-21 12:57:33,158 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000196A581D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:57:33,280 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196AA527050>
2024-10-21 12:57:33,280 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:57:33,281 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:57:33,281 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:57:33,282 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:57:33,282 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:57:35,942 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:57:36 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1641'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_aa847ff40170ac984c84b115396301a7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60625728e64eb2-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:57:35,943 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:57:35,943 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:57:36 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1641', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_aa847ff40170ac984c84b115396301a7', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d60625728e64eb2-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:57:35,944 - openai._base_client - DEBUG - request_id: req_aa847ff40170ac984c84b115396301a7
2024-10-21 12:57:35,944 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:57:42,297 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:57:42,298 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:57:42,298 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:57:48,164 - faster_whisper - INFO - Processing audio with duration 00:04.040
2024-10-21 12:57:48,982 - faster_whisper - INFO - Detected language 'en' with probability 0.52
2024-10-21 12:57:48,984 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:57:49,137 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.0 (-1.241399 < -1.000000)
2024-10-21 12:57:49,488 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.2 (-1.246162 < -1.000000)
2024-10-21 12:57:49,807 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.4 (-1.264722 < -1.000000)
2024-10-21 12:57:50,067 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.6 (-1.264722 < -1.000000)
2024-10-21 12:57:50,391 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.8 (-1.998035 < -1.000000)
2024-10-21 12:57:50,825 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 1.0 (-2.504400 < -1.000000)
2024-10-21 12:57:50,826 - faster_whisper - DEBUG - Reset prompt. prompt_reset_on_temperature threshold is met 1.000000 > 0.500000
2024-10-21 12:57:50,829 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': "I'm just creating it."}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:57:50,831 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:57:50,831 - httpcore.connection - DEBUG - close.started
2024-10-21 12:57:50,832 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:57:50,832 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:57:50,939 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196A88E5A00>
2024-10-21 12:57:50,940 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000196A581C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:57:51,093 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196A85D85F0>
2024-10-21 12:57:51,094 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:57:51,094 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:57:51,094 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:57:51,095 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:57:51,095 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:57:51,589 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:57:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19876'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'372ms'), (b'x-request-id', b'req_01jaq85y5nft8vsqsvfzkjw0hf'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6062c68c0b73e8-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:57:51,591 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:57:51,591 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:57:51,592 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:57:51,592 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:57:51,592 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:57:51,593 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:57:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19876', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '372ms', 'x-request-id': 'req_01jaq85y5nft8vsqsvfzkjw0hf', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6062c68c0b73e8-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:57:51,596 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'Hello.'}, {'role': 'assistant', 'content': "I'm happy to help, could you please provide more information or ask a question, I'm here to assist you."}, {'role': 'user', 'content': "I'm just creating it."}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:57:51,598 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:57:51,598 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:57:51,599 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:57:51,599 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:57:51,599 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:57:51,600 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:57:52,218 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:57:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19786'), (b'x-ratelimit-reset-requests', b'11.431s'), (b'x-ratelimit-reset-tokens', b'642ms'), (b'x-request-id', b'req_01jaq85yqfffya99fsdzdgg451'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6062c9f84773e8-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:57:52,219 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:57:52,220 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:57:52,220 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:57:52,221 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:57:52,221 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:57:52,221 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:57:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19786', 'x-ratelimit-reset-requests': '11.431s', 'x-ratelimit-reset-tokens': '642ms', 'x-request-id': 'req_01jaq85yqfffya99fsdzdgg451', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6062c9f84773e8-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:57:52,395 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "You're testing the AI assistant, how can I assist you during this testing process, please provide a voice prompt or relevant context, I'll do my best to provide a helpful response,", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:57:52,396 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:57:52,397 - httpcore.connection - DEBUG - close.started
2024-10-21 12:57:52,397 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:57:52,398 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:57:52,522 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196AA526480>
2024-10-21 12:57:52,522 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000196A581D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:57:52,805 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196AA5276B0>
2024-10-21 12:57:52,805 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:57:52,806 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:57:52,806 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:57:52,807 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:57:52,807 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:57:53,306 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:57:53 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_891f24244afea1e2d7d290e9297ebc49'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6062d11a5a73d4-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:57:53,308 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:57:53,308 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:57:53 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_891f24244afea1e2d7d290e9297ebc49', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6062d11a5a73d4-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:57:53,309 - openai._base_client - DEBUG - request_id: req_891f24244afea1e2d7d290e9297ebc49
2024-10-21 12:57:53,309 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:57:53,311 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:57:53,311 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:57:53,312 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:57:53,312 - openai._base_client - DEBUG - 2 retries left
2024-10-21 12:57:53,312 - openai._base_client - INFO - Retrying request to /audio/speech in 0.414202 seconds
2024-10-21 12:57:53,727 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "You're testing the AI assistant, how can I assist you during this testing process, please provide a voice prompt or relevant context, I'll do my best to provide a helpful response,", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:57:53,728 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:57:53,729 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:57:53,853 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196AA5249B0>
2024-10-21 12:57:53,854 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000196A581D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:57:53,992 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196AA5259D0>
2024-10-21 12:57:53,992 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:57:53,993 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:57:53,993 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:57:53,994 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:57:53,994 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:57:55,988 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:57:56 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'968'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_acae50106ec057488fd7ba9ff221c815'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6062d8986a73c1-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:57:55,989 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:57:55,989 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:57:56 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '968', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_acae50106ec057488fd7ba9ff221c815', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6062d8986a73c1-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:57:55,990 - openai._base_client - DEBUG - request_id: req_acae50106ec057488fd7ba9ff221c815
2024-10-21 12:57:55,991 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:58:07,246 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:58:07,247 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:58:07,248 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:58:15,955 - faster_whisper - INFO - Processing audio with duration 00:06.200
2024-10-21 12:58:16,590 - faster_whisper - INFO - Detected language 'en' with probability 0.75
2024-10-21 12:58:16,591 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:58:16,703 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.0 (-1.400433 < -1.000000)
2024-10-21 12:58:17,035 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.2 (-1.449844 < -1.000000)
2024-10-21 12:58:17,327 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.4 (-1.450350 < -1.000000)
2024-10-21 12:58:17,819 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.6 (-1.667772 < -1.000000)
2024-10-21 12:58:18,123 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.8 (-2.460308 < -1.000000)
2024-10-21 12:58:18,452 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 1.0 (-2.705516 < -1.000000)
2024-10-21 12:58:18,453 - faster_whisper - DEBUG - Reset prompt. prompt_reset_on_temperature threshold is met 1.000000 > 0.500000
2024-10-21 12:58:18,457 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': "I'll check screenshots."}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:58:18,458 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:58:18,459 - httpcore.connection - DEBUG - close.started
2024-10-21 12:58:18,459 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:58:18,460 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:58:18,723 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196A88E7C20>
2024-10-21 12:58:18,723 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000196A581C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:58:18,967 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196A88E7140>
2024-10-21 12:58:18,967 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:58:18,968 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:58:18,968 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:58:18,969 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:58:18,969 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:58:19,455 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:58:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19876'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'372ms'), (b'x-request-id', b'req_01jaq86scdfxr9kj7sqfa13qrt'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d606374aa6c4eb7-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:58:19,456 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:58:19,457 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:58:19,458 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:58:19,458 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:58:19,459 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:58:19,459 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:58:19 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19876', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '372ms', 'x-request-id': 'req_01jaq86scdfxr9kj7sqfa13qrt', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d606374aa6c4eb7-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:58:19,637 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'Screenshot deleted successfully.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:58:19,639 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:58:19,639 - httpcore.connection - DEBUG - close.started
2024-10-21 12:58:19,640 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:58:19,640 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:58:19,766 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196AA527BF0>
2024-10-21 12:58:19,766 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000196A581D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:58:19,901 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196AA524DD0>
2024-10-21 12:58:19,902 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:58:19,902 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:58:19,903 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:58:19,903 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:58:19,903 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:58:20,311 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:58:20 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_184c7c2ea875c4663fa109e0b417b0af'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60637a988673cc-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:58:20,312 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:58:20,313 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:58:20 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_184c7c2ea875c4663fa109e0b417b0af', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d60637a988673cc-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:58:20,313 - openai._base_client - DEBUG - request_id: req_184c7c2ea875c4663fa109e0b417b0af
2024-10-21 12:58:20,314 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:58:20,316 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:58:20,316 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:58:20,317 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:58:20,317 - openai._base_client - DEBUG - 2 retries left
2024-10-21 12:58:20,318 - openai._base_client - INFO - Retrying request to /audio/speech in 0.410302 seconds
2024-10-21 12:58:20,729 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'Screenshot deleted successfully.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:58:20,730 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:58:20,730 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:58:20,880 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196AA5251C0>
2024-10-21 12:58:20,880 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000196A581D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:58:21,001 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196AA524B30>
2024-10-21 12:58:21,002 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:58:21,002 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:58:21,003 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:58:21,003 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:58:21,004 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:58:22,026 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:58:22 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_0bf8b14905388f6740993be34fa90112'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6063816f7d4fcb-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:58:22,027 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:58:22,028 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:58:22 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_0bf8b14905388f6740993be34fa90112', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6063816f7d4fcb-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:58:22,028 - openai._base_client - DEBUG - request_id: req_0bf8b14905388f6740993be34fa90112
2024-10-21 12:58:22,028 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:58:22,031 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:58:22,031 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:58:22,031 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:58:22,031 - openai._base_client - DEBUG - 1 retry left
2024-10-21 12:58:22,032 - openai._base_client - INFO - Retrying request to /audio/speech in 0.894365 seconds
2024-10-21 12:58:22,927 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'Screenshot deleted successfully.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:58:22,928 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:58:22,928 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:58:23,039 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196AA525280>
2024-10-21 12:58:23,039 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000196A581D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:58:23,165 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000196A88E6810>
2024-10-21 12:58:23,166 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:58:23,166 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:58:23,167 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:58:23,167 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:58:23,168 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:58:23,976 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:58:24 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_6835ee84da2cd2cd64561f1fdde6a9cc'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60638eeac57405-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:58:23,977 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:58:23,977 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:58:24 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_6835ee84da2cd2cd64561f1fdde6a9cc', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d60638eeac57405-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:58:23,978 - openai._base_client - DEBUG - request_id: req_6835ee84da2cd2cd64561f1fdde6a9cc
2024-10-21 12:58:23,979 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:58:23,985 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:58:23,985 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:58:23,985 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:58:23,986 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:58:23,986 - openai._base_client - DEBUG - Re-raising status error
2024-10-21 12:59:36,635 - comtypes._post_coinit.unknwn - DEBUG - Calling CoUninitialize()
2024-10-21 12:59:36,636 - comtypes._post_coinit.unknwn - DEBUG - CoUninitialize() done.
2024-10-21 12:59:36,849 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000196A5544590>.Release() -> 0
2024-10-21 12:59:36,850 - comtypes._comobject - DEBUG - 0 active COM objects: Removed <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000196A5544590>
2024-10-21 12:59:36,850 - comtypes._comobject - DEBUG - Remaining: []
2024-10-21 12:59:36,928 - httpcore.connection - DEBUG - close.started
2024-10-21 12:59:36,928 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:59:36,929 - httpcore.connection - DEBUG - close.started
2024-10-21 12:59:36,929 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:59:39,462 - __main__ - INFO - Starting main.py
2024-10-21 12:59:39,463 - __main__ - INFO - Chat log file path: C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\chat_history\2024\10\21.log
2024-10-21 12:59:39,464 - __main__ - INFO - API keys loaded successfully
2024-10-21 12:59:39,471 - comtypes - DEBUG - CoInitializeEx(None, 2)
2024-10-21 12:59:39,495 - comtypes.client._code_cache - INFO - Imported existing <module 'comtypes.gen' from 'C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\comtypes\\gen\\__init__.py'>
2024-10-21 12:59:39,495 - comtypes.client._code_cache - INFO - Using writeable comtypes cache directory: 'C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\comtypes\gen'
2024-10-21 12:59:39,552 - comtypes.client - DEBUG - SAPI.SPVoice -> {96749377-3391-11D2-9EE3-00C04F797396}
2024-10-21 12:59:39,552 - comtypes.client - DEBUG - CoCreateInstance({96749377-3391-11D2-9EE3-00C04F797396}, clsctx=None, interface=None)
2024-10-21 12:59:39,563 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IUnknown) ptr=0x229e3f8f640 at 229fb3b6fd0>)
2024-10-21 12:59:39,564 - comtypes.client - DEBUG - Does implement IProvideClassInfo
2024-10-21 12:59:39,565 - comtypes.client - DEBUG - Default interface is {269316D8-57BD-11D2-9EEE-00C04F797396}
2024-10-21 12:59:39,566 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x229e3f8f680 at 229fb3b73d0>
2024-10-21 12:59:39,566 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:59:39,567 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechVoice'>
2024-10-21 12:59:39,567 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechVoice) ptr=0x229e3f8f680 at 229fb3b7350>
2024-10-21 12:59:39,567 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo) ptr=0x229e3f8f6a0 at 229fb3b6f50>
2024-10-21 12:59:39,568 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x229f9cc5048 at 229fb3b7050>
2024-10-21 12:59:39,568 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x229f9cc50a0 at 229fb3b70d0>
2024-10-21 12:59:39,568 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x229f98df060 at 229fb3b73d0>
2024-10-21 12:59:39,569 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x229e3f8f640 at 229fb3b6fd0>
2024-10-21 12:59:39,569 - comtypes.client._events - DEBUG - <POINTER(ISpeechVoice) ptr=0x229e3f8f680 at 229fb3b7350> using sinkinterface from clsid <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:59:39,570 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo2) ptr=0x229e3f8f6a0 at 229fb3b6fd0>
2024-10-21 12:59:39,571 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000229FB111280>: _ISpeechVoiceEvents.VoiceChange not implemented
2024-10-21 12:59:39,571 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000229FB111280>: _ISpeechVoiceEvents.Bookmark not implemented
2024-10-21 12:59:39,572 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000229FB111280>: _ISpeechVoiceEvents.Sentence not implemented
2024-10-21 12:59:39,572 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000229FB111280>: _ISpeechVoiceEvents.Phoneme not implemented
2024-10-21 12:59:39,572 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000229FB111280>: _ISpeechVoiceEvents.Viseme not implemented
2024-10-21 12:59:39,573 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000229FB111280>: _ISpeechVoiceEvents.AudioLevel not implemented
2024-10-21 12:59:39,573 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000229FB111280>: _ISpeechVoiceEvents.EnginePrivate not implemented
2024-10-21 12:59:39,574 - comtypes.client._events - DEBUG - Start advise <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:59:39,574 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000229FB111280>.QueryInterface({A372ACD1-3BEF-4BBD-8FFB-CB3E2B416AF8}) -> S_OK
2024-10-21 12:59:39,575 - comtypes._comobject - DEBUG - 1 active COM objects: Added   <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000229FB111280>
2024-10-21 12:59:39,575 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000229FB111280>.AddRef() -> 1
2024-10-21 12:59:39,577 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IConnectionPointContainer) ptr=0x229e3f8f6a8 at 229fb41c7d0>
2024-10-21 12:59:39,638 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectToken) ptr=0x229e3fd0f70 at 229fb41c7d0>)
2024-10-21 12:59:39,638 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x229e3fd0f70 at 229fb41c7d0>
2024-10-21 12:59:39,638 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x229fd0ce5d0 at 229fb41c7d0>)
2024-10-21 12:59:39,639 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x229fd0f7970 at 229fb41c8d0>
2024-10-21 12:59:39,639 - comtypes.client - DEBUG - wrap_outparam(<POINTER(IDispatch) ptr=0x229fd00ae50 at 229fb41cad0>)
2024-10-21 12:59:39,639 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IDispatch) ptr=0x229fd00ae50 at 229fb41cad0>)
2024-10-21 12:59:39,640 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo, trying IProvideClassInfo2
2024-10-21 12:59:39,641 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo/IProvideClassInfo2
2024-10-21 12:59:39,641 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x229f9cc5150 at 229fb41ccd0>
2024-10-21 12:59:39,643 - comtypes.client - DEBUG - Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}
2024-10-21 12:59:39,643 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x229fd00ae50 at 229fb41cdd0>
2024-10-21 12:59:39,643 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:59:39,643 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>
2024-10-21 12:59:39,643 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechObjectToken) ptr=0x229fd00ae50 at 229fb41ccd0>
2024-10-21 12:59:39,643 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x229fd00ae50 at 229fb41cc50>
2024-10-21 12:59:39,644 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x229f9cc5150 at 229fb41cd50>
2024-10-21 12:59:39,644 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x229f98df060 at 229fb41cdd0>
2024-10-21 12:59:39,644 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x229fd00ae50 at 229fb41cad0>
2024-10-21 12:59:39,644 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IEnumVARIANT) ptr=0x229fd0f7970 at 229fb41c950>
2024-10-21 12:59:39,645 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectTokens) ptr=0x229fd0ce5d0 at 229fb41c7d0>
2024-10-21 12:59:39,645 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x229fd00ae50 at 229fb41ccd0>
2024-10-21 12:59:39,646 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:59:39,650 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:59:39,872 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:59:39,873 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:59:40,230 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2024-10-21 12:59:40,859 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/Systran/faster-whisper-base/revision/main HTTP/1.1" 200 1848
2024-10-21 12:59:41,463 - __main__ - INFO - pro instance initialized
2024-10-21 13:00:01,867 - faster_whisper - INFO - Processing audio with duration 00:01.904
2024-10-21 13:00:02,533 - faster_whisper - INFO - Detected language 'ru' with probability 0.39
2024-10-21 13:00:02,534 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 13:00:02,683 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.0 (-1.269620 < -1.000000)
2024-10-21 13:00:03,050 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.2 (-1.269620 < -1.000000)
2024-10-21 13:00:03,423 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.4 (-1.558803 < -1.000000)
2024-10-21 13:00:03,749 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.6 (-1.875439 < -1.000000)
2024-10-21 13:00:04,453 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.8 (-2.014740 < -1.000000)
2024-10-21 13:00:04,790 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 1.0 (-4.250103 < -1.000000)
2024-10-21 13:00:04,791 - faster_whisper - DEBUG - Reset prompt. prompt_reset_on_temperature threshold is met 1.000000 > 0.500000
2024-10-21 13:00:25,073 - comtypes._post_coinit.unknwn - DEBUG - Calling CoUninitialize()
2024-10-21 13:00:25,073 - comtypes._post_coinit.unknwn - DEBUG - CoUninitialize() done.
2024-10-21 13:00:25,115 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000229FB111280>.Release() -> 0
2024-10-21 13:00:25,116 - comtypes._comobject - DEBUG - 0 active COM objects: Removed <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000229FB111280>
2024-10-21 13:00:25,116 - comtypes._comobject - DEBUG - Remaining: []
2024-10-21 13:00:39,280 - __main__ - INFO - Starting main.py
2024-10-21 13:00:39,281 - __main__ - INFO - Chat log file path: C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\chat_history\2024\10\21.log
2024-10-21 13:00:39,289 - __main__ - INFO - API keys loaded successfully
2024-10-21 13:00:39,359 - comtypes - DEBUG - CoInitializeEx(None, 2)
2024-10-21 13:00:39,538 - comtypes.client._code_cache - INFO - Imported existing <module 'comtypes.gen' from 'C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\comtypes\\gen\\__init__.py'>
2024-10-21 13:00:39,539 - comtypes.client._code_cache - INFO - Using writeable comtypes cache directory: 'C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\comtypes\gen'
2024-10-21 13:00:39,710 - comtypes.client - DEBUG - SAPI.SPVoice -> {96749377-3391-11D2-9EE3-00C04F797396}
2024-10-21 13:00:39,711 - comtypes.client - DEBUG - CoCreateInstance({96749377-3391-11D2-9EE3-00C04F797396}, clsctx=None, interface=None)
2024-10-21 13:00:39,723 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IUnknown) ptr=0x23d6eb8f640 at 23d81fc6fd0>)
2024-10-21 13:00:39,723 - comtypes.client - DEBUG - Does implement IProvideClassInfo
2024-10-21 13:00:39,725 - comtypes.client - DEBUG - Default interface is {269316D8-57BD-11D2-9EEE-00C04F797396}
2024-10-21 13:00:39,726 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x23d6eb8f680 at 23d81fc73d0>
2024-10-21 13:00:39,726 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 13:00:39,726 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechVoice'>
2024-10-21 13:00:39,727 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechVoice) ptr=0x23d6eb8f680 at 23d81fc7350>
2024-10-21 13:00:39,727 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo) ptr=0x23d6eb8f6a0 at 23d81fc6f50>
2024-10-21 13:00:39,727 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x23d8085c638 at 23d81fc7050>
2024-10-21 13:00:39,728 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x23d8085c690 at 23d81fc70d0>
2024-10-21 13:00:39,728 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x23d808dcdd0 at 23d81fc73d0>
2024-10-21 13:00:39,728 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x23d6eb8f640 at 23d81fc6fd0>
2024-10-21 13:00:39,729 - comtypes.client._events - DEBUG - <POINTER(ISpeechVoice) ptr=0x23d6eb8f680 at 23d81fc7350> using sinkinterface from clsid <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 13:00:39,729 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo2) ptr=0x23d6eb8f6a0 at 23d81fc6fd0>
2024-10-21 13:00:39,730 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000023D81D212B0>: _ISpeechVoiceEvents.VoiceChange not implemented
2024-10-21 13:00:39,730 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000023D81D212B0>: _ISpeechVoiceEvents.Bookmark not implemented
2024-10-21 13:00:39,730 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000023D81D212B0>: _ISpeechVoiceEvents.Sentence not implemented
2024-10-21 13:00:39,730 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000023D81D212B0>: _ISpeechVoiceEvents.Phoneme not implemented
2024-10-21 13:00:39,730 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000023D81D212B0>: _ISpeechVoiceEvents.Viseme not implemented
2024-10-21 13:00:39,731 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000023D81D212B0>: _ISpeechVoiceEvents.AudioLevel not implemented
2024-10-21 13:00:39,731 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000023D81D212B0>: _ISpeechVoiceEvents.EnginePrivate not implemented
2024-10-21 13:00:39,731 - comtypes.client._events - DEBUG - Start advise <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 13:00:39,731 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000023D81D212B0>.QueryInterface({A372ACD1-3BEF-4BBD-8FFB-CB3E2B416AF8}) -> S_OK
2024-10-21 13:00:39,731 - comtypes._comobject - DEBUG - 1 active COM objects: Added   <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000023D81D212B0>
2024-10-21 13:00:39,732 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x0000023D81D212B0>.AddRef() -> 1
2024-10-21 13:00:39,734 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IConnectionPointContainer) ptr=0x23d6eb8f6a8 at 23d8202c7d0>
2024-10-21 13:00:39,873 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectToken) ptr=0x23d6ebd0f70 at 23d8202c7d0>)
2024-10-21 13:00:39,873 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x23d6ebd0f70 at 23d8202c7d0>
2024-10-21 13:00:39,874 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x23d82cce650 at 23d8202c7d0>)
2024-10-21 13:00:39,875 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x23d82cf71f0 at 23d8202c8d0>
2024-10-21 13:00:39,875 - comtypes.client - DEBUG - wrap_outparam(<POINTER(IDispatch) ptr=0x23d82c0ad30 at 23d8202cad0>)
2024-10-21 13:00:39,875 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IDispatch) ptr=0x23d82c0ad30 at 23d8202cad0>)
2024-10-21 13:00:39,876 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo, trying IProvideClassInfo2
2024-10-21 13:00:39,877 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo/IProvideClassInfo2
2024-10-21 13:00:39,878 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x23d8085c740 at 23d8202ccd0>
2024-10-21 13:00:39,878 - comtypes.client - DEBUG - Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}
2024-10-21 13:00:39,878 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x23d82c0ad30 at 23d8202cdd0>
2024-10-21 13:00:39,879 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 13:00:39,879 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>
2024-10-21 13:00:39,879 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechObjectToken) ptr=0x23d82c0ad30 at 23d8202ccd0>
2024-10-21 13:00:39,880 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x23d82c0ad30 at 23d8202cc50>
2024-10-21 13:00:39,880 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x23d8085c740 at 23d8202cd50>
2024-10-21 13:00:39,880 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x23d808dcdd0 at 23d8202cdd0>
2024-10-21 13:00:39,881 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x23d82c0ad30 at 23d8202cad0>
2024-10-21 13:00:39,881 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IEnumVARIANT) ptr=0x23d82cf71f0 at 23d8202c950>
2024-10-21 13:00:39,882 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectTokens) ptr=0x23d82cce650 at 23d8202c7d0>
2024-10-21 13:00:39,882 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x23d82c0ad30 at 23d8202ccd0>
2024-10-21 13:00:39,882 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 13:00:39,885 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 13:00:40,181 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 13:00:40,182 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 13:00:41,341 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2024-10-21 13:00:42,021 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/Systran/faster-whisper-base/revision/main HTTP/1.1" 200 1848
2024-10-21 13:00:43,024 - __main__ - INFO - pro instance initialized
2024-10-21 13:00:56,933 - faster_whisper - INFO - Processing audio with duration 00:01.649
2024-10-21 13:00:57,566 - faster_whisper - INFO - Detected language 'en' with probability 0.40
2024-10-21 13:00:57,567 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 13:00:57,706 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 13:00:57,799 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 13:00:57,799 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 13:00:57,905 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023D851E9CD0>
2024-10-21 13:00:57,906 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023D8202C9D0> server_hostname='api.groq.com' timeout=5.0
2024-10-21 13:00:58,050 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023D851078C0>
2024-10-21 13:00:58,051 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 13:00:58,051 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 13:00:58,051 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 13:00:58,052 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 13:00:58,052 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 13:00:58,543 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 10:00:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19881'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'357ms'), (b'x-request-id', b'req_01jaq8bmqjeh79eaa68mmswdez'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=FMUAJnop8rHLTnxg6ynbLtXaSdrtEEtezjUjvozqCgE-1729504859-1.0.1.1-RKEKwsixFkKoRMCbYrVzBLHPvlaOR4XGph5MzSd5Tol2ZeDm2162DX28ExzN0mHLFeajYygwK8UzOVC9d1cyVw; path=/; expires=Mon, 21-Oct-24 10:30:59 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d606756ed037404-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 13:00:58,546 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 13:00:58,546 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 13:00:58,547 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 13:00:58,547 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 13:00:58,547 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 13:00:58,548 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 10:00:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19881', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '357ms', 'x-request-id': 'req_01jaq8bmqjeh79eaa68mmswdez', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=FMUAJnop8rHLTnxg6ynbLtXaSdrtEEtezjUjvozqCgE-1729504859-1.0.1.1-RKEKwsixFkKoRMCbYrVzBLHPvlaOR4XGph5MzSd5Tol2ZeDm2162DX28ExzN0mHLFeajYygwK8UzOVC9d1cyVw; path=/; expires=Mon, 21-Oct-24 10:30:59 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8d606756ed037404-JNB', 'content-encoding': 'gzip'})
2024-10-21 13:00:58,553 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 13:00:58,554 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 13:00:58,555 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 13:00:58,555 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 13:00:58,556 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 13:00:58,556 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 13:00:58,557 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 13:00:59,152 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 10:00:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19827'), (b'x-ratelimit-reset-requests', b'11.484s'), (b'x-ratelimit-reset-tokens', b'519ms'), (b'x-request-id', b'req_01jaq8bn7pfy2vaab5hbn1tg8n'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60675a19bb7404-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 13:00:59,154 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 13:00:59,154 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 13:00:59,155 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 13:00:59,155 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 13:00:59,156 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 13:00:59,156 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 10:00:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19827', 'x-ratelimit-reset-requests': '11.484s', 'x-ratelimit-reset-tokens': '519ms', 'x-request-id': 'req_01jaq8bn7pfy2vaab5hbn1tg8n', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60675a19bb7404-JNB', 'content-encoding': 'gzip'})
2024-10-21 13:00:59,158 - gtts.tts - DEBUG - text: Functioning as a multi-modal AI voice assistant, I can process and respond to both voice and visual inputs I was provided previous context in the form of a user's voice input though what it actually is is more complex as it can originate from either self-contained text prompts or image to text generated information.
2024-10-21 13:00:59,158 - gtts.tts - DEBUG - tld: com
2024-10-21 13:00:59,158 - gtts.tts - DEBUG - lang: en
2024-10-21 13:00:59,159 - gtts.tts - DEBUG - slow: False
2024-10-21 13:00:59,159 - gtts.tts - DEBUG - lang_check: True
2024-10-21 13:00:59,159 - gtts.tts - DEBUG - pre_processor_funcs: [<function tone_marks at 0x0000023D8076C7C0>, <function end_of_line at 0x0000023D8076C860>, <function abbreviations at 0x0000023D8076C900>, <function word_sub at 0x0000023D8076D1C0>]
2024-10-21 13:00:59,178 - gtts.tts - DEBUG - timeout: None
2024-10-21 13:00:59,178 - gtts.lang - DEBUG - langs: {'af': 'Afrikaans', 'am': 'Amharic', 'ar': 'Arabic', 'bg': 'Bulgarian', 'bn': 'Bengali', 'bs': 'Bosnian', 'ca': 'Catalan', 'cs': 'Czech', 'cy': 'Welsh', 'da': 'Danish', 'de': 'German', 'el': 'Greek', 'en': 'English', 'es': 'Spanish', 'et': 'Estonian', 'eu': 'Basque', 'fi': 'Finnish', 'fr': 'French', 'gl': 'Galician', 'gu': 'Gujarati', 'ha': 'Hausa', 'hi': 'Hindi', 'hr': 'Croatian', 'hu': 'Hungarian', 'id': 'Indonesian', 'is': 'Icelandic', 'it': 'Italian', 'iw': 'Hebrew', 'ja': 'Japanese', 'jw': 'Javanese', 'km': 'Khmer', 'kn': 'Kannada', 'ko': 'Korean', 'la': 'Latin', 'lt': 'Lithuanian', 'lv': 'Latvian', 'ml': 'Malayalam', 'mr': 'Marathi', 'ms': 'Malay', 'my': 'Myanmar (Burmese)', 'ne': 'Nepali', 'nl': 'Dutch', 'no': 'Norwegian', 'pa': 'Punjabi (Gurmukhi)', 'pl': 'Polish', 'pt': 'Portuguese (Brazil)', 'pt-PT': 'Portuguese (Portugal)', 'ro': 'Romanian', 'ru': 'Russian', 'si': 'Sinhala', 'sk': 'Slovak', 'sq': 'Albanian', 'sr': 'Serbian', 'su': 'Sundanese', 'sv': 'Swedish', 'sw': 'Swahili', 'ta': 'Tamil', 'te': 'Telugu', 'th': 'Thai', 'tl': 'Filipino', 'tr': 'Turkish', 'uk': 'Ukrainian', 'ur': 'Urdu', 'vi': 'Vietnamese', 'yue': 'Cantonese', 'zh-CN': 'Chinese (Simplified)', 'zh-TW': 'Chinese (Mandarin/Taiwan)', 'zh': 'Chinese (Mandarin)'}
2024-10-21 13:00:59,179 - gtts.tts - DEBUG - pre-processing: <function tone_marks at 0x0000023D8076C7C0>
2024-10-21 13:00:59,179 - gtts.tts - DEBUG - pre-processing: <function end_of_line at 0x0000023D8076C860>
2024-10-21 13:00:59,180 - gtts.tts - DEBUG - pre-processing: <function abbreviations at 0x0000023D8076C900>
2024-10-21 13:00:59,180 - gtts.tts - DEBUG - pre-processing: <function word_sub at 0x0000023D8076D1C0>
2024-10-21 13:00:59,183 - gtts.tts - DEBUG - text_parts: ['Functioning as a multi-modal AI voice assistant', 'I can process and respond to both voice and visual inputs I was provided previous context in the', "form of a user's voice input though what it actually is is more complex as it can originate from", 'either self-contained text prompts or image to text generated information.']
2024-10-21 13:00:59,183 - gtts.tts - DEBUG - text_parts: 4
2024-10-21 13:00:59,184 - gtts.tts - DEBUG - data-0: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22Functioning%20as%20a%20multi-modal%20AI%20voice%20assistant%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 13:00:59,184 - gtts.tts - DEBUG - data-1: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22I%20can%20process%20and%20respond%20to%20both%20voice%20and%20visual%20inputs%20I%20was%20provided%20previous%20context%20in%20the%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 13:00:59,184 - gtts.tts - DEBUG - data-2: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22form%20of%20a%20user%27s%20voice%20input%20though%20what%20it%20actually%20is%20is%20more%20complex%20as%20it%20can%20originate%20from%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 13:00:59,185 - gtts.tts - DEBUG - data-3: f.req=%5B%5B%5B%22jQ1olc%22%2C%22%5B%5C%22either%20self-contained%20text%20prompts%20or%20image%20to%20text%20generated%20information.%5C%22%2C%5C%22en%5C%22%2Cnull%2C%5C%22null%5C%22%5D%22%2Cnull%2C%22generic%22%5D%5D%5D&
2024-10-21 13:00:59,185 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 13:01:00,141 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 13:01:00,426 - gtts.tts - DEBUG - headers-0: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '189'}
2024-10-21 13:01:00,427 - gtts.tts - DEBUG - url-0: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 13:01:00,427 - gtts.tts - DEBUG - status-0: 200
2024-10-21 13:01:00,428 - gtts.tts - DEBUG - part-0 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 13:01:00,429 - gtts.tts - DEBUG - part-0 created
2024-10-21 13:01:00,430 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 13:01:01,411 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 13:01:01,780 - gtts.tts - DEBUG - headers-1: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '260'}
2024-10-21 13:01:01,781 - gtts.tts - DEBUG - url-1: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 13:01:01,781 - gtts.tts - DEBUG - status-1: 200
2024-10-21 13:01:01,784 - gtts.tts - DEBUG - part-1 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 13:01:01,784 - gtts.tts - DEBUG - part-1 created
2024-10-21 13:01:01,785 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 13:01:02,665 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 13:01:03,031 - gtts.tts - DEBUG - headers-2: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '264'}
2024-10-21 13:01:03,032 - gtts.tts - DEBUG - url-2: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 13:01:03,032 - gtts.tts - DEBUG - status-2: 200
2024-10-21 13:01:03,034 - gtts.tts - DEBUG - part-2 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 13:01:03,035 - gtts.tts - DEBUG - part-2 created
2024-10-21 13:01:03,036 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): translate.google.com:443
2024-10-21 13:01:03,969 - urllib3.connectionpool - DEBUG - https://translate.google.com:443 "POST /_/TranslateWebserverUi/data/batchexecute HTTP/1.1" 200 None
2024-10-21 13:01:04,411 - gtts.tts - DEBUG - headers-3: {'Referer': 'http://translate.google.com/', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Content-Length': '222'}
2024-10-21 13:01:04,412 - gtts.tts - DEBUG - url-3: https://translate.google.com/_/TranslateWebserverUi/data/batchexecute
2024-10-21 13:01:04,412 - gtts.tts - DEBUG - status-3: 200
2024-10-21 13:01:04,414 - gtts.tts - DEBUG - part-3 written to <_io.BufferedWriter name='C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3'>
2024-10-21 13:01:04,414 - gtts.tts - DEBUG - part-3 created
2024-10-21 13:01:04,415 - gtts.tts - DEBUG - Saved to C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\ai_response\ai_response_audio.mp3
2024-10-21 13:01:04,745 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-f', 'mp3', '-i', 'C:\\Users\\Lance\\Desktop\\CODEWRLD\\ai-personal-assistant\\data\\ai_response\\ai_response_audio.mp3', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
2024-10-21 13:01:32,282 - comtypes._post_coinit.unknwn - DEBUG - Calling CoUninitialize()
2024-10-21 13:01:32,283 - comtypes._post_coinit.unknwn - DEBUG - CoUninitialize() done.
