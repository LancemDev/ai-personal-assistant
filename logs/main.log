2024-10-21 11:57:31,012 - __main__ - INFO - Starting main.py
2024-10-21 11:57:31,012 - __main__ - INFO - Chat log file path: C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\chat_history\2024\10\21.log
2024-10-21 11:57:31,012 - __main__ - INFO - API keys loaded successfully
2024-10-21 11:57:31,032 - comtypes - DEBUG - CoInitializeEx(None, 2)
2024-10-21 11:57:31,044 - comtypes.client._code_cache - INFO - Imported existing <module 'comtypes.gen' from 'C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\comtypes\\gen\\__init__.py'>
2024-10-21 11:57:31,044 - comtypes.client._code_cache - INFO - Using writeable comtypes cache directory: 'C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\comtypes\gen'
2024-10-21 11:57:31,092 - comtypes.client - DEBUG - SAPI.SPVoice -> {96749377-3391-11D2-9EE3-00C04F797396}
2024-10-21 11:57:31,092 - comtypes.client - DEBUG - CoCreateInstance({96749377-3391-11D2-9EE3-00C04F797396}, clsctx=None, interface=None)
2024-10-21 11:57:31,092 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IUnknown) ptr=0x1b7b771ba20 at 1b7caec6ed0>)
2024-10-21 11:57:31,092 - comtypes.client - DEBUG - Does implement IProvideClassInfo
2024-10-21 11:57:31,107 - comtypes.client - DEBUG - Default interface is {269316D8-57BD-11D2-9EEE-00C04F797396}
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1b7b771ba60 at 1b7caec72d0>
2024-10-21 11:57:31,107 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 11:57:31,107 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechVoice'>
2024-10-21 11:57:31,107 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechVoice) ptr=0x1b7b771ba60 at 1b7caec7250>
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo) ptr=0x1b7b771ba80 at 1b7caec6e50>
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x1b7c92b4ba8 at 1b7caec6f50>
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x1b7c92b4c00 at 1b7caec6fd0>
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x1b7c8ffa2f0 at 1b7caec72d0>
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1b7b771ba20 at 1b7caec6ed0>
2024-10-21 11:57:31,107 - comtypes.client._events - DEBUG - <POINTER(ISpeechVoice) ptr=0x1b7b771ba60 at 1b7caec7250> using sinkinterface from clsid <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo2) ptr=0x1b7b771ba80 at 1b7caec6ed0>
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>: _ISpeechVoiceEvents.VoiceChange not implemented
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>: _ISpeechVoiceEvents.Bookmark not implemented
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>: _ISpeechVoiceEvents.Sentence not implemented
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>: _ISpeechVoiceEvents.Phoneme not implemented
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>: _ISpeechVoiceEvents.Viseme not implemented
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>: _ISpeechVoiceEvents.AudioLevel not implemented
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>: _ISpeechVoiceEvents.EnginePrivate not implemented
2024-10-21 11:57:31,107 - comtypes.client._events - DEBUG - Start advise <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>.QueryInterface({A372ACD1-3BEF-4BBD-8FFB-CB3E2B416AF8}) -> S_OK
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - 1 active COM objects: Added   <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>
2024-10-21 11:57:31,107 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001B7CAC21130>.AddRef() -> 1
2024-10-21 11:57:31,107 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IConnectionPointContainer) ptr=0x1b7b771ba88 at 1b7caf2c6d0>
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectToken) ptr=0x1b7b77f2b80 at 1b7caf2c6d0>)
2024-10-21 11:57:31,155 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x1b7b77f2b80 at 1b7caf2c6d0>
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x1b7cbc0a850 at 1b7caf2c6d0>)
2024-10-21 11:57:31,155 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1b7cbdb1420 at 1b7caf2c7d0>
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - wrap_outparam(<POINTER(IDispatch) ptr=0x1b7cbd64710 at 1b7caf2c9d0>)
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IDispatch) ptr=0x1b7cbd64710 at 1b7caf2c9d0>)
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo, trying IProvideClassInfo2
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo/IProvideClassInfo2
2024-10-21 11:57:31,155 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1b7c92b4cb0 at 1b7caf2cbd0>
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}
2024-10-21 11:57:31,155 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1b7cbd64710 at 1b7caf2ccd0>
2024-10-21 11:57:31,155 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>
2024-10-21 11:57:31,155 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechObjectToken) ptr=0x1b7cbd64710 at 1b7caf2cbd0>
2024-10-21 11:57:31,171 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x1b7cbd64710 at 1b7caf2cb50>
2024-10-21 11:57:31,171 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x1b7c92b4cb0 at 1b7caf2cc50>
2024-10-21 11:57:31,171 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x1b7c8ffa2f0 at 1b7caf2ccd0>
2024-10-21 11:57:31,171 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x1b7cbd64710 at 1b7caf2c9d0>
2024-10-21 11:57:31,171 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IEnumVARIANT) ptr=0x1b7cbdb1420 at 1b7caf2c850>
2024-10-21 11:57:31,171 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectTokens) ptr=0x1b7cbc0a850 at 1b7caf2c6d0>
2024-10-21 11:57:31,171 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x1b7cbd64710 at 1b7caf2cbd0>
2024-10-21 11:57:31,171 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 11:57:31,171 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 11:57:31,392 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 11:57:31,392 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 11:57:31,784 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2024-10-21 11:57:32,654 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/Systran/faster-whisper-base/revision/main HTTP/1.1" 200 1848
2024-10-21 11:57:33,239 - __main__ - INFO - Siri instance initialized
2024-10-21 11:57:43,828 - faster_whisper - INFO - Processing audio with duration 00:07.012
2024-10-21 11:57:44,529 - faster_whisper - INFO - Detected language 'es' with probability 0.40
2024-10-21 11:57:44,529 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:57:48,491 - faster_whisper - INFO - Processing audio with duration 00:02.020
2024-10-21 11:57:49,140 - faster_whisper - INFO - Detected language 'en' with probability 0.43
2024-10-21 11:57:49,140 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:58:04,371 - faster_whisper - INFO - Processing audio with duration 00:10.449
2024-10-21 11:58:05,035 - faster_whisper - INFO - Detected language 'en' with probability 0.43
2024-10-21 11:58:05,035 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:58:05,129 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.0 (-1.006838 < -1.000000)
2024-10-21 11:58:08,107 - faster_whisper - INFO - Processing audio with duration 00:01.486
2024-10-21 11:58:08,827 - faster_whisper - INFO - Detected language 'en' with probability 0.47
2024-10-21 11:58:08,827 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:58:18,851 - faster_whisper - INFO - Processing audio with duration 00:01.532
2024-10-21 11:58:19,645 - faster_whisper - INFO - Detected language 'en' with probability 0.39
2024-10-21 11:58:19,646 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:58:36,300 - faster_whisper - INFO - Processing audio with duration 00:15.186
2024-10-21 11:58:37,172 - faster_whisper - INFO - Detected language 'en' with probability 0.90
2024-10-21 11:58:37,172 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:58:57,414 - faster_whisper - INFO - Processing audio with duration 00:18.135
2024-10-21 11:58:58,078 - faster_whisper - INFO - Detected language 'en' with probability 0.36
2024-10-21 11:58:58,078 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:58:58,235 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'hello. Hello, Siri.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 11:58:58,329 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 11:58:58,329 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 11:58:58,464 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CE0EB590>
2024-10-21 11:58:58,464 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B7CAF2C8D0> server_hostname='api.groq.com' timeout=5.0
2024-10-21 11:58:58,578 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CE0EAF30>
2024-10-21 11:58:58,578 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 11:58:58,578 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 11:58:58,578 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 11:58:58,578 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 11:58:58,578 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 11:58:59,098 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 08:58:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19877'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'369ms'), (b'x-request-id', b'req_01jaq4t4dwf6ntxprjqej0sgr6'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=a8Nf1MCnumdQuxItbUgZ6sNHAxEyJHaT6FAT3gfgQK0-1729501139-1.0.1.1-iWwtbcXXIIM4MLlQQGingf0pF6RYJsu5ATHP6dSFmnVGuE5F5fl2CQOoVy7SEBy5RoNFwUTVUzi15WZC_oIWYQ; path=/; expires=Mon, 21-Oct-24 09:28:59 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d600c882c990566-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 11:58:59,113 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 11:58:59,114 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 08:58:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19877', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '369ms', 'x-request-id': 'req_01jaq4t4dwf6ntxprjqej0sgr6', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=a8Nf1MCnumdQuxItbUgZ6sNHAxEyJHaT6FAT3gfgQK0-1729501139-1.0.1.1-iWwtbcXXIIM4MLlQQGingf0pF6RYJsu5ATHP6dSFmnVGuE5F5fl2CQOoVy7SEBy5RoNFwUTVUzi15WZC_oIWYQ; path=/; expires=Mon, 21-Oct-24 09:28:59 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8d600c882c990566-JNB', 'content-encoding': 'gzip'})
2024-10-21 11:58:59,114 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'hello. Hello, Siri.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 11:58:59,114 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 11:58:59,114 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 11:58:59,830 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 08:59:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19823'), (b'x-ratelimit-reset-requests', b'11.351999999s'), (b'x-ratelimit-reset-tokens', b'531ms'), (b'x-request-id', b'req_01jaq4t522e7rtt42rh33m47jy'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d600c8c396d0566-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 11:58:59,830 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 11:58:59,830 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 11:58:59,830 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 11:58:59,830 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 11:58:59,830 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 11:58:59,830 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 08:59:00 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19823', 'x-ratelimit-reset-requests': '11.351999999s', 'x-ratelimit-reset-tokens': '531ms', 'x-request-id': 'req_01jaq4t522e7rtt42rh33m47jy', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d600c8c396d0566-JNB', 'content-encoding': 'gzip'})
2024-10-21 11:59:00,107 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I'm not Siri, I'm a multi-modal AI voice assistant. This is the beginning of our conversation, and I'm not seeing any context or additional information attached. Please feel free to share any questions, topics, or photos you'd like to discuss.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 11:59:00,107 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 11:59:00,107 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 11:59:00,288 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CFD29FA0>
2024-10-21 11:59:00,288 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B7CAF2D150> server_hostname='api.openai.com' timeout=5.0
2024-10-21 11:59:00,430 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CFD29E80>
2024-10-21 11:59:00,430 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 11:59:00,430 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 11:59:00,430 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 11:59:00,430 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 11:59:00,430 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 11:59:02,955 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 08:59:03 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1176'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_ac496087664a55a99dcf24ea3c59a227'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=s.R2B8sW99AdBjmGSAccB0sskkqZTGs69aM0zByWwAM-1729501143-1.0.1.1-Zaf26vFgtIkZkxwTncp..uicoJkFwCaGMjXHpHRv1v8HPcOSafWnBRKD5U178dLwpp7UaVnC8u2rxHufEL6akQ; path=/; expires=Mon, 21-Oct-24 09:29:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=xMM10zBBCXHMYhtPqK.Oif7xxRvFiOQbTjS7IC210RM-1729501143472-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d600c942bef73e2-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 11:59:02,955 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 11:59:02,955 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers([('date', 'Mon, 21 Oct 2024 08:59:03 GMT'), ('content-type', 'audio/pcm'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'viva-ai-g59lkf'), ('openai-processing-ms', '1176'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-reset-requests', '120ms'), ('x-request-id', 'req_ac496087664a55a99dcf24ea3c59a227'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=s.R2B8sW99AdBjmGSAccB0sskkqZTGs69aM0zByWwAM-1729501143-1.0.1.1-Zaf26vFgtIkZkxwTncp..uicoJkFwCaGMjXHpHRv1v8HPcOSafWnBRKD5U178dLwpp7UaVnC8u2rxHufEL6akQ; path=/; expires=Mon, 21-Oct-24 09:29:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=xMM10zBBCXHMYhtPqK.Oif7xxRvFiOQbTjS7IC210RM-1729501143472-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8d600c942bef73e2-JNB'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-10-21 11:59:02,955 - openai._base_client - DEBUG - request_id: req_ac496087664a55a99dcf24ea3c59a227
2024-10-21 11:59:02,955 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 11:59:17,548 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 11:59:17,548 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 11:59:17,548 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 11:59:49,986 - faster_whisper - INFO - Processing audio with duration 00:31.974
2024-10-21 11:59:50,694 - faster_whisper - INFO - Detected language 'en' with probability 0.78
2024-10-21 11:59:50,694 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 11:59:50,945 - faster_whisper - DEBUG - Processing segment at 00:20.000
2024-10-21 12:00:11,099 - faster_whisper - INFO - Processing audio with duration 00:17.810
2024-10-21 12:00:12,071 - faster_whisper - INFO - Detected language 'en' with probability 0.89
2024-10-21 12:00:12,072 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:00:14,106 - faster_whisper - INFO - Processing audio with duration 00:01.440
2024-10-21 12:00:15,025 - faster_whisper - INFO - Detected language 'en' with probability 0.42
2024-10-21 12:00:15,025 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:00:21,798 - faster_whisper - INFO - Processing audio with duration 00:01.370
2024-10-21 12:00:22,624 - faster_whisper - INFO - Detected language 'en' with probability 0.39
2024-10-21 12:00:22,624 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:00:23,946 - faster_whisper - INFO - Processing audio with duration 00:00.859
2024-10-21 12:00:24,796 - faster_whisper - INFO - Detected language 'en' with probability 0.46
2024-10-21 12:00:24,796 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:00:26,966 - faster_whisper - INFO - Processing audio with duration 00:01.765
2024-10-21 12:00:27,707 - faster_whisper - INFO - Detected language 'en' with probability 0.46
2024-10-21 12:00:27,707 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:00:31,191 - faster_whisper - INFO - Processing audio with duration 00:01.347
2024-10-21 12:00:31,931 - faster_whisper - INFO - Detected language 'en' with probability 0.37
2024-10-21 12:00:31,931 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:00:41,663 - faster_whisper - INFO - Processing audio with duration 00:02.624
2024-10-21 12:00:42,346 - faster_whisper - INFO - Detected language 'en' with probability 0.34
2024-10-21 12:00:42,346 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:01:00,514 - faster_whisper - INFO - Processing audio with duration 00:02.972
2024-10-21 12:01:01,512 - faster_whisper - INFO - Detected language 'en' with probability 0.39
2024-10-21 12:01:01,513 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:01:37,825 - faster_whisper - INFO - Processing audio with duration 00:25.496
2024-10-21 12:01:38,836 - faster_whisper - INFO - Detected language 'en' with probability 0.47
2024-10-21 12:01:38,838 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:01:39,177 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'who is the president of the US? Hello Siri, who is the first US president?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:01:39,178 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:01:39,179 - httpcore.connection - DEBUG - close.started
2024-10-21 12:01:39,179 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:01:39,180 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:01:39,283 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CE0E97C0>
2024-10-21 12:01:39,284 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B7CAF2C8D0> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:01:39,418 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CE0EAFF0>
2024-10-21 12:01:39,418 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:01:39,419 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:01:39,420 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:01:39,420 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:01:39,421 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:01:39,916 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:01:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19863'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'411ms'), (b'x-request-id', b'req_01jaq4z1fpfznvn9766rn6kqm2'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6010755a6c4eb7-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:01:39,917 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:01:39,917 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:01:39,918 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:01:39,918 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:01:39,918 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:01:39,919 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:01:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19863', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '411ms', 'x-request-id': 'req_01jaq4z1fpfznvn9766rn6kqm2', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6010755a6c4eb7-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:01:39,923 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'hello. Hello, Siri.'}, {'role': 'assistant', 'content': "I'm not Siri, I'm a multi-modal AI voice assistant. This is the beginning of our conversation, and I'm not seeing any context or additional information attached. Please feel free to share any questions, topics, or photos you'd like to discuss."}, {'role': 'user', 'content': 'who is the president of the US? Hello Siri, who is the first US president?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:01:39,924 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:01:39,925 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:01:39,925 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:01:39,925 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:01:39,926 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:01:39,926 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:01:40,515 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:01:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19735'), (b'x-ratelimit-reset-requests', b'11.483s'), (b'x-ratelimit-reset-tokens', b'795ms'), (b'x-request-id', b'req_01jaq4z1zxepnrhnehpggb8q2b'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6010789de94eb7-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:01:40,516 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:01:40,516 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:01:40,517 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:01:40,517 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:01:40,517 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:01:40,518 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:01:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19735', 'x-ratelimit-reset-requests': '11.483s', 'x-ratelimit-reset-tokens': '795ms', 'x-request-id': 'req_01jaq4z1zxepnrhnehpggb8q2b', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6010789de94eb7-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:01:40,777 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I'm not Siri, I'm a different AI voice assistant. Our conversation continues - currently, the President of the United States is Joe Biden. The first US president and the first commander-in-chief of the US military is George Washington, who served from 1789 to 1797.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:01:40,779 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:01:40,779 - httpcore.connection - DEBUG - close.started
2024-10-21 12:01:40,780 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:01:40,780 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:01:40,883 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CFD2BFB0>
2024-10-21 12:01:40,883 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B7CAF2D150> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:01:41,240 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CFD2B890>
2024-10-21 12:01:41,242 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:01:41,243 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:01:41,245 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:01:41,247 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:01:41,248 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:01:43,616 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:01:44 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1230'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_0019c5559e9eaacea61071af786e6c69'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60108109bb73b5-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:01:43,616 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:01:43,617 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:01:44 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1230', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_0019c5559e9eaacea61071af786e6c69', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d60108109bb73b5-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:01:43,618 - openai._base_client - DEBUG - request_id: req_0019c5559e9eaacea61071af786e6c69
2024-10-21 12:01:43,618 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:02:01,608 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:02:01,608 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:02:01,609 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:02:42,254 - faster_whisper - INFO - Processing audio with duration 00:35.085
2024-10-21 12:07:03,550 - faster_whisper - INFO - Detected language 'en' with probability 0.57
2024-10-21 12:07:03,550 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:07:03,785 - faster_whisper - DEBUG - Processing segment at 00:19.600
2024-10-21 12:07:23,032 - faster_whisper - INFO - Processing audio with duration 00:13.630
2024-10-21 12:07:23,697 - faster_whisper - INFO - Detected language 'en' with probability 0.70
2024-10-21 12:07:23,697 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:07:23,949 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': "and if you're not Siri, who are you?"}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:07:23,949 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:07:23,949 - httpcore.connection - DEBUG - close.started
2024-10-21 12:07:23,949 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:07:23,949 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:07:24,064 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CFD2A8A0>
2024-10-21 12:07:24,064 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B7CAF2C8D0> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:07:24,202 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CFD2A1B0>
2024-10-21 12:07:24,202 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:07:24,203 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:07:24,203 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:07:24,204 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:07:24,204 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:07:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19872'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'384ms'), (b'x-request-id', b'req_01jaq59jche6caq4nnt1c8b7eq'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6018e038970519-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:07:24,887 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:07:24,887 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:07:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19872', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '384ms', 'x-request-id': 'req_01jaq59jche6caq4nnt1c8b7eq', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6018e038970519-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:07:24,887 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'hello. Hello, Siri.'}, {'role': 'assistant', 'content': "I'm not Siri, I'm a multi-modal AI voice assistant. This is the beginning of our conversation, and I'm not seeing any context or additional information attached. Please feel free to share any questions, topics, or photos you'd like to discuss."}, {'role': 'user', 'content': 'who is the president of the US? Hello Siri, who is the first US president?'}, {'role': 'assistant', 'content': "I'm not Siri, I'm a different AI voice assistant. Our conversation continues - currently, the President of the United States is Joe Biden. The first US president and the first commander-in-chief of the US military is George Washington, who served from 1789 to 1797."}, {'role': 'user', 'content': "and if you're not Siri, who are you?"}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:07:24,887 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:07:24,887 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:07:25,516 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:07:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19650'), (b'x-ratelimit-reset-requests', b'11.47s'), (b'x-ratelimit-reset-tokens', b'1.05s'), (b'x-request-id', b'req_01jaq59jx3e72vy08r4d8s1n34'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6018e4dc7c0519-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:07:25,516 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:07:25,516 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:07:25,516 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:07:25,516 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:07:25,516 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:07:25,516 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:07:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19650', 'x-ratelimit-reset-requests': '11.47s', 'x-ratelimit-reset-tokens': '1.05s', 'x-request-id': 'req_01jaq59jx3e72vy08r4d8s1n34', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6018e4dc7c0519-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:07:25,802 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I'm an AI assistant that can process and respond to various inputs, including text prompts, audio questions, and visual data attached to our conversation. Since I can integrate with user-media and engage with context, I'm often referred to as a multi-modal AI voice assistant.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:07:25,802 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:07:25,802 - httpcore.connection - DEBUG - close.started
2024-10-21 12:07:25,802 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:07:25,802 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:07:25,936 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CE0E9910>
2024-10-21 12:07:25,936 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B7CAF2D150> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:07:26,072 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B7CFD2B470>
2024-10-21 12:07:26,072 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:07:26,072 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:07:26,072 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:07:26,072 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:07:26,072 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:07:27,927 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:07:28 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1151'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_db323bbb8c3296a019cc60550aa8e379'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6018ebe89473fc-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:07:27,927 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:07:27,927 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:07:28 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1151', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_db323bbb8c3296a019cc60550aa8e379', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6018ebe89473fc-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:07:27,927 - openai._base_client - DEBUG - request_id: req_db323bbb8c3296a019cc60550aa8e379
2024-10-21 12:07:27,927 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:07:45,169 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:07:56,770 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:07:56,770 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:08:18,018 - faster_whisper - INFO - Processing audio with duration 00:18.228
2024-10-21 12:08:18,683 - faster_whisper - INFO - Detected language 'en' with probability 0.41
2024-10-21 12:08:30,035 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:08:33,259 - faster_whisper - INFO - Processing audio with duration 00:01.324
2024-10-21 12:08:33,873 - faster_whisper - INFO - Detected language 'en' with probability 0.40
2024-10-21 12:08:33,873 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:08:41,737 - comtypes._post_coinit.unknwn - DEBUG - Calling CoUninitialize()
2024-10-21 12:08:41,737 - comtypes._post_coinit.unknwn - DEBUG - CoUninitialize() done.
2024-10-21 12:10:00,380 - __main__ - INFO - Starting main.py
2024-10-21 12:10:00,380 - __main__ - INFO - Chat log file path: C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\chat_history\2024\10\21.log
2024-10-21 12:10:00,380 - __main__ - INFO - API keys loaded successfully
2024-10-21 12:10:00,380 - comtypes - DEBUG - CoInitializeEx(None, 2)
2024-10-21 12:10:00,412 - comtypes.client._code_cache - INFO - Imported existing <module 'comtypes.gen' from 'C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\comtypes\\gen\\__init__.py'>
2024-10-21 12:10:00,412 - comtypes.client._code_cache - INFO - Using writeable comtypes cache directory: 'C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\comtypes\gen'
2024-10-21 12:10:00,459 - comtypes.client - DEBUG - SAPI.SPVoice -> {96749377-3391-11D2-9EE3-00C04F797396}
2024-10-21 12:10:00,459 - comtypes.client - DEBUG - CoCreateInstance({96749377-3391-11D2-9EE3-00C04F797396}, clsctx=None, interface=None)
2024-10-21 12:10:00,465 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IUnknown) ptr=0x1f63ad1ba20 at 1f64e4b6f50>)
2024-10-21 12:10:00,465 - comtypes.client - DEBUG - Does implement IProvideClassInfo
2024-10-21 12:10:00,465 - comtypes.client - DEBUG - Default interface is {269316D8-57BD-11D2-9EEE-00C04F797396}
2024-10-21 12:10:00,465 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1f63ad1ba60 at 1f64e4b7350>
2024-10-21 12:10:00,465 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:10:00,465 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechVoice'>
2024-10-21 12:10:00,465 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechVoice) ptr=0x1f63ad1ba60 at 1f64e4b72d0>
2024-10-21 12:10:00,465 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo) ptr=0x1f63ad1ba80 at 1f64e4b6ed0>
2024-10-21 12:10:00,465 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x1f64c8e2048 at 1f64e4b6fd0>
2024-10-21 12:10:00,465 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x1f64c8e20a0 at 1f64e4b7050>
2024-10-21 12:10:00,465 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x1f64c50eb00 at 1f64e4b7350>
2024-10-21 12:10:00,465 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1f63ad1ba20 at 1f64e4b6f50>
2024-10-21 12:10:00,465 - comtypes.client._events - DEBUG - <POINTER(ISpeechVoice) ptr=0x1f63ad1ba60 at 1f64e4b72d0> using sinkinterface from clsid <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:10:00,465 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo2) ptr=0x1f63ad1ba80 at 1f64e4b6f50>
2024-10-21 12:10:00,465 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>: _ISpeechVoiceEvents.VoiceChange not implemented
2024-10-21 12:10:00,465 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>: _ISpeechVoiceEvents.Bookmark not implemented
2024-10-21 12:10:00,465 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>: _ISpeechVoiceEvents.Sentence not implemented
2024-10-21 12:10:00,475 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>: _ISpeechVoiceEvents.Phoneme not implemented
2024-10-21 12:10:00,475 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>: _ISpeechVoiceEvents.Viseme not implemented
2024-10-21 12:10:00,475 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>: _ISpeechVoiceEvents.AudioLevel not implemented
2024-10-21 12:10:00,475 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>: _ISpeechVoiceEvents.EnginePrivate not implemented
2024-10-21 12:10:00,475 - comtypes.client._events - DEBUG - Start advise <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:10:00,475 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>.QueryInterface({A372ACD1-3BEF-4BBD-8FFB-CB3E2B416AF8}) -> S_OK
2024-10-21 12:10:00,475 - comtypes._comobject - DEBUG - 1 active COM objects: Added   <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>
2024-10-21 12:10:00,475 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x000001F64E248F80>.AddRef() -> 1
2024-10-21 12:10:00,475 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IConnectionPointContainer) ptr=0x1f63ad1ba88 at 1f64e51c750>
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectToken) ptr=0x1f6371e5f50 at 1f64e51c750>)
2024-10-21 12:10:00,521 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x1f6371e5f50 at 1f64e51c750>
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x1f6501606d0 at 1f64e51c750>)
2024-10-21 12:10:00,521 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1f6501af470 at 1f64e51c850>
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - wrap_outparam(<POINTER(IDispatch) ptr=0x1f6501f25f0 at 1f64e51ca50>)
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IDispatch) ptr=0x1f6501f25f0 at 1f64e51ca50>)
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo, trying IProvideClassInfo2
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo/IProvideClassInfo2
2024-10-21 12:10:00,521 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1f64c8e2150 at 1f64e51cc50>
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}
2024-10-21 12:10:00,521 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1f6501f25f0 at 1f64e51cd50>
2024-10-21 12:10:00,521 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>
2024-10-21 12:10:00,521 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechObjectToken) ptr=0x1f6501f25f0 at 1f64e51cc50>
2024-10-21 12:10:00,521 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x1f6501f25f0 at 1f64e51cbd0>
2024-10-21 12:10:00,521 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x1f64c8e2150 at 1f64e51ccd0>
2024-10-21 12:10:00,521 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x1f64c50eb00 at 1f64e51cd50>
2024-10-21 12:10:00,537 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x1f6501f25f0 at 1f64e51ca50>
2024-10-21 12:10:00,537 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IEnumVARIANT) ptr=0x1f6501af470 at 1f64e51c8d0>
2024-10-21 12:10:00,537 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectTokens) ptr=0x1f6501606d0 at 1f64e51c750>
2024-10-21 12:10:00,537 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x1f6501f25f0 at 1f64e51cc50>
2024-10-21 12:10:00,537 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:10:00,537 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:10:00,773 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:10:00,773 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:10:01,136 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2024-10-21 12:10:01,671 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/Systran/faster-whisper-base/revision/main HTTP/1.1" 200 1848
2024-10-21 12:10:02,340 - __main__ - INFO - Siri instance initialized
2024-10-21 12:10:13,622 - faster_whisper - INFO - Processing audio with duration 00:01.834
2024-10-21 12:10:26,352 - faster_whisper - INFO - Detected language 'en' with probability 0.39
2024-10-21 12:10:26,352 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:10:26,463 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:10:26,557 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:10:26,557 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:10:26,668 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E6030>
2024-10-21 12:10:26,668 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F64E51C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:10:26,797 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E5F70>
2024-10-21 12:10:26,797 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:10:26,797 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:10:26,797 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:10:26,797 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:10:26,797 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:10:27,300 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:10:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19881'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'357ms'), (b'x-request-id', b'req_01jaq5f4g5e2ctegj4rtds80ax'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WzeGaSMIKP14LZHIyQTVBeutaCEgpSt9zdOeWTWyyTM-1729501827-1.0.1.1-SKjvJEl0pIUf5dfiC_LFcZp.2qUDR5XF_grGivaxjF84F8mLXz2cCCNejhdfTjbf83oHeYe3pwAg2yFPc_GPUw; path=/; expires=Mon, 21-Oct-24 09:40:27 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601d557fa093ce-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:10:27,300 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:10:27,300 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:10:27,300 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:10:27,300 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:10:27,300 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:10:27,300 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:10:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19881', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '357ms', 'x-request-id': 'req_01jaq5f4g5e2ctegj4rtds80ax', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=WzeGaSMIKP14LZHIyQTVBeutaCEgpSt9zdOeWTWyyTM-1729501827-1.0.1.1-SKjvJEl0pIUf5dfiC_LFcZp.2qUDR5XF_grGivaxjF84F8mLXz2cCCNejhdfTjbf83oHeYe3pwAg2yFPc_GPUw; path=/; expires=Mon, 21-Oct-24 09:40:27 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8d601d557fa093ce-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:10:27,309 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:10:27,309 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:10:27,309 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:10:27,309 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:10:27,309 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:10:27,309 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:10:27,309 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:10:27,851 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:10:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19827'), (b'x-ratelimit-reset-requests', b'11.477s'), (b'x-ratelimit-reset-tokens', b'519ms'), (b'x-request-id', b'req_01jaq5f50hejqsyb6c828dte1w'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601d58bb6993ce-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:10:27,851 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:10:27,851 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:10:27,851 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:10:27,851 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:10:27,851 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:10:27,851 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:10:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19827', 'x-ratelimit-reset-requests': '11.477s', 'x-ratelimit-reset-tokens': '519ms', 'x-request-id': 'req_01jaq5f50hejqsyb6c828dte1w', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d601d58bb6993ce-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:10:28,147 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "What can I assist you with, or would you like to discuss or provide more context such as providing an image which may help generate a more accurate and personalized response, don't worry though the conversation can proceed without.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:10:28,147 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:10:28,147 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:10:28,322 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F653216270>
2024-10-21 12:10:28,322 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F64E51D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:10:28,463 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F653216180>
2024-10-21 12:10:28,464 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:10:28,466 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:10:28,466 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:10:28,467 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:10:28,467 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:10:30,747 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:10:31 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1295'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_d7bfe365e6df3e71286281ea402f2144'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Yp3tYXfW0IhEx_DL6Xm4w9qXceI7RbTJLBxFIvI0gec-1729501831-1.0.1.1-f.JZlNvY_YE2ESfcryMlzoRHwzfeAGzEbGF.m3llhTUiFs5iYDe8LHX.18E8k72onRbaDd8Jt_R1kj8LdRa0fA; path=/; expires=Mon, 21-Oct-24 09:40:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=OyDQVnTU1JNZIOKIZsPdwvmcE1MBfe0fuA_s5fs5O3Q-1729501831260-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601d5fe9fe73ad-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:10:30,747 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:10:30,747 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers([('date', 'Mon, 21 Oct 2024 09:10:31 GMT'), ('content-type', 'audio/pcm'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'viva-ai-g59lkf'), ('openai-processing-ms', '1295'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-reset-requests', '120ms'), ('x-request-id', 'req_d7bfe365e6df3e71286281ea402f2144'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Yp3tYXfW0IhEx_DL6Xm4w9qXceI7RbTJLBxFIvI0gec-1729501831-1.0.1.1-f.JZlNvY_YE2ESfcryMlzoRHwzfeAGzEbGF.m3llhTUiFs5iYDe8LHX.18E8k72onRbaDd8Jt_R1kj8LdRa0fA; path=/; expires=Mon, 21-Oct-24 09:40:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=OyDQVnTU1JNZIOKIZsPdwvmcE1MBfe0fuA_s5fs5O3Q-1729501831260-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8d601d5fe9fe73ad-JNB'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-10-21 12:10:30,747 - openai._base_client - DEBUG - request_id: req_d7bfe365e6df3e71286281ea402f2144
2024-10-21 12:10:30,747 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:10:45,069 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:10:45,069 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:10:45,069 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:11:00,899 - faster_whisper - INFO - Processing audio with duration 00:13.375
2024-10-21 12:11:03,786 - faster_whisper - INFO - Detected language 'en' with probability 0.76
2024-10-21 12:11:03,786 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:11:03,959 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'I want to know if what model you are based on.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:11:03,974 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:11:03,974 - httpcore.connection - DEBUG - close.started
2024-10-21 12:11:03,974 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:11:03,974 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:11:04,089 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E7710>
2024-10-21 12:11:04,090 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F64E51C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:11:04,219 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E6660>
2024-10-21 12:11:04,220 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:11:04,221 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:11:04,221 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:11:04,221 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:11:04,221 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:11:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19870'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'390ms'), (b'x-request-id', b'req_01jaq5g91ve0jvekbqjtp0x3y9'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601e3f5be94f6f-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:11:04,783 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:11:04,783 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:11:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19870', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '390ms', 'x-request-id': 'req_01jaq5g91ve0jvekbqjtp0x3y9', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d601e3f5be94f6f-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:11:04,783 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': "What can I assist you with, or would you like to discuss or provide more context such as providing an image which may help generate a more accurate and personalized response, don't worry though the conversation can proceed without."}, {'role': 'user', 'content': 'I want to know if what model you are based on.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:11:04,783 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:11:04,783 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:11:05,463 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:11:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19749'), (b'x-ratelimit-reset-requests', b'11.442999999s'), (b'x-ratelimit-reset-tokens', b'753ms'), (b'x-request-id', b'req_01jaq5g9kaf7x86r1gyegt7jv5'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601e42ef3e4f6f-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:11:05,463 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:11:05,463 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:11:05,463 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:11:05,463 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:11:05,463 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:11:05,463 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:11:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19749', 'x-ratelimit-reset-requests': '11.442999999s', 'x-ratelimit-reset-tokens': '753ms', 'x-request-id': 'req_01jaq5g9kaf7x86r1gyegt7jv5', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d601e42ef3e4f6f-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:11:05,637 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I'm a multi-modal AI voice assistant based on the combination of various transformer models including T5 and BERT, fine-tuned on a large dataset of text from the internet and integrated with computer vision capabilities to process images and text from screenshots or webcam captures for context.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:11:05,642 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:11:05,642 - httpcore.connection - DEBUG - close.started
2024-10-21 12:11:05,642 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:11:05,642 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:11:05,762 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F653217DD0>
2024-10-21 12:11:05,762 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F64E51D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:11:05,882 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6532175C0>
2024-10-21 12:11:05,882 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:11:05,882 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:11:05,882 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:11:05,882 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:11:05,882 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:11:07,248 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:11:07 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'757'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_819624b4c4cf06de102cdd6958f05c15'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601e49b8c1740c-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:11:07,248 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:11:07,253 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:11:07 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '757', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_819624b4c4cf06de102cdd6958f05c15', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d601e49b8c1740c-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:11:07,253 - openai._base_client - DEBUG - request_id: req_819624b4c4cf06de102cdd6958f05c15
2024-10-21 12:11:07,253 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:11:25,866 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:11:25,866 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:11:25,867 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:11:27,484 - faster_whisper - INFO - Processing audio with duration 00:01.277
2024-10-21 12:11:28,349 - faster_whisper - INFO - Detected language 'en' with probability 0.41
2024-10-21 12:11:28,352 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:11:28,519 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:11:28,519 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:11:28,519 - httpcore.connection - DEBUG - close.started
2024-10-21 12:11:28,519 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:11:28,519 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:11:28,630 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E5E80>
2024-10-21 12:11:28,631 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F64E51C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:11:28,762 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E70E0>
2024-10-21 12:11:28,762 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:11:28,762 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:11:28,762 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:11:28,762 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:11:28,762 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:11:29,232 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:11:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19881'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'357ms'), (b'x-request-id', b'req_01jaq5h111e9hrgmfs72ng27jv'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601ed8cf399e94-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:11:29,232 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:11:29,232 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:11:29,232 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:11:29,232 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:11:29,232 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:11:29,232 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:11:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19881', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '357ms', 'x-request-id': 'req_01jaq5h111e9hrgmfs72ng27jv', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d601ed8cf399e94-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:11:29,248 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': "What can I assist you with, or would you like to discuss or provide more context such as providing an image which may help generate a more accurate and personalized response, don't worry though the conversation can proceed without."}, {'role': 'user', 'content': 'I want to know if what model you are based on.'}, {'role': 'assistant', 'content': "I'm a multi-modal AI voice assistant based on the combination of various transformer models including T5 and BERT, fine-tuned on a large dataset of text from the internet and integrated with computer vision capabilities to process images and text from screenshots or webcam captures for context."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:11:29,248 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:11:29,248 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:11:29,248 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:11:29,248 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:11:29,248 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:11:29,248 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:11:29,849 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:11:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19666'), (b'x-ratelimit-reset-requests', b'11.532s'), (b'x-ratelimit-reset-tokens', b'1.002s'), (b'x-request-id', b'req_01jaq5h1fpfyfarg3wszr42v0z'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601edbcbb29e94-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:11:29,849 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:11:29,849 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:11:29,849 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:11:29,849 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:11:29,849 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:11:29,849 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:11:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19666', 'x-ratelimit-reset-requests': '11.532s', 'x-ratelimit-reset-tokens': '1.002s', 'x-request-id': 'req_01jaq5h1fpfyfarg3wszr42v0z', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d601edbcbb29e94-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:11:30,017 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'As a multi-modal AI voice assistant, my primary architecture combines elements of natural language processing and computer vision to provide more accurate and informative responses to a wider range of questions and prompts, utilizing a combination of BERT and T5 to form my foundation.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:11:30,017 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:11:30,017 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:11:30,017 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:11:30,017 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:11:30,017 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:11:30,017 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:11:31,536 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:11:31 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'943'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_0013e766061bc70a13bfd5400709a45f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601ee0bf18740c-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:11:31,536 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:11:31,536 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:11:31 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '943', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_0013e766061bc70a13bfd5400709a45f', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d601ee0bf18740c-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:11:31,536 - openai._base_client - DEBUG - request_id: req_0013e766061bc70a13bfd5400709a45f
2024-10-21 12:11:31,536 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:11:48,953 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:11:56,602 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:11:56,602 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:12:05,109 - faster_whisper - INFO - Processing audio with duration 00:02.694
2024-10-21 12:12:05,741 - faster_whisper - INFO - Detected language 'en' with probability 0.54
2024-10-21 12:12:05,741 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:12:05,882 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.0 (-1.107911 < -1.000000)
2024-10-21 12:12:06,150 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.2 (-1.431759 < -1.000000)
2024-10-21 12:12:06,482 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.4 (-1.435050 < -1.000000)
2024-10-21 12:12:07,907 - faster_whisper - DEBUG - Compression ratio threshold is not met with temperature 0.6 (13.382979 > 2.400000)
2024-10-21 12:12:08,255 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.8 (-1.944614 < -1.000000)
2024-10-21 12:12:08,491 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 1.0 (-2.275364 < -1.000000)
2024-10-21 12:12:08,491 - faster_whisper - DEBUG - Reset prompt. prompt_reset_on_temperature threshold is met 1.000000 > 0.500000
2024-10-21 12:12:08,491 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': "We'll see you in the next one."}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:12:08,491 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:12:08,491 - httpcore.connection - DEBUG - close.started
2024-10-21 12:12:08,491 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:12:08,491 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:12:08,602 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E73B0>
2024-10-21 12:12:08,602 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F64E51C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:12:08,738 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6515E6000>
2024-10-21 12:12:08,738 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:12:08,738 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:12:08,738 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:12:08,738 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:12:08,738 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:12:09,239 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:12:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19874'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'378ms'), (b'x-request-id', b'req_01jaq5j82cemz8cskws01tskz3'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601fd2a8fa4eb5-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:12:09,239 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:12:09,239 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:12:09,247 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:12:09,247 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:12:09,248 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:12:09,248 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:12:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19874', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '378ms', 'x-request-id': 'req_01jaq5j82cemz8cskws01tskz3', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d601fd2a8fa4eb5-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:12:09,248 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': "What can I assist you with, or would you like to discuss or provide more context such as providing an image which may help generate a more accurate and personalized response, don't worry though the conversation can proceed without."}, {'role': 'user', 'content': 'I want to know if what model you are based on.'}, {'role': 'assistant', 'content': "I'm a multi-modal AI voice assistant based on the combination of various transformer models including T5 and BERT, fine-tuned on a large dataset of text from the internet and integrated with computer vision capabilities to process images and text from screenshots or webcam captures for context."}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'As a multi-modal AI voice assistant, my primary architecture combines elements of natural language processing and computer vision to provide more accurate and informative responses to a wider range of questions and prompts, utilizing a combination of BERT and T5 to form my foundation.'}, {'role': 'user', 'content': "We'll see you in the next one."}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:12:09,248 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:12:09,248 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:12:09,248 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:12:09,248 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:12:09,248 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:12:09,248 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:12:09,915 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:12:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19578'), (b'x-ratelimit-reset-requests', b'11.461999999s'), (b'x-ratelimit-reset-tokens', b'1.266s'), (b'x-request-id', b'req_01jaq5j8k7fsrajp2s9bzb4ayh'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601fd60ecc4eb5-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:12:09,915 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:12:09,915 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:12:09,915 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:12:09,915 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:12:09,915 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:12:09,915 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:12:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19578', 'x-ratelimit-reset-requests': '11.461999999s', 'x-ratelimit-reset-tokens': '1.266s', 'x-request-id': 'req_01jaq5j8k7fsrajp2s9bzb4ayh', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d601fd60ecc4eb5-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:12:10,099 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "Sounds good, I'll be ready for our next conversation.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:12:10,099 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:12:10,099 - httpcore.connection - DEBUG - close.started
2024-10-21 12:12:10,099 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:12:10,099 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:12:10,228 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F653216600>
2024-10-21 12:12:10,238 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F64E51D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:12:10,371 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F653215A60>
2024-10-21 12:12:10,371 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:12:10,371 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:12:10,371 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:12:10,371 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:12:10,371 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:12:11,806 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:12:12 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'778'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_ad940687ac62c6f04c008d193a2186bc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d601fdcef6e4ebc-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:12:11,806 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:12:11,806 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:12:12 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '778', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_ad940687ac62c6f04c008d193a2186bc', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d601fdcef6e4ebc-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:12:11,806 - openai._base_client - DEBUG - request_id: req_ad940687ac62c6f04c008d193a2186bc
2024-10-21 12:12:11,806 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:12:14,662 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:12:14,662 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:12:14,662 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:12:25,458 - comtypes._post_coinit.unknwn - DEBUG - Calling CoUninitialize()
2024-10-21 12:12:25,458 - comtypes._post_coinit.unknwn - DEBUG - CoUninitialize() done.
2024-10-21 12:12:30,503 - __main__ - INFO - Starting main.py
2024-10-21 12:12:30,519 - __main__ - INFO - Chat log file path: C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\chat_history\2024\10\21.log
2024-10-21 12:12:30,519 - __main__ - INFO - API keys loaded successfully
2024-10-21 12:12:30,524 - comtypes - DEBUG - CoInitializeEx(None, 2)
2024-10-21 12:12:30,551 - comtypes.client._code_cache - INFO - Imported existing <module 'comtypes.gen' from 'C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\comtypes\\gen\\__init__.py'>
2024-10-21 12:12:30,551 - comtypes.client._code_cache - INFO - Using writeable comtypes cache directory: 'C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\comtypes\gen'
2024-10-21 12:12:30,598 - comtypes.client - DEBUG - SAPI.SPVoice -> {96749377-3391-11D2-9EE3-00C04F797396}
2024-10-21 12:12:30,598 - comtypes.client - DEBUG - CoCreateInstance({96749377-3391-11D2-9EE3-00C04F797396}, clsctx=None, interface=None)
2024-10-21 12:12:30,598 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IUnknown) ptr=0x256da11ba20 at 256ed8f6f50>)
2024-10-21 12:12:30,598 - comtypes.client - DEBUG - Does implement IProvideClassInfo
2024-10-21 12:12:30,598 - comtypes.client - DEBUG - Default interface is {269316D8-57BD-11D2-9EEE-00C04F797396}
2024-10-21 12:12:30,598 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x256da11ba60 at 256ed8f7350>
2024-10-21 12:12:30,598 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:12:30,598 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechVoice'>
2024-10-21 12:12:30,598 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechVoice) ptr=0x256da11ba60 at 256ed8f72d0>
2024-10-21 12:12:30,598 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo) ptr=0x256da11ba80 at 256ed8f6ed0>
2024-10-21 12:12:30,598 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x256ebca55e8 at 256ed8f6fd0>
2024-10-21 12:12:30,598 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x256ebca5640 at 256ed8f7050>
2024-10-21 12:12:30,613 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x256ebecddd0 at 256ed8f7350>
2024-10-21 12:12:30,613 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x256da11ba20 at 256ed8f6f50>
2024-10-21 12:12:30,613 - comtypes.client._events - DEBUG - <POINTER(ISpeechVoice) ptr=0x256da11ba60 at 256ed8f72d0> using sinkinterface from clsid <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:12:30,613 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo2) ptr=0x256da11ba80 at 256ed8f6f50>
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>: _ISpeechVoiceEvents.VoiceChange not implemented
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>: _ISpeechVoiceEvents.Bookmark not implemented
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>: _ISpeechVoiceEvents.Sentence not implemented
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>: _ISpeechVoiceEvents.Phoneme not implemented
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>: _ISpeechVoiceEvents.Viseme not implemented
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>: _ISpeechVoiceEvents.AudioLevel not implemented
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>: _ISpeechVoiceEvents.EnginePrivate not implemented
2024-10-21 12:12:30,613 - comtypes.client._events - DEBUG - Start advise <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>.QueryInterface({A372ACD1-3BEF-4BBD-8FFB-CB3E2B416AF8}) -> S_OK
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - 1 active COM objects: Added   <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>
2024-10-21 12:12:30,613 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>.AddRef() -> 1
2024-10-21 12:12:30,624 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IConnectionPointContainer) ptr=0x256da11ba88 at 256ed95c750>
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectToken) ptr=0x256da1f2d30 at 256ed95c750>)
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x256da1f2d30 at 256ed95c750>
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x256ec70aad0 at 256ed95c750>)
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x256edeb1150 at 256ed95c850>
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - wrap_outparam(<POINTER(IDispatch) ptr=0x256ede64950 at 256ed95ca50>)
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IDispatch) ptr=0x256ede64950 at 256ed95ca50>)
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo, trying IProvideClassInfo2
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo/IProvideClassInfo2
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x256ebca56f0 at 256ed95cc50>
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x256ede64950 at 256ed95cd50>
2024-10-21 12:12:30,676 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>
2024-10-21 12:12:30,676 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechObjectToken) ptr=0x256ede64950 at 256ed95cc50>
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x256ede64950 at 256ed95cbd0>
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x256ebca56f0 at 256ed95ccd0>
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x256ebecddd0 at 256ed95cd50>
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x256ede64950 at 256ed95ca50>
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IEnumVARIANT) ptr=0x256edeb1150 at 256ed95c8d0>
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectTokens) ptr=0x256ec70aad0 at 256ed95c750>
2024-10-21 12:12:30,676 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x256ede64950 at 256ed95cc50>
2024-10-21 12:12:30,676 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:12:30,676 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:12:30,912 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:12:30,912 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:12:31,273 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2024-10-21 12:12:31,871 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/Systran/faster-whisper-base/revision/main HTTP/1.1" 200 1848
2024-10-21 12:12:32,374 - __main__ - INFO - Siri instance initialized
2024-10-21 12:12:40,209 - faster_whisper - INFO - Processing audio with duration 00:01.834
2024-10-21 12:12:43,675 - faster_whisper - INFO - Detected language 'en' with probability 0.38
2024-10-21 12:12:43,675 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:12:43,801 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:12:43,879 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:12:43,879 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:12:44,013 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E9CD0>
2024-10-21 12:12:44,013 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:12:44,142 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F0907CE0>
2024-10-21 12:12:44,142 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:12:44,142 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:12:44,142 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:12:44,147 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:12:44,147 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:12:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19881'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'357ms'), (b'x-request-id', b'req_01jaq5katse16993a3k47dj4zr'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cdBVonBffTnLSMRT2Ar5iU.JJOxvoHF6jeVFYxd6SCY-1729501965-1.0.1.1-UInXDxqRDB4tko_r0Nj6tpTCQRoN9ZO5xRB304ykaVH4zdWbDrhXhs1uwNfvCRGF6ORUtWDMpp9YE5GEy29BNA; path=/; expires=Mon, 21-Oct-24 09:42:45 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6020afee7d7404-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:12:44,930 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:12:44,930 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:12:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19881', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '357ms', 'x-request-id': 'req_01jaq5katse16993a3k47dj4zr', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=cdBVonBffTnLSMRT2Ar5iU.JJOxvoHF6jeVFYxd6SCY-1729501965-1.0.1.1-UInXDxqRDB4tko_r0Nj6tpTCQRoN9ZO5xRB304ykaVH4zdWbDrhXhs1uwNfvCRGF6ORUtWDMpp9YE5GEy29BNA; path=/; expires=Mon, 21-Oct-24 09:42:45 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8d6020afee7d7404-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:12:44,930 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:12:44,930 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:12:44,930 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:12:45,527 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:12:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19827'), (b'x-ratelimit-reset-requests', b'11.411s'), (b'x-ratelimit-reset-tokens', b'519ms'), (b'x-request-id', b'req_01jaq5kbd6e9p9tef06hn3q6be'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6020b4dcdb7404-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:12:45,528 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:12:45,528 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:12:45,528 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:12:45,529 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:12:45,529 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:12:45,530 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:12:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19827', 'x-ratelimit-reset-requests': '11.411s', 'x-ratelimit-reset-tokens': '519ms', 'x-request-id': 'req_01jaq5kbd6e9p9tef06hn3q6be', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6020b4dcdb7404-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:12:45,795 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:12:45,795 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:12:45,795 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:12:45,913 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269DF40>
2024-10-21 12:12:45,913 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:12:46,086 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269DE50>
2024-10-21 12:12:46,086 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:12:46,089 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:12:46,089 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:12:46,089 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:12:46,089 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:12:47,928 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:12:48 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1223'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_d18c338b62cb2c820b9bc83bfea9ccf6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=kflyyrAD8OojjpvFyg8b9.RsJ3CS_qVg_JtVPG2s_vk-1729501968-1.0.1.1-3eRM6JrBLXFr4UTyDRNJpEIliHSIScprP92KOiXbjRaXshoCFnTiVT3AJeC.N.BPq7Wa2PLPcNeap9.vAsKfjQ; path=/; expires=Mon, 21-Oct-24 09:42:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=dRea2fCGFH6B.FQ72e3TrK.6pXSMK6hC6OgSUbQotyw-1729501968467-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6020bc1e5c73e5-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:12:47,944 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:12:47,944 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers([('date', 'Mon, 21 Oct 2024 09:12:48 GMT'), ('content-type', 'audio/pcm'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'viva-ai-g59lkf'), ('openai-processing-ms', '1223'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-reset-requests', '120ms'), ('x-request-id', 'req_d18c338b62cb2c820b9bc83bfea9ccf6'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=kflyyrAD8OojjpvFyg8b9.RsJ3CS_qVg_JtVPG2s_vk-1729501968-1.0.1.1-3eRM6JrBLXFr4UTyDRNJpEIliHSIScprP92KOiXbjRaXshoCFnTiVT3AJeC.N.BPq7Wa2PLPcNeap9.vAsKfjQ; path=/; expires=Mon, 21-Oct-24 09:42:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=dRea2fCGFH6B.FQ72e3TrK.6pXSMK6hC6OgSUbQotyw-1729501968467-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8d6020bc1e5c73e5-JNB'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-10-21 12:12:47,944 - openai._base_client - DEBUG - request_id: req_d18c338b62cb2c820b9bc83bfea9ccf6
2024-10-21 12:12:47,944 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:13:17,395 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:13:17,395 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:13:17,395 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:13:33,405 - faster_whisper - INFO - Processing audio with duration 00:11.935
2024-10-21 12:13:34,047 - faster_whisper - INFO - Detected language 'en' with probability 0.85
2024-10-21 12:13:34,047 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:13:34,195 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Which is the longest you find the world?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:13:34,195 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:13:34,195 - httpcore.connection - DEBUG - close.started
2024-10-21 12:13:34,195 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:13:34,195 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:13:34,325 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E92E0>
2024-10-21 12:13:34,325 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:13:34,462 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EA1B0>
2024-10-21 12:13:34,462 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:13:34,462 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:13:34,462 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:13:34,462 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:13:34,462 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:13:34,979 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:13:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19871'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'387ms'), (b'x-request-id', b'req_01jaq5mvshebfavymvt102794g'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6021ea6cfd740d-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:13:34,979 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:13:34,979 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:13:34,979 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:13:34,979 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:13:34,979 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:13:34,979 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:13:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19871', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '387ms', 'x-request-id': 'req_01jaq5mvshebfavymvt102794g', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6021ea6cfd740d-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:13:34,979 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:13:34,995 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:13:34,996 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:13:34,996 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:13:34,996 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:13:34,996 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:13:34,996 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:13:35,618 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:13:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19690'), (b'x-ratelimit-reset-requests', b'11.484s'), (b'x-ratelimit-reset-tokens', b'930ms'), (b'x-request-id', b'req_01jaq5mw9tfhj9qjz9m7yks7r7'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6021eda8a6740d-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:13:35,618 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:13:35,618 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:13:35,618 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:13:35,618 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:13:35,618 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:13:35,618 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:13:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19690', 'x-ratelimit-reset-requests': '11.484s', 'x-ratelimit-reset-tokens': '930ms', 'x-request-id': 'req_01jaq5mw9tfhj9qjz9m7yks7r7', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6021eda8a6740d-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:13:35,796 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:13:35,796 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:13:35,796 - httpcore.connection - DEBUG - close.started
2024-10-21 12:13:35,796 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:13:35,796 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:13:35,942 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269FA10>
2024-10-21 12:13:35,942 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:13:36,051 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269F410>
2024-10-21 12:13:36,051 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:13:36,053 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:13:36,053 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:13:36,053 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:13:36,053 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:13:39,393 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:13:39 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'2100'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_92cbc3c6b7cbbdc2b469bb4e374bb4ed'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6021f44b0573ad-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:13:39,393 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:13:39,393 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:13:39 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '2100', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_92cbc3c6b7cbbdc2b469bb4e374bb4ed', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6021f44b0573ad-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:13:39,393 - openai._base_client - DEBUG - request_id: req_92cbc3c6b7cbbdc2b469bb4e374bb4ed
2024-10-21 12:13:39,393 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:14:02,898 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:14:02,898 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:14:02,898 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:14:19,970 - faster_whisper - INFO - Processing audio with duration 00:13.375
2024-10-21 12:14:20,636 - faster_whisper - INFO - Detected language 'en' with probability 0.79
2024-10-21 12:14:20,636 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:14:20,761 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:14:20,761 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:14:20,761 - httpcore.connection - DEBUG - close.started
2024-10-21 12:14:20,761 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:14:20,761 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:14:20,895 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E95B0>
2024-10-21 12:14:20,896 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:14:21,012 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E9340>
2024-10-21 12:14:21,013 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:14:21,014 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:14:21,014 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:14:21,014 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:14:21,015 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:14:21,562 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:14:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19870'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'390ms'), (b'x-request-id', b'req_01jaq5p9a5fg7a70qjxvwbx0qj'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60230ddfb47402-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:14:21,562 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:14:21,562 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:14:21,562 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:14:21,562 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:14:21,562 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:14:21,562 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:14:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19870', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '390ms', 'x-request-id': 'req_01jaq5p9a5fg7a70qjxvwbx0qj', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60230ddfb47402-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:14:21,573 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:14:21,573 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:14:21,577 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:14:21,578 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:14:21,578 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:14:21,578 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:14:21,578 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:14:22,226 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:14:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19584'), (b'x-ratelimit-reset-requests', b'11.524s'), (b'x-ratelimit-reset-tokens', b'1.248s'), (b'x-request-id', b'req_01jaq5p9s3f86ra2mhp20fs9nn'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602310cc837402-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:14:22,226 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:14:22,226 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:14:22,227 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:14:22,228 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:14:22,228 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:14:22,228 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:14:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19584', 'x-ratelimit-reset-requests': '11.524s', 'x-ratelimit-reset-tokens': '1.248s', 'x-request-id': 'req_01jaq5p9s3f86ra2mhp20fs9nn', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602310cc837402-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:14:22,396 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:14:22,396 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:14:22,396 - httpcore.connection - DEBUG - close.started
2024-10-21 12:14:22,396 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:14:22,396 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:14:22,525 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269C950>
2024-10-21 12:14:22,525 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:14:22,668 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269CC20>
2024-10-21 12:14:22,668 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:14:22,668 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:14:22,668 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:14:22,668 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:14:22,668 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:14:24,104 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:14:24 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'911'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_2b4735701e629b786ca00c28b9c46599'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602317acff73dd-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:14:24,104 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:14:24,104 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:14:24 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '911', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_2b4735701e629b786ca00c28b9c46599', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602317acff73dd-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:14:24,118 - openai._base_client - DEBUG - request_id: req_2b4735701e629b786ca00c28b9c46599
2024-10-21 12:14:24,118 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:14:51,389 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:14:51,389 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:14:51,389 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:15:07,664 - faster_whisper - INFO - Processing audio with duration 00:13.421
2024-10-21 12:15:08,323 - faster_whisper - INFO - Detected language 'en' with probability 0.28
2024-10-21 12:15:08,323 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:15:08,511 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:15:08,511 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:15:08,511 - httpcore.connection - DEBUG - close.started
2024-10-21 12:15:08,511 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:15:08,511 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:15:08,887 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E90A0>
2024-10-21 12:15:08,887 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:15:09,193 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EA480>
2024-10-21 12:15:09,193 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:15:09,194 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:15:09,194 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:15:09,194 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:15:09,194 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:15:09,693 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:15:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19869'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'393ms'), (b'x-request-id', b'req_01jaq5qr99e50av37bnynmbavf'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60243a6b13740e-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:15:09,694 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:15:09,694 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:15:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19869', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '393ms', 'x-request-id': 'req_01jaq5qr99e50av37bnynmbavf', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60243a6b13740e-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:15:09,694 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:15:09,694 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:15:09,694 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:15:11,218 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:15:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19453'), (b'x-ratelimit-reset-requests', b'10.68s'), (b'x-ratelimit-reset-tokens', b'1.641s'), (b'x-request-id', b'req_01jaq5qsjke10bs4q539et3p87'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60243daf69740e-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:15:11,218 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:15:11,218 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:15:11,218 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:15:11,218 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:15:11,218 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:15:11,234 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:15:11 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19453', 'x-ratelimit-reset-requests': '10.68s', 'x-ratelimit-reset-tokens': '1.641s', 'x-request-id': 'req_01jaq5qsjke10bs4q539et3p87', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60243daf69740e-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:15:11,394 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:15:11,394 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:15:11,394 - httpcore.connection - DEBUG - close.started
2024-10-21 12:15:11,394 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:15:11,394 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:15:11,525 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269EF00>
2024-10-21 12:15:11,525 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:15:11,649 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269ECF0>
2024-10-21 12:15:11,649 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:15:11,649 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:15:11,649 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:15:11,649 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:15:11,655 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:15:13,795 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:15:14 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1579'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_4f7881b93e68e4e1a9d1b13348e3284c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602449dd364ec4-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:15:13,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:15:13,795 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:15:14 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1579', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_4f7881b93e68e4e1a9d1b13348e3284c', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602449dd364ec4-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:15:13,795 - openai._base_client - DEBUG - request_id: req_4f7881b93e68e4e1a9d1b13348e3284c
2024-10-21 12:15:13,795 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:15:47,881 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:15:47,881 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:15:47,881 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:16:07,090 - faster_whisper - INFO - Processing audio with duration 00:17.299
2024-10-21 12:16:07,947 - faster_whisper - INFO - Detected language 'en' with probability 0.65
2024-10-21 12:16:07,947 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:16:08,151 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:16:08,151 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:16:08,151 - httpcore.connection - DEBUG - close.started
2024-10-21 12:16:08,151 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:16:08,151 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:16:08,264 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EAB70>
2024-10-21 12:16:08,265 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:16:08,457 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EB7A0>
2024-10-21 12:16:08,457 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:16:08,457 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:16:08,457 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:16:08,457 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:16:08,457 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:16:08,958 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:16:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19864'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'408ms'), (b'x-request-id', b'req_01jaq5sj5re1hrsg8rn6te15p1'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6025acee7773f1-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:16:08,959 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:16:08,959 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:16:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19864', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '408ms', 'x-request-id': 'req_01jaq5sj5re1hrsg8rn6te15p1', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6025acee7773f1-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:16:08,959 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:16:08,959 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:16:08,959 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:16:09,650 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:16:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19289'), (b'x-ratelimit-reset-requests', b'11.469s'), (b'x-ratelimit-reset-tokens', b'2.133s'), (b'x-request-id', b'req_01jaq5sjnrfatvf3a94jg68yjf'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6025b01bdd73f1-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:16:09,650 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:16:09,650 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:16:09,650 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:16:09,650 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:16:09,650 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:16:09,650 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:16:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19289', 'x-ratelimit-reset-requests': '11.469s', 'x-ratelimit-reset-tokens': '2.133s', 'x-request-id': 'req_01jaq5sjnrfatvf3a94jg68yjf', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6025b01bdd73f1-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:16:09,826 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:16:09,826 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:16:09,826 - httpcore.connection - DEBUG - close.started
2024-10-21 12:16:09,826 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:16:09,826 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:16:09,956 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269F350>
2024-10-21 12:16:09,956 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:16:10,090 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269F9E0>
2024-10-21 12:16:10,090 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:16:10,090 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:16:10,090 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:16:10,090 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:16:10,090 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:16:12,845 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:16:13 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1706'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_1468df37b393345f9ce16ecb0b2dfd50'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6025b71d35738c-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:16:12,845 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:16:12,845 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:16:13 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1706', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_1468df37b393345f9ce16ecb0b2dfd50', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6025b71d35738c-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:16:12,851 - openai._base_client - DEBUG - request_id: req_1468df37b393345f9ce16ecb0b2dfd50
2024-10-21 12:16:12,851 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:16:34,282 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:16:34,282 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:16:34,282 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:16:50,317 - faster_whisper - INFO - Processing audio with duration 00:15.604
2024-10-21 12:16:51,106 - faster_whisper - INFO - Detected language 'en' with probability 0.45
2024-10-21 12:16:51,106 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:16:51,280 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:16:51,280 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:16:51,280 - httpcore.connection - DEBUG - close.started
2024-10-21 12:16:51,280 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:16:51,280 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:16:51,383 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EBC80>
2024-10-21 12:16:51,383 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:16:51,541 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EA150>
2024-10-21 12:16:51,541 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:16:51,541 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:16:51,541 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:16:51,556 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:16:51,556 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:16:52,021 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:16:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19868'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'396ms'), (b'x-request-id', b'req_01jaq5tw7sf14rxhpmcpar0d6h'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6026ba3fa24eb6-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:16:52,024 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:16:52,025 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:16:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19868', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '396ms', 'x-request-id': 'req_01jaq5tw7sf14rxhpmcpar0d6h', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6026ba3fa24eb6-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:16:52,025 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}, {'role': 'assistant', 'content': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?"}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:16:52,025 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:16:52,025 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:16:52,804 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:16:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19180'), (b'x-ratelimit-reset-requests', b'11.494999999s'), (b'x-ratelimit-reset-tokens', b'2.46s'), (b'x-request-id', b'req_01jaq5twptesm8y7sy4qh0vbep'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6026bd2ba64eb6-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:16:52,804 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:16:52,804 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:16:52,804 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:16:52,804 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:16:52,804 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:16:52,804 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:16:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19180', 'x-ratelimit-reset-requests': '11.494999999s', 'x-ratelimit-reset-tokens': '2.46s', 'x-request-id': 'req_01jaq5twptesm8y7sy4qh0vbep', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6026bd2ba64eb6-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:16:52,975 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'Directions from Nairobi City to Mombasa City typically involve driving via the Mombasa Highway or A109 highway, which is a major road network connecting the two cities. The journey is approximately 480 kilometers and usually takes around 8-10 hours by car, depending on traffic and road conditions. You can take regular breaks along the way through towns like Machakos, Kitale and Voi and it is also advisable to consider hiring a guided tour or driving with a local.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:16:52,975 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:16:52,975 - httpcore.connection - DEBUG - close.started
2024-10-21 12:16:52,975 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:16:52,975 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:16:53,106 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269CB00>
2024-10-21 12:16:53,106 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:16:53,217 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269D520>
2024-10-21 12:16:53,217 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:16:53,217 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:16:53,217 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:16:53,217 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:16:53,217 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:16:56,776 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:16:56 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1385'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_1e8819260d5f3fa3c769a59669061899'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6026c4cbae051d-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:16:56,792 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:16:56,792 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:16:56 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1385', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_1e8819260d5f3fa3c769a59669061899', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6026c4cbae051d-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:16:56,792 - openai._base_client - DEBUG - request_id: req_1e8819260d5f3fa3c769a59669061899
2024-10-21 12:16:56,792 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:17:27,263 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:17:27,263 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:17:27,263 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:18:01,367 - faster_whisper - INFO - Processing audio with duration 00:12.098
2024-10-21 12:18:02,050 - faster_whisper - INFO - Detected language 'en' with probability 0.79
2024-10-21 12:18:02,050 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:18:02,207 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': "Do you have access to Google Maps API's?"}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:18:02,207 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:18:02,207 - httpcore.connection - DEBUG - close.started
2024-10-21 12:18:02,207 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:18:02,207 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:18:02,787 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E9D60>
2024-10-21 12:18:02,787 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:18:02,907 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EACC0>
2024-10-21 12:18:02,907 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:18:02,907 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:18:02,907 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:18:02,907 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:18:02,907 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:18:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19871'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'387ms'), (b'x-request-id', b'req_01jaq5x1y4f8rt7bjs4xqnrnkp'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6028783c81053e-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:18:03,390 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:18:03,390 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:18:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19871', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '387ms', 'x-request-id': 'req_01jaq5x1y4f8rt7bjs4xqnrnkp', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6028783c81053e-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:18:03,390 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}, {'role': 'assistant', 'content': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?"}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}, {'role': 'assistant', 'content': 'Directions from Nairobi City to Mombasa City typically involve driving via the Mombasa Highway or A109 highway, which is a major road network connecting the two cities. The journey is approximately 480 kilometers and usually takes around 8-10 hours by car, depending on traffic and road conditions. You can take regular breaks along the way through towns like Machakos, Kitale and Voi and it is also advisable to consider hiring a guided tour or driving with a local.'}, {'role': 'user', 'content': "Do you have access to Google Maps API's?"}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:18:03,390 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:18:03,390 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:18:04,098 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:18:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19044'), (b'x-ratelimit-reset-requests', b'11.504999999s'), (b'x-ratelimit-reset-tokens', b'2.868s'), (b'x-request-id', b'req_01jaq5x2ddebyan3wf3dxwar0q'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60287b3ff1053e-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:18:04,098 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:18:04,098 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:18:04,098 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:18:04,098 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:18:04,098 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:18:04,098 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:18:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19044', 'x-ratelimit-reset-requests': '11.504999999s', 'x-ratelimit-reset-tokens': '2.868s', 'x-request-id': 'req_01jaq5x2ddebyan3wf3dxwar0q', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60287b3ff1053e-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:18:04,274 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "No, I don't have direct access to the Google Maps API or any external APIs for that matter. My previous response was based on pre-existing knowledge and general information. I can provide directions and distances but will not have real-time traffic updates or exact route information.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:18:04,274 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:18:04,274 - httpcore.connection - DEBUG - close.started
2024-10-21 12:18:04,274 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:18:04,274 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:18:04,405 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26A8920>
2024-10-21 12:18:04,405 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:18:04,553 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26A80E0>
2024-10-21 12:18:04,553 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:18:04,553 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:18:04,553 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:18:04,553 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:18:04,553 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:18:06,612 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:18:07 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1237'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_625473e1189bfbcb269283b279faa304'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6028827a4c73f1-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:18:06,612 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:18:06,612 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:18:07 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1237', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_625473e1189bfbcb269283b279faa304', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6028827a4c73f1-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:18:06,628 - openai._base_client - DEBUG - request_id: req_625473e1189bfbcb269283b279faa304
2024-10-21 12:18:06,628 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:18:24,411 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:18:24,411 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:18:24,411 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:18:42,514 - faster_whisper - INFO - Processing audio with duration 00:14.280
2024-10-21 12:18:43,230 - faster_whisper - INFO - Detected language 'en' with probability 0.59
2024-10-21 12:18:43,230 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:18:43,464 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': "Does Jimmy know, can I change your voice? Can I change it to someone else's voice?"}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:18:43,464 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:18:43,464 - httpcore.connection - DEBUG - close.started
2024-10-21 12:18:43,464 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:18:43,464 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:18:43,582 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E90A0>
2024-10-21 12:18:43,582 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:18:43,699 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EB980>
2024-10-21 12:18:43,699 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:18:43,700 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:18:43,700 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:18:43,700 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:18:43,701 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:18:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19861'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'417ms'), (b'x-request-id', b'req_01jaq5y9s5e7vtgm0034ytn9d7'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6029771c074eb9-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:18:44,189 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:18:44,189 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:18:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19861', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '417ms', 'x-request-id': 'req_01jaq5y9s5e7vtgm0034ytn9d7', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6029771c074eb9-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:18:44,189 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}, {'role': 'assistant', 'content': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?"}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}, {'role': 'assistant', 'content': 'Directions from Nairobi City to Mombasa City typically involve driving via the Mombasa Highway or A109 highway, which is a major road network connecting the two cities. The journey is approximately 480 kilometers and usually takes around 8-10 hours by car, depending on traffic and road conditions. You can take regular breaks along the way through towns like Machakos, Kitale and Voi and it is also advisable to consider hiring a guided tour or driving with a local.'}, {'role': 'user', 'content': "Do you have access to Google Maps API's?"}, {'role': 'assistant', 'content': "No, I don't have direct access to the Google Maps API or any external APIs for that matter. My previous response was based on pre-existing knowledge and general information. I can provide directions and distances but will not have real-time traffic updates or exact route information."}, {'role': 'user', 'content': "Does Jimmy know, can I change your voice? Can I change it to someone else's voice?"}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:18:44,189 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:18:44,189 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:18:44,985 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:18:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'18943'), (b'x-ratelimit-reset-requests', b'11.491s'), (b'x-ratelimit-reset-tokens', b'3.171s'), (b'x-request-id', b'req_01jaq5ya8re8n95srzaf8cf2js'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60297a48b84eb9-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:18:44,985 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:18:44,985 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:18:44,985 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:18:44,985 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:18:44,985 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:18:44,985 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:18:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '18943', 'x-ratelimit-reset-requests': '11.491s', 'x-ratelimit-reset-tokens': '3.171s', 'x-request-id': 'req_01jaq5ya8re8n95srzaf8cf2js', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d60297a48b84eb9-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:18:45,173 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'I don\'t have personal relationships or interactions with individuals, so I\'m not aware of a "Jimmy" who knows anything about me. Regarding changing my voice, I can mimic the tones, pace, and language styles of different human voices, but I don\'t have direct control over external synthesis or persona modeling that would allow me to perfectly emulate someone else\'s voice, such as a well-known celebrity or an individual. However, I can modify my voice to fit various personas or reflect different emotional tones with varying levels of success, based on pre-existing data and modeling.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:18:45,173 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:18:45,173 - httpcore.connection - DEBUG - close.started
2024-10-21 12:18:45,173 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:18:45,173 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:18:45,299 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269EC30>
2024-10-21 12:18:45,299 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:18:45,478 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26ABC50>
2024-10-21 12:18:45,478 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:18:45,478 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:18:45,478 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:18:45,483 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:18:45,483 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:18:47,146 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:18:47 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1244'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_db1d60d5aff214a901071cdc28a0739f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602982395173e4-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:18:47,146 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:18:47,146 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:18:47 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1244', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_db1d60d5aff214a901071cdc28a0739f', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602982395173e4-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:18:47,146 - openai._base_client - DEBUG - request_id: req_db1d60d5aff214a901071cdc28a0739f
2024-10-21 12:18:47,146 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:19:22,528 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:19:22,528 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:19:22,528 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:19:39,686 - faster_whisper - INFO - Processing audio with duration 00:15.023
2024-10-21 12:19:40,398 - faster_whisper - INFO - Detected language 'en' with probability 0.82
2024-10-21 12:19:40,398 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:19:40,571 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Okay, so now from now on be sound more empathetic.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:19:40,571 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:19:40,571 - httpcore.connection - DEBUG - close.started
2024-10-21 12:19:40,571 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:19:40,571 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:19:40,686 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269D610>
2024-10-21 12:19:40,686 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:19:40,809 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269DA90>
2024-10-21 12:19:40,809 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:19:40,810 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:19:40,810 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:19:40,810 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:19:40,811 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:19:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19869'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'393ms'), (b'x-request-id', b'req_01jaq601htf928xczaj0c63mc6'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602adc28d373fa-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:19:41,321 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:19:41,321 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:19:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19869', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '393ms', 'x-request-id': 'req_01jaq601htf928xczaj0c63mc6', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602adc28d373fa-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:19:41,321 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}, {'role': 'assistant', 'content': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?"}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}, {'role': 'assistant', 'content': 'Directions from Nairobi City to Mombasa City typically involve driving via the Mombasa Highway or A109 highway, which is a major road network connecting the two cities. The journey is approximately 480 kilometers and usually takes around 8-10 hours by car, depending on traffic and road conditions. You can take regular breaks along the way through towns like Machakos, Kitale and Voi and it is also advisable to consider hiring a guided tour or driving with a local.'}, {'role': 'user', 'content': "Do you have access to Google Maps API's?"}, {'role': 'assistant', 'content': "No, I don't have direct access to the Google Maps API or any external APIs for that matter. My previous response was based on pre-existing knowledge and general information. I can provide directions and distances but will not have real-time traffic updates or exact route information."}, {'role': 'user', 'content': "Does Jimmy know, can I change your voice? Can I change it to someone else's voice?"}, {'role': 'assistant', 'content': 'I don\'t have personal relationships or interactions with individuals, so I\'m not aware of a "Jimmy" who knows anything about me. Regarding changing my voice, I can mimic the tones, pace, and language styles of different human voices, but I don\'t have direct control over external synthesis or persona modeling that would allow me to perfectly emulate someone else\'s voice, such as a well-known celebrity or an individual. However, I can modify my voice to fit various personas or reflect different emotional tones with varying levels of success, based on pre-existing data and modeling.'}, {'role': 'user', 'content': 'Okay, so now from now on be sound more empathetic.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:19:41,321 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:19:41,321 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:19:41,336 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:19:41,338 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:19:42,952 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:19:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'18775'), (b'x-ratelimit-reset-requests', b'10.616s'), (b'x-ratelimit-reset-tokens', b'3.675s'), (b'x-request-id', b'req_01jaq602w2f9ctg1hmyww3sktz'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602adf6d4473fa-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:19:42,952 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:19:42,952 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:19:42,952 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:19:42,952 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:19:42,952 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:19:42,952 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:19:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '18775', 'x-ratelimit-reset-requests': '10.616s', 'x-ratelimit-reset-tokens': '3.675s', 'x-request-id': 'req_01jaq602w2f9ctg1hmyww3sktz', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602adf6d4473fa-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:19:43,121 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I'll do my best to adapt my tone and language to be more empathetic and compassionate, acknowledging the emotional and personal contexts that users bring to our conversations. I'll strive to be more understanding, supportive, and validating, while still providing accurate and helpful information. Let's communicate in a way that feels more personal and sensitive to your concerns and needs.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:19:43,121 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:19:43,121 - httpcore.connection - DEBUG - close.started
2024-10-21 12:19:43,121 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:19:43,121 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:19:43,230 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26AA5D0>
2024-10-21 12:19:43,230 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:19:43,351 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26AA3F0>
2024-10-21 12:19:43,351 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:19:43,351 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:19:43,351 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:19:43,351 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:19:43,351 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:19:46,905 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:19:47 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'2285'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_c619d872b0937a5748774ba8dc4f110b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602aec0c4d0521-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:19:46,905 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:19:46,905 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:19:47 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '2285', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_c619d872b0937a5748774ba8dc4f110b', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602aec0c4d0521-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:19:46,905 - openai._base_client - DEBUG - request_id: req_c619d872b0937a5748774ba8dc4f110b
2024-10-21 12:19:46,905 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:20:11,071 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:20:11,071 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:20:11,071 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:20:27,185 - faster_whisper - INFO - Processing audio with duration 00:14.257
2024-10-21 12:20:27,875 - faster_whisper - INFO - Detected language 'en' with probability 0.42
2024-10-21 12:20:27,875 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:20:28,033 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'What other languages can you recognize apart from English?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:20:28,033 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:20:28,033 - httpcore.connection - DEBUG - close.started
2024-10-21 12:20:28,033 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:20:28,033 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:20:28,170 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269FE00>
2024-10-21 12:20:28,171 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:20:28,296 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269F650>
2024-10-21 12:20:28,297 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:20:28,298 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:20:28,298 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:20:28,298 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:20:28,298 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:20:28,771 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:20:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19867'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'399ms'), (b'x-request-id', b'req_01jaq61fx8fjmbq4wffgyazshe'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602c04dbc84ed9-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:20:28,771 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:20:28,771 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:20:28,771 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:20:28,771 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:20:28,771 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:20:28,771 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:20:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19867', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '399ms', 'x-request-id': 'req_01jaq61fx8fjmbq4wffgyazshe', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602c04dbc84ed9-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:20:28,787 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}, {'role': 'assistant', 'content': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?"}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}, {'role': 'assistant', 'content': 'Directions from Nairobi City to Mombasa City typically involve driving via the Mombasa Highway or A109 highway, which is a major road network connecting the two cities. The journey is approximately 480 kilometers and usually takes around 8-10 hours by car, depending on traffic and road conditions. You can take regular breaks along the way through towns like Machakos, Kitale and Voi and it is also advisable to consider hiring a guided tour or driving with a local.'}, {'role': 'user', 'content': "Do you have access to Google Maps API's?"}, {'role': 'assistant', 'content': "No, I don't have direct access to the Google Maps API or any external APIs for that matter. My previous response was based on pre-existing knowledge and general information. I can provide directions and distances but will not have real-time traffic updates or exact route information."}, {'role': 'user', 'content': "Does Jimmy know, can I change your voice? Can I change it to someone else's voice?"}, {'role': 'assistant', 'content': 'I don\'t have personal relationships or interactions with individuals, so I\'m not aware of a "Jimmy" who knows anything about me. Regarding changing my voice, I can mimic the tones, pace, and language styles of different human voices, but I don\'t have direct control over external synthesis or persona modeling that would allow me to perfectly emulate someone else\'s voice, such as a well-known celebrity or an individual. However, I can modify my voice to fit various personas or reflect different emotional tones with varying levels of success, based on pre-existing data and modeling.'}, {'role': 'user', 'content': 'Okay, so now from now on be sound more empathetic.'}, {'role': 'assistant', 'content': "I'll do my best to adapt my tone and language to be more empathetic and compassionate, acknowledging the emotional and personal contexts that users bring to our conversations. I'll strive to be more understanding, supportive, and validating, while still providing accurate and helpful information. Let's communicate in a way that feels more personal and sensitive to your concerns and needs."}, {'role': 'user', 'content': 'What other languages can you recognize apart from English?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:20:28,787 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:20:28,787 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:20:28,787 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:20:28,787 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:20:28,787 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:20:28,787 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:20:29,648 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:20:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'18654'), (b'x-ratelimit-reset-requests', b'11.47s'), (b'x-ratelimit-reset-tokens', b'4.038s'), (b'x-request-id', b'req_01jaq61gdbem3bj9axwzhtsk71'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602c07ffd54ed9-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:20:29,648 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:20:29,648 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:20:29,648 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:20:29,648 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:20:29,648 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:20:29,648 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:20:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '18654', 'x-ratelimit-reset-requests': '11.47s', 'x-ratelimit-reset-tokens': '4.038s', 'x-request-id': 'req_01jaq61gdbem3bj9axwzhtsk71', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602c07ffd54ed9-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:20:29,827 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I've been trained on a broad range of languages, but I'm not fluent in the same way I am in English. I can understand and respond in dozens of languages, including Spanish, French, German, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, and many others. My proficiency might vary, but I can still be of help and provide basic information, translations, or simple conversations in multiple languages. If you need a more detailed or nuanced conversation in a specific language, I can try to point you in the right direction or find a resource that can assist you better.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:20:29,827 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:20:29,827 - httpcore.connection - DEBUG - close.started
2024-10-21 12:20:29,827 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:20:29,827 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:20:29,951 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F098B380>
2024-10-21 12:20:29,951 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:20:30,143 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26A9670>
2024-10-21 12:20:30,143 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:20:30,143 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:20:30,143 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:20:30,143 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:20:30,143 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:20:30,735 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:20:31 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_cfc2ad4401e9acaf8c7d0c0d48e0fc03'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602c10deba4ebb-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:20:30,736 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:20:30,737 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:20:31 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_cfc2ad4401e9acaf8c7d0c0d48e0fc03', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602c10deba4ebb-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:20:30,737 - openai._base_client - DEBUG - request_id: req_cfc2ad4401e9acaf8c7d0c0d48e0fc03
2024-10-21 12:20:30,737 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:20:30,740 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:20:30,740 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:20:30,741 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:20:30,741 - openai._base_client - DEBUG - 2 retries left
2024-10-21 12:20:30,741 - openai._base_client - INFO - Retrying request to /audio/speech in 0.493186 seconds
2024-10-21 12:20:31,236 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I've been trained on a broad range of languages, but I'm not fluent in the same way I am in English. I can understand and respond in dozens of languages, including Spanish, French, German, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, and many others. My proficiency might vary, but I can still be of help and provide basic information, translations, or simple conversations in multiple languages. If you need a more detailed or nuanced conversation in a specific language, I can try to point you in the right direction or find a resource that can assist you better.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:20:31,236 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:20:31,236 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:20:31,387 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EB4A0>
2024-10-21 12:20:31,387 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:20:31,513 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09E9FD0>
2024-10-21 12:20:31,513 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:20:31,513 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:20:31,513 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:20:31,513 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:20:31,513 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:20:32,064 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:20:32 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_98a5c942fce3ac55e6551a4ce7b6b04e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602c18f8364eb4-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:20:32,064 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:20:32,064 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:20:32 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_98a5c942fce3ac55e6551a4ce7b6b04e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602c18f8364eb4-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:20:32,064 - openai._base_client - DEBUG - request_id: req_98a5c942fce3ac55e6551a4ce7b6b04e
2024-10-21 12:20:32,064 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:20:32,064 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:20:32,080 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:20:32,080 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:20:32,080 - openai._base_client - DEBUG - 1 retry left
2024-10-21 12:20:32,080 - openai._base_client - INFO - Retrying request to /audio/speech in 0.875671 seconds
2024-10-21 12:20:32,957 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "I've been trained on a broad range of languages, but I'm not fluent in the same way I am in English. I can understand and respond in dozens of languages, including Spanish, French, German, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, and many others. My proficiency might vary, but I can still be of help and provide basic information, translations, or simple conversations in multiple languages. If you need a more detailed or nuanced conversation in a specific language, I can try to point you in the right direction or find a resource that can assist you better.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:20:32,957 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:20:32,957 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:20:33,072 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26CC5C0>
2024-10-21 12:20:33,072 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:20:33,182 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26CC4A0>
2024-10-21 12:20:33,182 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:20:33,182 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:20:33,182 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:20:33,182 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:20:33,182 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:20:34,929 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:20:35 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1202'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_d1f876d5e6cd5f2383a6b104298d8998'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602c23ad9e739e-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:20:34,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:20:34,929 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:20:35 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1202', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_d1f876d5e6cd5f2383a6b104298d8998', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602c23ad9e739e-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:20:34,929 - openai._base_client - DEBUG - request_id: req_d1f876d5e6cd5f2383a6b104298d8998
2024-10-21 12:20:34,929 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:21:09,156 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:21:09,156 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:21:09,156 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:21:30,063 - faster_whisper - INFO - Processing audio with duration 00:16.904
2024-10-21 12:21:30,806 - faster_whisper - INFO - Detected language 'en' with probability 0.63
2024-10-21 12:21:30,806 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:21:30,994 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Translate this French statement into English, Komotitapel.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:21:30,994 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:21:30,994 - httpcore.connection - DEBUG - close.started
2024-10-21 12:21:30,994 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:21:30,994 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:21:31,104 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EB9E0>
2024-10-21 12:21:31,104 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:21:31,223 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F09EBBC0>
2024-10-21 12:21:31,236 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:21:31,237 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:21:31,237 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:21:31,238 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:21:31,238 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:21:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19867'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'399ms'), (b'x-request-id', b'req_01jaq63dcceh5bbt7g6pjrzyd2'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602d8e3c7373bc-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:21:31,736 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:21:31,736 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:21:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19867', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '399ms', 'x-request-id': 'req_01jaq63dcceh5bbt7g6pjrzyd2', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602d8e3c7373bc-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:21:31,736 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}, {'role': 'assistant', 'content': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?"}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}, {'role': 'assistant', 'content': 'Directions from Nairobi City to Mombasa City typically involve driving via the Mombasa Highway or A109 highway, which is a major road network connecting the two cities. The journey is approximately 480 kilometers and usually takes around 8-10 hours by car, depending on traffic and road conditions. You can take regular breaks along the way through towns like Machakos, Kitale and Voi and it is also advisable to consider hiring a guided tour or driving with a local.'}, {'role': 'user', 'content': "Do you have access to Google Maps API's?"}, {'role': 'assistant', 'content': "No, I don't have direct access to the Google Maps API or any external APIs for that matter. My previous response was based on pre-existing knowledge and general information. I can provide directions and distances but will not have real-time traffic updates or exact route information."}, {'role': 'user', 'content': "Does Jimmy know, can I change your voice? Can I change it to someone else's voice?"}, {'role': 'assistant', 'content': 'I don\'t have personal relationships or interactions with individuals, so I\'m not aware of a "Jimmy" who knows anything about me. Regarding changing my voice, I can mimic the tones, pace, and language styles of different human voices, but I don\'t have direct control over external synthesis or persona modeling that would allow me to perfectly emulate someone else\'s voice, such as a well-known celebrity or an individual. However, I can modify my voice to fit various personas or reflect different emotional tones with varying levels of success, based on pre-existing data and modeling.'}, {'role': 'user', 'content': 'Okay, so now from now on be sound more empathetic.'}, {'role': 'assistant', 'content': "I'll do my best to adapt my tone and language to be more empathetic and compassionate, acknowledging the emotional and personal contexts that users bring to our conversations. I'll strive to be more understanding, supportive, and validating, while still providing accurate and helpful information. Let's communicate in a way that feels more personal and sensitive to your concerns and needs."}, {'role': 'user', 'content': 'What other languages can you recognize apart from English?'}, {'role': 'assistant', 'content': "I've been trained on a broad range of languages, but I'm not fluent in the same way I am in English. I can understand and respond in dozens of languages, including Spanish, French, German, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, and many others. My proficiency might vary, but I can still be of help and provide basic information, translations, or simple conversations in multiple languages. If you need a more detailed or nuanced conversation in a specific language, I can try to point you in the right direction or find a resource that can assist you better."}, {'role': 'user', 'content': 'Translate this French statement into English, Komotitapel.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:21:31,736 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:21:31,736 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:21:32,831 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:21:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'18486'), (b'x-ratelimit-reset-requests', b'11.215s'), (b'x-ratelimit-reset-tokens', b'4.542s'), (b'x-request-id', b'req_01jaq63e40e5vtscfvas1fg5x4'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602d91a8a473bc-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:21:32,831 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:21:32,831 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:21:32,831 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:21:32,831 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:21:32,831 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:21:32,831 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:21:33 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '18486', 'x-ratelimit-reset-requests': '11.215s', 'x-ratelimit-reset-tokens': '4.542s', 'x-request-id': 'req_01jaq63e40e5vtscfvas1fg5x4', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602d91a8a473bc-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:21:33,003 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'The phrase "Komotitapel" doesn\'t seem to be a real French word or phrase. It\'s possible that it\'s a made-up word, a word from another language, or a word with no meaning. If you can provide the actual context or a correct translation attempt of the word, I\'ll do my best to help you understand its meaning or offer a correct translation.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:21:33,003 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:21:33,003 - httpcore.connection - DEBUG - close.started
2024-10-21 12:21:33,003 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:21:33,003 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:21:33,134 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26A9550>
2024-10-21 12:21:33,134 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:21:33,263 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26AA180>
2024-10-21 12:21:33,263 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:21:33,263 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:21:33,263 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:21:33,263 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:21:33,263 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:21:38,759 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:21:39 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'4885'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_4e7b62e61f0a01f361066aa952173d09'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602d9afcde73b5-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:21:38,759 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:21:38,759 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:21:39 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '4885', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_4e7b62e61f0a01f361066aa952173d09', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602d9afcde73b5-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:21:38,759 - openai._base_client - DEBUG - request_id: req_4e7b62e61f0a01f361066aa952173d09
2024-10-21 12:21:38,759 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:21:59,110 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:21:59,110 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:21:59,110 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:22:10,389 - faster_whisper - INFO - Processing audio with duration 00:10.797
2024-10-21 12:22:11,070 - faster_whisper - INFO - Detected language 'fr' with probability 0.90
2024-10-21 12:22:11,070 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:22:11,201 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Et ce que tu fais de la vie.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:22:11,201 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:22:11,217 - httpcore.connection - DEBUG - close.started
2024-10-21 12:22:11,217 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:22:11,217 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:22:11,323 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269F2F0>
2024-10-21 12:22:11,323 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95C950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:22:11,446 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F269DD00>
2024-10-21 12:22:11,446 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:22:11,446 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:22:11,447 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:22:11,447 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:22:11,447 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:22:11,952 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:22:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19874'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'378ms'), (b'x-request-id', b'req_01jaq64mndf20rd0nk2sk7zxaw'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602e89a87b93d0-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:22:11,952 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:22:11,952 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:22:11,952 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:22:11,952 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:22:11,952 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:22:11,952 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:22:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19874', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '378ms', 'x-request-id': 'req_01jaq64mndf20rd0nk2sk7zxaw', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602e89a87b93d0-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:22:11,968 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'You'}, {'role': 'assistant', 'content': 'I am a multi-modal AI voice assistant designed to provide information, answer questions, and complete tasks based on user input. I can process and understand both voice commands and detailed text prompts, including those generated from attached images for context. My primary goal is to generate relevant and factual responses while carefully considering any previously generated text, providing clear, concise, and accurate information to assist users in their queries.'}, {'role': 'user', 'content': 'Which is the longest you find the world?'}, {'role': 'assistant', 'content': 'The length of countries can vary depending on the source and method of measurement. However, the longest country in the world is Greenland, which is approximately 2,750 kilometers (1,710 miles) long, that is roughly 43 times the height of Mount Everest and 7,500 times the length of a football field, with its longest width at 650 kilometers.'}, {'role': 'user', 'content': 'Other countries where perfect communism exists.'}, {'role': 'assistant', 'content': "It's worth noting that perfect communism as envisioned by Karl Marx is rare or nonexistent in practice. However, some countries have implemented socialist or communist systems, such as China, Cuba, Laos, and Vietnam. These countries have varying degrees of market-oriented economies, state control, and restrictions on private property and personal freedoms, which diverges from the ideologies of communism and may not fit the ideal model."}, {'role': 'user', 'content': 'You can explain utilitarianism, utilitarianismism.'}, {'role': 'assistant', 'content': 'It seems like you meant to ask me to explain utilitarianism again, or perhaps clarify it since I couldn\'t find an instance of the term "utilitarianismism". Utilitarianism is a moral philosophy that asserts an action is right if it maximizes overall happiness or well-being, and wrong if it doesn\'t. It\'s often associated with the ideas of Jeremy Bentham and John Stuart Mill, who argued that the right action is the one that causes the greatest happiness for the greatest number of people, which they referred to as the "greatest happiness principle".'}, {'role': 'user', 'content': 'Can you give me directions from Strathmo University to Lannata by Rudd?'}, {'role': 'assistant', 'content': "I couldn't find any information about a university called Strathmo University or a location called Lannata by Rudd, which suggests that these might not be real places or at least not well-known. Can you provide more context or details about the university and the location you're trying to reach, or ask for directions to a different destination?"}, {'role': 'user', 'content': 'Directions from Nairobi City to Mombasa City in Kenya.'}, {'role': 'assistant', 'content': 'Directions from Nairobi City to Mombasa City typically involve driving via the Mombasa Highway or A109 highway, which is a major road network connecting the two cities. The journey is approximately 480 kilometers and usually takes around 8-10 hours by car, depending on traffic and road conditions. You can take regular breaks along the way through towns like Machakos, Kitale and Voi and it is also advisable to consider hiring a guided tour or driving with a local.'}, {'role': 'user', 'content': "Do you have access to Google Maps API's?"}, {'role': 'assistant', 'content': "No, I don't have direct access to the Google Maps API or any external APIs for that matter. My previous response was based on pre-existing knowledge and general information. I can provide directions and distances but will not have real-time traffic updates or exact route information."}, {'role': 'user', 'content': "Does Jimmy know, can I change your voice? Can I change it to someone else's voice?"}, {'role': 'assistant', 'content': 'I don\'t have personal relationships or interactions with individuals, so I\'m not aware of a "Jimmy" who knows anything about me. Regarding changing my voice, I can mimic the tones, pace, and language styles of different human voices, but I don\'t have direct control over external synthesis or persona modeling that would allow me to perfectly emulate someone else\'s voice, such as a well-known celebrity or an individual. However, I can modify my voice to fit various personas or reflect different emotional tones with varying levels of success, based on pre-existing data and modeling.'}, {'role': 'user', 'content': 'Okay, so now from now on be sound more empathetic.'}, {'role': 'assistant', 'content': "I'll do my best to adapt my tone and language to be more empathetic and compassionate, acknowledging the emotional and personal contexts that users bring to our conversations. I'll strive to be more understanding, supportive, and validating, while still providing accurate and helpful information. Let's communicate in a way that feels more personal and sensitive to your concerns and needs."}, {'role': 'user', 'content': 'What other languages can you recognize apart from English?'}, {'role': 'assistant', 'content': "I've been trained on a broad range of languages, but I'm not fluent in the same way I am in English. I can understand and respond in dozens of languages, including Spanish, French, German, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, and many others. My proficiency might vary, but I can still be of help and provide basic information, translations, or simple conversations in multiple languages. If you need a more detailed or nuanced conversation in a specific language, I can try to point you in the right direction or find a resource that can assist you better."}, {'role': 'user', 'content': 'Translate this French statement into English, Komotitapel.'}, {'role': 'assistant', 'content': 'The phrase "Komotitapel" doesn\'t seem to be a real French word or phrase. It\'s possible that it\'s a made-up word, a word from another language, or a word with no meaning. If you can provide the actual context or a correct translation attempt of the word, I\'ll do my best to help you understand its meaning or offer a correct translation.'}, {'role': 'user', 'content': 'Et ce que tu fais de la vie.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:22:11,970 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:22:11,970 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:22:11,970 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:22:11,970 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:22:11,970 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:22:11,970 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:22:12,856 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:22:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'18385'), (b'x-ratelimit-reset-requests', b'11.448999999s'), (b'x-ratelimit-reset-tokens', b'4.845s'), (b'x-request-id', b'req_01jaq64n5bf9m95y03nqaf86ra'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602e8cdc8593d0-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:22:12,856 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:22:12,856 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:22:12,856 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:22:12,856 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:22:12,856 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:22:12,856 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:22:13 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '18385', 'x-ratelimit-reset-requests': '11.448999999s', 'x-ratelimit-reset-tokens': '4.845s', 'x-request-id': 'req_01jaq64n5bf9m95y03nqaf86ra', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d602e8cdc8593d0-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:22:13,020 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'The phrase "Et ce que tu fais de la vie" is a French expression that translates to "And what do you make of life" in English. This phrase is asking someone how they perceive life, what they think it is all about, or how they approach their existence. It\'s a philosophical and introspective question that invites the person to share their thoughts and feelings about life.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:22:13,020 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:22:13,020 - httpcore.connection - DEBUG - close.started
2024-10-21 12:22:13,020 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:22:13,020 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:22:13,134 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26A8D70>
2024-10-21 12:22:13,134 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256ED95D1D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:22:13,268 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256F26ABBF0>
2024-10-21 12:22:13,268 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:22:13,268 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:22:13,268 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:22:13,268 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:22:13,268 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:22:15,356 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:22:15 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'948'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_992da4c2079ef5a35a12f6622e967485'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d602e94f9544ec8-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:22:15,356 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:22:15,356 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:22:15 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '948', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_992da4c2079ef5a35a12f6622e967485', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d602e94f9544ec8-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:22:15,356 - openai._base_client - DEBUG - request_id: req_992da4c2079ef5a35a12f6622e967485
2024-10-21 12:22:15,356 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:22:38,058 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:22:38,058 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:22:38,058 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:22:55,106 - faster_whisper - INFO - Processing audio with duration 00:10.890
2024-10-21 12:22:55,762 - faster_whisper - INFO - Detected language 'ar' with probability 0.76
2024-10-21 12:22:55,762 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:22:55,935 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.0 (-1.106405 < -1.000000)
2024-10-21 12:22:56,264 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.2 (-1.142616 < -1.000000)
2024-10-21 12:22:56,594 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.4 (-1.483379 < -1.000000)
2024-10-21 12:22:56,910 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.6 (-1.238541 < -1.000000)
2024-10-21 12:22:57,240 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 0.8 (-1.948776 < -1.000000)
2024-10-21 12:22:57,511 - faster_whisper - DEBUG - Log probability threshold is not met with temperature 1.0 (-3.143185 < -1.000000)
2024-10-21 12:22:57,524 - faster_whisper - DEBUG - Reset prompt. prompt_reset_on_temperature threshold is met 1.000000 > 0.500000
2024-10-21 12:23:13,093 - comtypes._post_coinit.unknwn - DEBUG - Calling CoUninitialize()
2024-10-21 12:23:13,093 - comtypes._post_coinit.unknwn - DEBUG - CoUninitialize() done.
2024-10-21 12:23:13,140 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>.Release() -> 0
2024-10-21 12:23:13,140 - comtypes._comobject - DEBUG - 0 active COM objects: Removed <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000256ED689D00>
2024-10-21 12:23:13,140 - comtypes._comobject - DEBUG - Remaining: []
2024-10-21 12:23:13,203 - httpcore.connection - DEBUG - close.started
2024-10-21 12:23:13,203 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:23:13,203 - httpcore.connection - DEBUG - close.started
2024-10-21 12:23:13,203 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:27:35,649 - __main__ - INFO - Starting main.py
2024-10-21 12:27:35,649 - __main__ - INFO - Chat log file path: C:\Users\Lance\Desktop\CODEWRLD\ai-personal-assistant\data\chat_history\2024\10\21.log
2024-10-21 12:27:35,649 - __main__ - INFO - API keys loaded successfully
2024-10-21 12:27:35,664 - comtypes - DEBUG - CoInitializeEx(None, 2)
2024-10-21 12:27:35,700 - comtypes.client._code_cache - INFO - Imported existing <module 'comtypes.gen' from 'C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\comtypes\\gen\\__init__.py'>
2024-10-21 12:27:35,701 - comtypes.client._code_cache - INFO - Using writeable comtypes cache directory: 'C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\comtypes\gen'
2024-10-21 12:27:35,746 - comtypes.client - DEBUG - SAPI.SPVoice -> {96749377-3391-11D2-9EE3-00C04F797396}
2024-10-21 12:27:35,746 - comtypes.client - DEBUG - CoCreateInstance({96749377-3391-11D2-9EE3-00C04F797396}, clsctx=None, interface=None)
2024-10-21 12:27:35,762 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IUnknown) ptr=0x1569f78f640 at 156b6abaf50>)
2024-10-21 12:27:35,763 - comtypes.client - DEBUG - Does implement IProvideClassInfo
2024-10-21 12:27:35,764 - comtypes.client - DEBUG - Default interface is {269316D8-57BD-11D2-9EEE-00C04F797396}
2024-10-21 12:27:35,765 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1569f78f680 at 156b6abb350>
2024-10-21 12:27:35,765 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:27:35,766 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechVoice'>
2024-10-21 12:27:35,766 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechVoice) ptr=0x1569f78f680 at 156b6abb2d0>
2024-10-21 12:27:35,766 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo) ptr=0x1569f78f6a0 at 156b6abaed0>
2024-10-21 12:27:35,767 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x156b51a95e8 at 156b6abafd0>
2024-10-21 12:27:35,767 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x156b51a9640 at 156b6abb050>
2024-10-21 12:27:35,767 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x156b5144870 at 156b6abb350>
2024-10-21 12:27:35,768 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x1569f78f640 at 156b6abaf50>
2024-10-21 12:27:35,768 - comtypes.client._events - DEBUG - <POINTER(ISpeechVoice) ptr=0x1569f78f680 at 156b6abb2d0> using sinkinterface from clsid <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:27:35,796 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IProvideClassInfo2) ptr=0x1569f78f6a0 at 156b6abaf50>
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>: _ISpeechVoiceEvents.VoiceChange not implemented
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>: _ISpeechVoiceEvents.Bookmark not implemented
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>: _ISpeechVoiceEvents.Sentence not implemented
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>: _ISpeechVoiceEvents.Phoneme not implemented
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>: _ISpeechVoiceEvents.Viseme not implemented
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>: _ISpeechVoiceEvents.AudioLevel not implemented
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>: _ISpeechVoiceEvents.EnginePrivate not implemented
2024-10-21 12:27:35,796 - comtypes.client._events - DEBUG - Start advise <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4._ISpeechVoiceEvents'>
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>.QueryInterface({A372ACD1-3BEF-4BBD-8FFB-CB3E2B416AF8}) -> S_OK
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - 1 active COM objects: Added   <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>
2024-10-21 12:27:35,796 - comtypes._comobject - DEBUG - <comtypes.client._events.CreateEventReceiver.<locals>.Sink object at 0x00000156B6849460>.AddRef() -> 1
2024-10-21 12:27:35,796 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IConnectionPointContainer) ptr=0x1569f78f6a8 at 156b6b20750>
2024-10-21 12:27:35,874 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectToken) ptr=0x1569f7d0f70 at 156b6b20750>)
2024-10-21 12:27:35,874 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x1569f7d0f70 at 156b6b20750>
2024-10-21 12:27:35,875 - comtypes.client - DEBUG - wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x156b6ece3d0 at 156b6b20750>)
2024-10-21 12:27:35,875 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x156b6ef7100 at 156b6b20850>
2024-10-21 12:27:35,875 - comtypes.client - DEBUG - wrap_outparam(<POINTER(IDispatch) ptr=0x156b6e0a160 at 156b6b20a50>)
2024-10-21 12:27:35,876 - comtypes.client - DEBUG - GetBestInterface(<POINTER(IDispatch) ptr=0x156b6e0a160 at 156b6b20a50>)
2024-10-21 12:27:35,876 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo, trying IProvideClassInfo2
2024-10-21 12:27:35,877 - comtypes.client - DEBUG - Does NOT implement IProvideClassInfo/IProvideClassInfo2
2024-10-21 12:27:35,878 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x156b51a96f0 at 156b6b20c50>
2024-10-21 12:27:35,878 - comtypes.client - DEBUG - Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}
2024-10-21 12:27:35,878 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IUnknown) ptr=0x156b6e0a160 at 156b6b20d50>
2024-10-21 12:27:35,879 - comtypes.client._generate - DEBUG - GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))
2024-10-21 12:27:35,879 - comtypes.client - DEBUG - Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>
2024-10-21 12:27:35,879 - comtypes.client - DEBUG - Final result is <POINTER(ISpeechObjectToken) ptr=0x156b6e0a160 at 156b6b20c50>
2024-10-21 12:27:35,879 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x156b6e0a160 at 156b6b20bd0>
2024-10-21 12:27:35,879 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeInfo) ptr=0x156b51a96f0 at 156b6b20cd0>
2024-10-21 12:27:35,879 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ITypeLib) ptr=0x156b5144870 at 156b6b20d50>
2024-10-21 12:27:35,880 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IDispatch) ptr=0x156b6e0a160 at 156b6b20a50>
2024-10-21 12:27:35,880 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(IEnumVARIANT) ptr=0x156b6ef7100 at 156b6b208d0>
2024-10-21 12:27:35,880 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectTokens) ptr=0x156b6ece3d0 at 156b6b20750>
2024-10-21 12:27:35,880 - comtypes._post_coinit.unknwn - DEBUG - Release <POINTER(ISpeechObjectToken) ptr=0x156b6e0a160 at 156b6b20c50>
2024-10-21 12:27:35,881 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:27:35,882 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:27:36,104 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-10-21 12:27:36,104 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\Lance\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-10-21 12:27:36,491 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2024-10-21 12:27:37,238 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/Systran/faster-whisper-base/revision/main HTTP/1.1" 200 1848
2024-10-21 12:27:37,830 - __main__ - INFO - Siri instance initialized
2024-10-21 12:27:43,239 - faster_whisper - INFO - Processing audio with duration 00:01.834
2024-10-21 12:27:43,885 - faster_whisper - INFO - Detected language 'en' with probability 0.63
2024-10-21 12:27:43,885 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:27:44,010 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'end of it again.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:27:44,136 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:27:44,136 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:27:44,275 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156B9BE5DC0>
2024-10-21 12:27:44,275 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B20950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:27:44,492 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156B9B8EE40>
2024-10-21 12:27:44,492 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:27:44,492 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:27:44,492 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:27:44,492 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:27:44,492 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:27:44,994 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:27:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19877'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'369ms'), (b'x-request-id', b'req_01jaq6esx4faaraas0fwxxv8a0'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pPHZ_dMbq8xuIsWLLGulqxE76tYVFLvq6aVQy8IFndI-1729502865-1.0.1.1-5Pf2VUNaTFsCUZ6b7Jn6mWdFAjsJHMF_e6C_2NmP4UDnMYiDRuctN9FQu8C.jSu0CcqEEmKXXz9YxUOTieaBtA; path=/; expires=Mon, 21-Oct-24 09:57:45 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6036ab3e3d73e2-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:27:44,995 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:27:44,995 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:27:44,995 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:27:44,995 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:27:44,995 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:27:44,995 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:27:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19877', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '369ms', 'x-request-id': 'req_01jaq6esx4faaraas0fwxxv8a0', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=pPHZ_dMbq8xuIsWLLGulqxE76tYVFLvq6aVQy8IFndI-1729502865-1.0.1.1-5Pf2VUNaTFsCUZ6b7Jn6mWdFAjsJHMF_e6C_2NmP4UDnMYiDRuctN9FQu8C.jSu0CcqEEmKXXz9YxUOTieaBtA; path=/; expires=Mon, 21-Oct-24 09:57:45 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8d6036ab3e3d73e2-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:27:45,004 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'end of it again.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:27:45,006 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:27:45,006 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:27:45,007 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:27:45,007 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:27:45,007 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:27:45,007 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:27:45,589 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:27:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19823'), (b'x-ratelimit-reset-requests', b'11.491999999s'), (b'x-ratelimit-reset-tokens', b'531ms'), (b'x-request-id', b'req_01jaq6etd2esxv4fqzcvsvkn5a'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6036ae7a1c73e2-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:27:45,605 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:27:45,605 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:27:45,605 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:27:45,605 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:27:45,605 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:27:45,605 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:27:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19823', 'x-ratelimit-reset-requests': '11.491999999s', 'x-ratelimit-reset-tokens': '531ms', 'x-request-id': 'req_01jaq6etd2esxv4fqzcvsvkn5a', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6036ae7a1c73e2-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:27:45,779 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'The phrase "end of it again" is likely a reference to the phrase "back to the start." This phrase often accompanies the SpongeBob SquarePants theme song when the episode is supposed to end in order to begin with the start again, indicating another error in the system at the end of an otherwise completed format of its 1999 television production', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:27:45,781 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:27:45,781 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:27:45,908 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB816120>
2024-10-21 12:27:45,909 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B211D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:27:46,044 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB815E80>
2024-10-21 12:27:46,044 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:27:46,049 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:27:46,049 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:27:46,049 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:27:46,049 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:27:47,016 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:27:47 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_c47bf6f27d268f2f9f0b948dbbf80210'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=blL3Y_M7ukF00xlC435Tmft7GV1uSy94QIYP3QNjQyQ-1729502867-1.0.1.1-pTKKsuTw9egsmUEqjiSe93wCFKL7pnc8dj36Ck6ZIKOGE5F4pKQM6m2pXbw_zKZzvoqiLLwcoKnT4zV2gv5Egg; path=/; expires=Mon, 21-Oct-24 09:57:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=p3Vc2oKlMPm20WUV.VOeB3titAhOn8qRWRDCWzF4rSI-1729502867537-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6036b4dc187410-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:27:47,016 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:27:47,016 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers([('date', 'Mon, 21 Oct 2024 09:27:47 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_c47bf6f27d268f2f9f0b948dbbf80210'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=blL3Y_M7ukF00xlC435Tmft7GV1uSy94QIYP3QNjQyQ-1729502867-1.0.1.1-pTKKsuTw9egsmUEqjiSe93wCFKL7pnc8dj36Ck6ZIKOGE5F4pKQM6m2pXbw_zKZzvoqiLLwcoKnT4zV2gv5Egg; path=/; expires=Mon, 21-Oct-24 09:57:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=p3Vc2oKlMPm20WUV.VOeB3titAhOn8qRWRDCWzF4rSI-1729502867537-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8d6036b4dc187410-JNB'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-10-21 12:27:47,016 - openai._base_client - DEBUG - request_id: req_c47bf6f27d268f2f9f0b948dbbf80210
2024-10-21 12:27:47,016 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:27:47,024 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:27:47,025 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:27:47,025 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:27:47,025 - openai._base_client - DEBUG - 2 retries left
2024-10-21 12:27:47,026 - openai._base_client - INFO - Retrying request to /audio/speech in 0.439467 seconds
2024-10-21 12:27:47,466 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'The phrase "end of it again" is likely a reference to the phrase "back to the start." This phrase often accompanies the SpongeBob SquarePants theme song when the episode is supposed to end in order to begin with the start again, indicating another error in the system at the end of an otherwise completed format of its 1999 television production', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:27:47,466 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:27:47,466 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:27:47,592 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB8175C0>
2024-10-21 12:27:47,592 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B211D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:27:47,712 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB815AF0>
2024-10-21 12:27:47,712 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:27:47,712 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:27:47,712 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:27:47,712 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:27:47,712 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:27:49,791 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:27:50 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1343'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_c63db1d62ca51aa84d87fafff648696f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6036bfca970526-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:27:49,791 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:27:49,791 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:27:50 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1343', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_c63db1d62ca51aa84d87fafff648696f', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6036bfca970526-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:27:49,791 - openai._base_client - DEBUG - request_id: req_c63db1d62ca51aa84d87fafff648696f
2024-10-21 12:27:49,791 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:28:11,672 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:28:11,672 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:28:11,672 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:28:28,934 - faster_whisper - INFO - Processing audio with duration 00:13.607
2024-10-21 12:28:29,571 - faster_whisper - INFO - Detected language 'en' with probability 0.70
2024-10-21 12:28:29,571 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:28:29,756 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'I wanted to ask you next, um, what more do you are?'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:28:29,756 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:28:29,756 - httpcore.connection - DEBUG - close.started
2024-10-21 12:28:29,756 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:28:29,756 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:28:29,879 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156B9BE5BB0>
2024-10-21 12:28:29,879 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B20950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:28:30,012 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156B9BE5A00>
2024-10-21 12:28:30,013 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:28:30,013 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:28:30,013 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:28:30,014 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:28:30,014 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:28:30,528 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19869'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'393ms'), (b'x-request-id', b'req_01jaq6g6c5e2w93f1e4nnxhxcf'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6037c7cffc4fc4-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:28:30,528 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:28:30,528 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:28:30,528 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:28:30,528 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:28:30,528 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:28:30,528 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:28:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19869', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '393ms', 'x-request-id': 'req_01jaq6g6c5e2w93f1e4nnxhxcf', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6037c7cffc4fc4-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:28:30,694 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2024-10-21 12:28:30,694 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2024-10-21 12:28:35,326 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'end of it again.'}, {'role': 'assistant', 'content': 'The phrase "end of it again" is likely a reference to the phrase "back to the start." This phrase often accompanies the SpongeBob SquarePants theme song when the episode is supposed to end in order to begin with the start again, indicating another error in the system at the end of an otherwise completed format of its 1999 television production'}, {'role': 'user', 'content': 'USER_PROMPT: I wanted to ask you next, um, what more do you are?\n\nIMAGE_CONTEXT: The image shows a code for a Python script that defines a class called `Siri`. This class appears to be a multi-modal AI voice assistant that processes voice commands and context. The script is shown to be in the process of being developed and contains comments explaining different parts of the code.  Within the comments, there are lines of code and a section called Summary, which provides a synopsis of the program\'s functionality.  The Summary section highlights the assistant\'s capability to capture images from a webcam using the `webcam.capture_webcam_image()` function.  The image also shows a terminal window with outputs from a program, possibly related to a web server request. There is also a small pop-up window with a message about the Siri assistant being initialized.  However, there is no mention of what the assistant is "more" than a multi-modal AI voice assistant that processes voice commands and context.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:28:35,326 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:28:35,326 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:28:35,326 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:28:35,326 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:28:35,326 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:28:35,326 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:28:36,096 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:28:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19474'), (b'x-ratelimit-reset-requests', b'6.640999999s'), (b'x-ratelimit-reset-tokens', b'1.578s'), (b'x-request-id', b'req_01jaq6gbkne9a8jw40gya2gpt3'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6037e8de294fc4-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:28:36,096 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:28:36,096 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:28:36,096 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:28:36,096 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:28:36,096 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:28:36,096 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:28:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19474', 'x-ratelimit-reset-requests': '6.640999999s', 'x-ratelimit-reset-tokens': '1.578s', 'x-request-id': 'req_01jaq6gbkne9a8jw40gya2gpt3', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6037e8de294fc4-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:28:36,341 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': 'It appears you are referring to the `Siri` class in a Python script, which is likely where the concept of a "Siri"-like assistant is being formalized; there\'s no indication that the code or comments explicitly describe the assistant being "more" than this multi-modal voice Assistant; more context or information would likely be required to identify any additional capabilities beyond its core voice command functionality.', 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:28:36,343 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:28:36,343 - httpcore.connection - DEBUG - close.started
2024-10-21 12:28:36,344 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:28:36,344 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:28:36,457 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB914080>
2024-10-21 12:28:36,458 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B211D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:28:36,577 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB903D40>
2024-10-21 12:28:36,581 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:28:36,581 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:28:36,581 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:28:36,581 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:28:36,581 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:28:38,886 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:28:39 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1411'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_534dcd0754ca05448c1e73864cc4b408'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6037f0bb3c4ec6-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:28:38,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:28:38,886 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:28:39 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1411', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_534dcd0754ca05448c1e73864cc4b408', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6037f0bb3c4ec6-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:28:38,886 - openai._base_client - DEBUG - request_id: req_534dcd0754ca05448c1e73864cc4b408
2024-10-21 12:28:38,886 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:29:04,732 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:29:04,732 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:29:04,732 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:29:18,255 - faster_whisper - INFO - Processing audio with duration 00:11.842
2024-10-21 12:29:18,901 - faster_whisper - INFO - Detected language 'en' with probability 0.80
2024-10-21 12:29:18,901 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:29:19,057 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'Watch our webcom and tell me what you see.'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:29:19,057 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:29:19,057 - httpcore.connection - DEBUG - close.started
2024-10-21 12:29:19,057 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:29:19,057 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:29:19,185 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB901310>
2024-10-21 12:29:19,185 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B20950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:29:19,326 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB902D50>
2024-10-21 12:29:19,326 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:29:19,326 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:29:19,326 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:29:19,326 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:29:19,326 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:29:19,893 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:29:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'19871'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'387ms'), (b'x-request-id', b'req_01jaq6hpgwfag8sgpzvtm6nf8e'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6038fbec2073f5-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:29:19,893 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:29:19,893 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:29:19,893 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:29:19,893 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:29:19,893 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:29:19,893 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:29:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '19871', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '387ms', 'x-request-id': 'req_01jaq6hpgwfag8sgpzvtm6nf8e', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d6038fbec2073f5-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:29:20,940 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2024-10-21 12:29:20,940 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 8192
2024-10-21 12:29:23,747 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are a multi-modal AI voice assistant. Your user may have attached a photo (screenshot or webcam capture) for context, which has already been processed into a detailed text prompt. This will be attached to their transcribed voice input. Generate the most relevant and factual response by carefully considering all previously generated text before adding new information. Do not expect or request additional images; use the provided context if available. Please do not include newlines in your response. Keep it all in one paragraph. Ensure your responses are clear, concise, and relevant to the ongoing conversation, avoiding any unnecessary verbosity.'}, {'role': 'user', 'content': 'end of it again.'}, {'role': 'assistant', 'content': 'The phrase "end of it again" is likely a reference to the phrase "back to the start." This phrase often accompanies the SpongeBob SquarePants theme song when the episode is supposed to end in order to begin with the start again, indicating another error in the system at the end of an otherwise completed format of its 1999 television production'}, {'role': 'user', 'content': 'USER_PROMPT: I wanted to ask you next, um, what more do you are?\n\nIMAGE_CONTEXT: The image shows a code for a Python script that defines a class called `Siri`. This class appears to be a multi-modal AI voice assistant that processes voice commands and context. The script is shown to be in the process of being developed and contains comments explaining different parts of the code.  Within the comments, there are lines of code and a section called Summary, which provides a synopsis of the program\'s functionality.  The Summary section highlights the assistant\'s capability to capture images from a webcam using the `webcam.capture_webcam_image()` function.  The image also shows a terminal window with outputs from a program, possibly related to a web server request. There is also a small pop-up window with a message about the Siri assistant being initialized.  However, there is no mention of what the assistant is "more" than a multi-modal AI voice assistant that processes voice commands and context.'}, {'role': 'assistant', 'content': 'It appears you are referring to the `Siri` class in a Python script, which is likely where the concept of a "Siri"-like assistant is being formalized; there\'s no indication that the code or comments explicitly describe the assistant being "more" than this multi-modal voice Assistant; more context or information would likely be required to identify any additional capabilities beyond its core voice command functionality.'}, {'role': 'user', 'content': "USER_PROMPT: Watch our webcom and tell me what you see.\n\nIMAGE_CONTEXT: The image shows a dark-skinned person, likely male, with short hair, looking directly at the camera. The person is partially obscured by shadows and is in a dimly lit room. Part of a sheer curtain or mosquito net is visible in the background, along with a portion of a window with a sheer curtain. The window is partially obscured by a bright light source outside, casting a glow onto the curtain.  The person's expression is obscured by the shadows."}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:29:23,763 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:29:23,763 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:29:23,763 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:29:23,763 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:29:23,763 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:29:23,763 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:29:24,550 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:29:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'20000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'19229'), (b'x-ratelimit-reset-requests', b'7.471s'), (b'x-ratelimit-reset-tokens', b'2.313s'), (b'x-request-id', b'req_01jaq6htxtedd8796fabh5eb4f'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d603917d9be73f5-JNB'), (b'Content-Encoding', b'gzip')])
2024-10-21 12:29:24,550 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-21 12:29:24,550 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:29:24,550 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:29:24,550 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:29:24,550 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:29:24,550 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:29:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '20000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '19229', 'x-ratelimit-reset-requests': '7.471s', 'x-ratelimit-reset-tokens': '2.313s', 'x-request-id': 'req_01jaq6htxtedd8796fabh5eb4f', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8d603917d9be73f5-JNB', 'content-encoding': 'gzip'})
2024-10-21 12:29:24,726 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "Based on the provided image, I see a person with a dark skin tone, having short hair, partially obscured by shadows. The room appears to be dimly lit and there's a window in the background with a sheer curtain, partially lit by an external light source which casts a glow onto the curtain. Unfortunately, the person's expression is not clearly visible due to the shadows.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:29:24,726 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:29:24,726 - httpcore.connection - DEBUG - close.started
2024-10-21 12:29:24,726 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:29:24,726 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:29:24,875 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB9157C0>
2024-10-21 12:29:24,875 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B211D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:29:25,025 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB9153A0>
2024-10-21 12:29:25,025 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:29:25,025 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:29:25,025 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:29:25,025 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:29:25,025 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:29:25,524 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:29:26 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_3df2000efb97e5e954b5f08c6233b722'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60391fdbbf73e0-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:29:25,526 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:29:25,526 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:29:26 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_3df2000efb97e5e954b5f08c6233b722', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d60391fdbbf73e0-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:29:25,526 - openai._base_client - DEBUG - request_id: req_3df2000efb97e5e954b5f08c6233b722
2024-10-21 12:29:25,526 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:29:25,526 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:29:25,526 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:29:25,526 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:29:25,526 - openai._base_client - DEBUG - 2 retries left
2024-10-21 12:29:25,532 - openai._base_client - INFO - Retrying request to /audio/speech in 0.386093 seconds
2024-10-21 12:29:25,919 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "Based on the provided image, I see a person with a dark skin tone, having short hair, partially obscured by shadows. The room appears to be dimly lit and there's a window in the background with a sheer curtain, partially lit by an external light source which casts a glow onto the curtain. Unfortunately, the person's expression is not clearly visible due to the shadows.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:29:25,919 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:29:25,919 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:29:26,042 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB916720>
2024-10-21 12:29:26,042 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B211D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:29:26,160 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB916420>
2024-10-21 12:29:26,160 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:29:26,160 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:29:26,160 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:29:26,160 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:29:26,160 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:29:26,546 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 21 Oct 2024 09:29:27 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_beb3ec8c41f7f9c43912f09834a4e55a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d6039269b57738b-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:29:26,546 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
2024-10-21 12:29:26,546 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "429 Too Many Requests" Headers({'date': 'Mon, 21 Oct 2024 09:29:27 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_beb3ec8c41f7f9c43912f09834a4e55a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d6039269b57738b-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:29:26,561 - openai._base_client - DEBUG - request_id: req_beb3ec8c41f7f9c43912f09834a4e55a
2024-10-21 12:29:26,561 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\openai\_base_client.py", line 1037, in _request
    response.raise_for_status()
  File "C:\Users\Lance\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/audio/speech'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-10-21 12:29:26,565 - openai._base_client - DEBUG - Retrying due to status code 429
2024-10-21 12:29:26,565 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:29:26,565 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:29:26,566 - openai._base_client - DEBUG - 1 retry left
2024-10-21 12:29:26,567 - openai._base_client - INFO - Retrying request to /audio/speech in 0.768365 seconds
2024-10-21 12:29:27,336 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/audio/speech', 'headers': {'Accept': 'application/octet-stream', 'X-Stainless-Raw-Response': 'stream'}, 'files': None, 'json_data': {'input': "Based on the provided image, I see a person with a dark skin tone, having short hair, partially obscured by shadows. The room appears to be dimly lit and there's a window in the background with a sheer curtain, partially lit by an external light source which casts a glow onto the curtain. Unfortunately, the person's expression is not clearly visible due to the shadows.", 'model': 'tts-1', 'voice': 'nova', 'response_format': 'pcm'}}
2024-10-21 12:29:27,336 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/audio/speech
2024-10-21 12:29:27,336 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:29:27,459 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB914500>
2024-10-21 12:29:27,459 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B211D0> server_hostname='api.openai.com' timeout=5.0
2024-10-21 12:29:27,576 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156BB917710>
2024-10-21 12:29:27,576 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-21 12:29:27,576 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-21 12:29:27,576 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-21 12:29:27,576 - httpcore.http11 - DEBUG - send_request_body.complete
2024-10-21 12:29:27,576 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-21 12:29:29,298 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 21 Oct 2024 09:29:29 GMT'), (b'Content-Type', b'audio/pcm'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'viva-ai-g59lkf'), (b'openai-processing-ms', b'1045'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-request-id', b'req_4e66dbdccc6ecb6a1a3554ad16aa8bd4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d60392f6bbf0526-JNB'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-21 12:29:29,298 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
2024-10-21 12:29:29,298 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/audio/speech "200 OK" Headers({'date': 'Mon, 21 Oct 2024 09:29:29 GMT', 'content-type': 'audio/pcm', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'viva-ai-g59lkf', 'openai-processing-ms': '1045', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_4e66dbdccc6ecb6a1a3554ad16aa8bd4', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d60392f6bbf0526-JNB', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-21 12:29:29,298 - openai._base_client - DEBUG - request_id: req_4e66dbdccc6ecb6a1a3554ad16aa8bd4
2024-10-21 12:29:29,298 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-21 12:29:52,169 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-21 12:29:52,170 - httpcore.http11 - DEBUG - response_closed.started
2024-10-21 12:29:52,170 - httpcore.http11 - DEBUG - response_closed.complete
2024-10-21 12:29:57,446 - faster_whisper - INFO - Processing audio with duration 00:01.718
2024-10-21 12:29:58,108 - faster_whisper - INFO - Detected language 'en' with probability 0.44
2024-10-21 12:29:58,108 - faster_whisper - DEBUG - Processing segment at 00:00.000
2024-10-21 12:29:58,209 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are an AI model tasked with selecting the most appropriate action for a voice assistant. Based on the user's prompt, choose one of the following actions: ['extract clipboard', 'take screenshot', 'delete screenshot', 'capture webcam', 'generic']. Assume the webcam is a standard laptop webcam facing the user. Provide only the action without explanations or additional text. Respond strictly with the most suitable option from the list."}, {'role': 'user', 'content': 'You'}], 'model': 'llama-3.1-8b-instant'}}
2024-10-21 12:29:58,209 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2024-10-21 12:29:58,209 - httpcore.connection - DEBUG - close.started
2024-10-21 12:29:58,209 - httpcore.connection - DEBUG - close.complete
2024-10-21 12:29:58,209 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-21 12:29:58,330 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000156A154BC50>
2024-10-21 12:29:58,330 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000156B6B20950> server_hostname='api.groq.com' timeout=5.0
2024-10-21 12:29:58,333 - comtypes._post_coinit.unknwn - DEBUG - Calling CoUninitialize()
2024-10-21 12:29:58,333 - comtypes._post_coinit.unknwn - DEBUG - CoUninitialize() done.
